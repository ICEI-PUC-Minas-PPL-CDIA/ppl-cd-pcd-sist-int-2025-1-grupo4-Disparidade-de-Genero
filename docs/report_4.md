# Disparidade de Gênero no Setor da Tecnologia


**Pedro Lansdowne Oliveira, pedro.lansdowne@sga.pucminas.br**

**Leonardo Andrade Caetano Dornelas, lacdornelas@sga.pucminas.br**

**Augusto Henrique Gonçalves Valbonetti, ahgvalbonetti@sga.pucminas.br**

**Eduardo Fraga Fonseca Gomes, eduardo.fonseca@sga.pucminas.br**

**Vitor Martins Gonçalves, vitor.goncalves@sga.pucminas.br**

**Gustavo Bacellar Nunes Soares, gbnsoares@sga.pucminas.br**


---

Professores:

**Hugo Bastos de Paula**

**Hayala Nepomuceno Curto**

---

_Curso de Ciência de Dados, Unidade Praça da Liberdade_

_Instituto de Informática e Ciências Exatas – Pontifícia Universidade de Minas Gerais (PUC MINAS), Belo Horizonte – MG – Brasil_

---

**Resumo**. 

Este estudo investiga a disparidade de gênero no setor da tecnologia no Brasil, analisando os desafios enfrentados pelas mulheres. A pesquisa utiliza dados do State of Data Brazil 2023 para identificar diferenças na participação, salários e oportunidades de crescimento entre homens e mulheres no mercado de trabalho de dados. Um dos objetivos será  fornecer dados e insights que possam embasar políticas de inclusão, contribuindo para um mercado de trabalho mais diverso e inovador.

---


## Introdução

  É notório que o pensamento, tanto feminino quanto masculino, apresenta-se extremamente válido para o avanço tecnológico, inclusive no Setor da tecnologia no Brasil. Entretanto, tal realidade apresenta-se desvirtuada e validada por uma análise descritiva que pode ser realizada ao observar o banco de dados servindo como referência para esta pesquisa. Através de uma análise descritiva, esse estudo busca, primeiramente, validar tal infeliz realidade da disparidade (em todas as suas vertentes) de gênero no Setor da tecnologia no Brasil e então, propor alternativas válidas para a promoção da inclusão de gênero equalitária nesse nicho.  
  
  As causas que podem ser inferidas para esse desafio são várias e serão abordadas abaixo. Dentre elas, observa-se o imaginário social enraizado de que mulheres não são tão ábeis em tecnologia quanto os homens, além haver uma ausência de representatividade feminina nesse nicho, fora a dupla-jornada de trabalho que,normalmente, mulheres enfrentam, limitando ainda mais sua capacidade de cresimento, contribuição e evolução nesse ramo.  

  Essa pesquisa é importante uma vez que, com sua validação e correta execução, mais mulheres poderão ter lugar e espaço no Setor da tecnologia no Brasil. Com isso, além de fornecer mais rotatividade de empregos no mercado, mais vidas serão positivamente contribuídas pelo trabalho, com o incentivo, mesmo que sutil, a mais mulheres ingressando nesse ramo, sem haver disparidades, desigualdades ou destratamentos, haverão mais mentes pensantes dentro desse mercado, contribuindo para mais avanços científicos úteis para o mundo e o futuro, os quais podem estar sendo retardados pela presença de desvalorização da força feminina dentro desse mercado, tema pelo qual abordaremos com mais detalhes a seguir.

###    Contextualização

A área de ciência de dados cresce a passos largos, movimentando bilhões e influenciando decisões no mundo todo. Mas, quando olhamos para quem está por trás dessas análises e algoritmos, percebemos uma realidade preocupante: a disparidade de gênero ainda é grande. As mulheres continuam sub-representadas no setor, enfrentando barreiras que vão desde a entrada no mercado até a progressão na carreira.
Os números refletem essa realidade. Pesquisas mostram que a presença feminina na ciência de dados ainda é muito menor do que a masculina, e as chances de ocupar cargos de liderança são ainda mais reduzidas. Entender essa disparidade e buscar soluções para torná-la coisa do passado não é apenas uma questão de justiça – é também uma maneira de tornar o setor mais diverso, inovador e eficiente.

###    Problema

No Brasil, as mulheres que trabalham em setores da Tecnologia são prejudicadas por haver, intrinsicamente, uma disparidade de gênero em seu setor laboral. Tal problema ocorre por um viés social, por exemplo, por meio de esteriótipos sobre empregos ou, também, por um viés econômico, em que as mulheres perdem oportunidades de empregos ou de salários melhores para homens.
Dito isso, observa-se uma notória discrepância de gênero em um mercado de trabalho na área da computação.



###    Objetivo geral

 Desenvolver um sistema inteligente para classificar se a pessoa vai estar empregada ou desempregada conforme o gênero e a região onde ela mora.


####    Objetivos específicos

1- Analisar a distribuição de gênero entre os profissionais do setor de tecnologia

2-Comparar os salários médios entre homens e mulheres no setor de dados

3- Comparar as oportunidades de crescimento entre homens e mulheres no setor de dados

4- Identificar os principais desafios enfrentados por mulheres no setor de dados

5- Comparar a representatividade feminina em cargos de liderança no setor de dados

6- Examinar a relação entre nível de escolaridade e empregabilidade de mulheres no setor

7- Estudar a presença de viés de gênero nos processos seletivos do setor de tecnologia



###    Justificativas

A razão pela a escolha do tema Disparidade de gênero no setor de T.I vem da necessidade de apoiar a igualdade entre gêneros no mercado de dados, 
um lugar que ainda mostra diferenças grandes entre homens e mulheres. Ao olharmos para a diferença por gênero, 
tentamos achar as causas dessas desigualdades e dar números que podem ajudar políticas e ações de inclusão. 



##    Público alvo

O nosso público-alvo são gerentes de empresa que buscam uma menor disparidade de mulheres nos diversos setores da tecnologia, como gerentes de RH e chefes de setor de tecnologia.
Temos como público alvo diretores e coordenadores de instiruições de ensino da área, ja que podemos observar uma grande falta de mulheres nos cursos da área. Além de estudantes que buscam se graduar na área de tecnologia.

###  Personas

1️⃣ Persona: Desenvolvedora Plena em Tecnologia

- Nome: Carla Nunes

- Idade: 29 anos

- Objetivo: Entender se está sendo remunerada de forma justa em comparação aos colegas homens com funções similares.

- Desafios: Dificuldade em acessar dados transparentes e atualizados sobre salários com recorte de gênero.

2️⃣ Persona: Coordenadora de Diversidade e Inclusão

- Nome: Priscila Duarte

- Idade: 35 anos

- Objetivo: Desenvolver políticas internas que reduzam a desigualdade salarial de gênero.

- Desafios: Falta de indicadores específicos sobre mulheres em cargos técnicos e de liderança na empresa.

3️⃣ Persona: Engenheiro de Software Sênior

- Nome: Rafael Lima

- Idade: 41 anos

- Objetivo: Apoiar iniciativas de equidade de gênero no setor, incluindo revisão salarial.

- Desafios: Não tem acesso a comparativos salariais por gênero que possam embasar ações efetivas.

4️⃣ Persona: Consultora de Igualdade de Gênero em ONGs

- Nome: Sônia Ferreira

- Idade: 47 anos

- Objetivo: Promover ações públicas e privadas que eliminem a diferença salarial entre homens e mulheres na tecnologia.

- Desafios: Precisa de estudos aprofundados com dados desagregados por cargo, gênero, região e senioridade.


# Análise Exploratória - Disparidade de Gênero no Mercado de Trabalho

**Hipótese**: Investigar como a disparidade de gênero interfere na situação atual de trabalho conforme a região onde a pessoa mora.

---

###    Dicionário de dados

## Análise de Dados da Pesquisa State of Data BR 2023

## 1. Base de Dados Principal

* **Fonte:** Arquivo CSV 'State_of_data_BR_2023_Kaggle - df_survey_2023.csv' (processado no notebook).
* **Descrição:** Esta base de dados contém informações sobre profissionais e estudantes da área de dados no Brasil em 2023. Os dados foram processados para facilitar a análise, incluindo a seleção de colunas relevantes e a codificação de variáveis categóricas.

## 2. Dicionário de Dados da Base Principal

| Atributo             | Significado                                     | Tipo        |
|----------------------|-------------------------------------------------|-------------|
| Idade                | Idade do respondente.                          | Inteiro     |
| Genero               | Gênero do respondente (codificado).             | Categórico  |
| Cor/raca/etnia       | Cor/raça/etnia do respondente (codificado).     | Categórico  |
| PCD                  | Indica se o respondente é Pessoa com Deficiência (codificado). | Categórico  |
| UF                   | Unidade Federativa onde o respondente mora (codificado). | Categórico  |
| Regiao onde mora     | Região do Brasil onde o respondente mora (codificado). | Categórico  |
| Nível de Ensino      | Nível de ensino do respondente (codificado).    | Categórico  |
| Área de formação     | Área de formação acadêmica do respondente (codificado). | Categórico  |
| Situação de trabalho | Situação atual de trabalho do respondente (codificado). | Categórico  |

**Observação:** No código, as colunas categóricas foram transformadas em tipos `int`. No entanto, do ponto de vista conceitual do dicionário de dados, elas representam categorias, embora armazenadas como números após o processamento.


##  Resumo das Transformações em `base_princ`

Esta seção detalha as transformações aplicadas às colunas da base de dados `base_princ` para converter variáveis categóricas em numéricas.

### 1. Gênero

| Classe Original        | Valor Numérico |
|------------------------|----------------|
| Masculino              | 0              |
| Feminino               | 1              |
| Outro                  | Removido       |

*Linhas com valor “Outro” foram removidas do DataFrame.*

### 2. Cor/Raça/Etnia

| Classe Original        | Valor Numérico |
|------------------------|----------------|
| Branca                 | 0              |
| Preta                  | 1              |
| Amarela                | 2              |
| Parda                  | 3              |
| Indígena               | 4              |
| Prefiro não informar   | 5              |
| Outra                  | 6              |

### 3. PCD (Pessoa com Deficiência)

| Classe Original        | Valor Numérico |
|------------------------|----------------|
| Sim                    | 1              |
| Não                    | 0              |
| Prefiro não informar   | Removido       |

*Linhas com valor “Prefiro não informar” foram removidas do DataFrame.*

### 4. Região onde mora

| Classe Original   | Valor Numérico |
|-------------------|----------------|
| Norte             | 0              |
| Nordeste          | 1              |
| Sudeste           | 2              |
| Sul               | 3              |
| Centro-oeste      | 4              |

### 5. UF (Unidade da Federação)

| UF | Valor Numérico | | UF | Valor Numérico |   | UF | Valor Numérico |   | UF | Valor Numérico |
|----|----------------|---|----|----------------|---|----|----------------|---|----|----------------|
| AC | 0              |   | AL | 1              |   | AP | 2              |   | AM | 3              |
| BA | 4              |   | CE | 5              |   | DF | 6              |   | ES | 7              |
| GO | 8              |   | MA | 9              |   | MT | 10             |   | MS | 11             |
| MG | 12             |   | PA | 13             |   | PB | 14             |   | PR | 15             |
| PE | 16             |   | PI | 17             |   | RJ | 18             |   | RN | 19             |
| RS | 20             |   | RO | 21             |   | RR | 22             |   | SC | 23             |
| SP | 24             |   | SE | 25             |   | TO | 26             |   |    |                |

### 6. Nível de Ensino

| Classe Original             | Valor Numérico |
|-----------------------------|----------------|
| Não tenho graduação formal  | 0              |
| Estudante de Graduação      | 1              |
| Graduação/Bacharelado       | 2              |
| Pós-graduação               | 3              |
| Mestrado                    | 4              |
| Doutorado ou PhD            | 5              |
| Prefiro não informar        | 6              |

### 7. Área de Formação

| Classe Original                                                                | Valor Numérico |
|--------------------------------------------------------------------------------|----------------|
| Computação / Engenharia / Sistemas de Informação / TI                            | 0              |
| Economia / Administração / Contabilidade / Finanças / Negócios                   | 1              |
| Outras Engenharias                                       | 2 / 8          |
| Química / Física                                                               | 3              |
| Estatística / Matemática / Ciências Atuariais                                  | 4              |
| Marketing / Publicidade / Comunicação / Jornalismo                             | 5              |
| Ciências Sociais                                                               | 6              |
| Ciências Biológicas / Farmácia / Medicina / Área da Saúde                      | 7              |
| Outra opção                                                                    | 0  |

 **Observações:**

* A categoria "Outras Engenharias" foi removida, pois não há dados nessa classe; 'nan' - nulos.
* "Outra opção" recebeu o mesmo valor que "Computação / Engenharia / Sistemas de Informação / TI" (0), pois a moda da àrea de fomação era a classe '0', então atribui 'Outra opção' a essa classe.
* Linhas com valores NaN nesta coluna foram removidas durante o processamento.

### 8. Situação de Trabalho

| Classe Original                                                                 | Valor Final      | Valor Numérico |
|---------------------------------------------------------------------------------|------------------|----------------|
| Empregado (CLT)                                                                 | Empregado(a)     | 0              |
| Empreendedor ou Empregado (CNPJ)                                                | Empregado(a)     | 0              |
| Estagiário                                                                      | Empregado(a)     | 0              |
| Trabalho na área Acadêmica/Pesquisador                                          | Empregado(a)     | 0              |
| Servidor Público                                                                | Empregado(a)     | 0              |
| Vivo no Brasil e trabalho remoto para empresa de fora do Brasil                 | Empregado(a)     | 0              |
| Vivo fora do Brasil e trabalho para empresa de fora do Brasil                   | Empregado(a)     | 0              |
| Freelancer                                                                      | Empregado(a)     | 0              |
| Desempregado, buscando recolocação                                              | Desempregado(a)  | 1              |
| Desempregado e não estou buscando recolocação                                   | Desempregado(a)  | 1              |
| Somente Estudante (graduação ou pós-graduação)                                  | Desempregado(a)  | 1              |
| Prefiro não informar                                                            | Desempregado(a)  | 1              |



## 3. Análise Descritiva dos Dados utilizando Estatísticas de Primeira Ordem

* **Descrição:** Esta seção apresenta uma análise descritiva das colunas da base de dados processada (`base_princ`), utilizando estatísticas de primeira ordem para descrever a distribuição e as características dos dados.

## Descrição de Dados Numéricos

As colunas na base de dados processada foram convertidas para o tipo `int` após a codificação das variáveis categóricas. Embora representem categorias, sua análise estatística descritiva pode fornecer insights sobre a distribuição dos valores codificados. A coluna 'Idade' é a única numérica original antes do processamento extenso das demais colunas.

Para dados numéricos, as estatísticas de primeira ordem incluem:

* **Média:** Medida de tendência central.
* **Mediana:** Valor central dos dados ordenados.
* **Moda:** Valor mais frequente nos dados.
* **Desvio Padrão:** Medida de dispersão dos dados em torno da média.
* **Variância:** Quadrado do desvio padrão, outra medida de dispersão.
* **Mínimo e Máximo:** Limites inferior e superior dos dados.
* **Quartis:** Valores que dividem os dados em quatro partes iguais (25%, 50% - mediana, 75%).

Considerando a saída do seu código para a análise estatística, podemos descrever cada coluna:

### Análise da Coluna 'Idade'

* **Média:** 31.96 anos.
* **Mediana:** 30.00 anos.
* **Moda:** 27.00 anos (o valor mais frequente de idade).
* **Desvio Padrão:** 7.55 anos (indica a dispersão das idades em torno da média).
* **Mínimo:** 18.00 anos.
* **Máximo:** 73.00 anos.
* **Quartis:** 25% dos respondentes têm 27 anos ou menos, 50% têm 30 anos ou menos, e 75% têm 36 anos ou menos.

### Análise da Coluna 'Genero'

* **Média:** 0.25 (considerando a codificação, indica a proporção relativa entre os gêneros).
* **Mediana:** 0.00.
* **Moda:** 1.00 (o gênero com maior frequência na codificação).
* **Desvio Padrão:** 0.43.
* **Mínimo:** 0.00.
* **Máximo:** 1.00.
* **Quartis:** 75% dos valores codificados de gênero são 0.

### Análise da Coluna 'Cor/raca/etnia'

* **Média:** 0.91 (valor médio da codificação da cor/raça/etnia).
* **Mediana:** 0.00.
* **Moda:** 3.00 (a cor/raça/etnia com maior frequência na codificação).
* **Desvio Padrão:** 1.34.
* **Mínimo:** 0.00.
* **Máximo:** 6.00.
* **Quartis:** 75% dos valores codificados de cor/raça/etnia são 3 ou menos.

### Análise da Coluna 'PCD'

* **Média:** 0.02 (indica a proporção de respondentes que se identificam como PCD na codificação).
* **Mediana:** 0.00.
* **Moda:** 1.00 (a categoria de PCD com maior frequência na codificação).
* **Desvio Padrão:** 0.14.
* **Mínimo:** 0.00.
* **Máximo:** 1.00.
* **Quartis:** 75% dos valores codificados para PCD são 0.

### Análise da Coluna 'UF'

* **Média:** 17.87 (valor médio da codificação da Unidade Federativa).
* **Mediana:** 20.00.
* **Moda:** 24.00 (a UF com maior frequência na codificação).
* **Desvio Padrão:** 6.71.
* **Mínimo:** 1.00.
* **Máximo:** 26.00.
* **Quartis:** 25% dos respondentes moram em UFs codificadas como 12 ou menos, 50% em UFs codificadas como 20 ou menos, e 75% em UFs codificadas como 24 ou menos.

### Análise da Coluna 'Regiao onde mora'

* **Média:** 2.17 (valor médio da codificação da região).
* **Mediana:** 2.00.
* **Moda:** 2.00 (a região com maior frequência na codificação).
* **Desvio Padrão:** 0.77.
* **Mínimo:** 0.00.
* **Máximo:** 4.00.
* **Quartis:** 75% dos respondentes moram em regiões codificadas como 3 ou menos.

### Análise da Coluna 'Nível de Ensino'

* **Média:** 2.59 (valor médio da codificação do nível de ensino).
* **Mediana:** 3.00.
* **Moda:** 3.00 (o nível de ensino com maior frequência na codificação).
* **Desvio Padrão:** 1.00.
* **Mínimo:** 1.00.
* **Máximo:** 5.00.
* **Quartis:** 75% dos respondentes têm nível de ensino codificado como 3 ou menos.

### Análise da Coluna 'Área de formação'

* **Média:** 1.32 (valor médio da codificação da área de formação).
* **Mediana:** 1.00.
* **Moda:** 2.00 (a área de formação com maior frequência na codificação).
* **Desvio Padrão:** 1.72.
* **Mínimo:** 0.00.
* **Máximo:** 7.00.
* **Quartis:** 75% dos respondentes têm área de formação codificada como 2 ou menos.

### Análise da Coluna 'Situação de trabalho'

* **Média:** 0.09 (indica a proporção de respondentes em uma das categorias de situação de trabalho na codificação).
* **Mediana:** 0.00.
* **Moda:** 1.00 (a situação de trabalho com maior frequência na codificação).
* **Desvio Padrão:** 0.28.
* **Mínimo:** 0.00.
* **Máximo:** 1.00.
* **Quartis:** 75% dos valores codificados para situação de trabalho são 0.

**Observação:** É crucial lembrar que a interpretação dessas estatísticas para as colunas codificadas deve ser feita com cautela, pois os números representam categorias e não possuem uma escala numérica inerente. A análise é mais útil para entender a distribuição dos códigos dentro de cada coluna. Para a coluna 'Idade', a interpretação é direta, pois se trata de uma variável numérica contínua.



## Preparação dos Dados

A fase de preparação dos dados é crucial para garantir a qualidade e adequação do dataset para a análise. Neste projeto, a preparação dos dados consistiu nos seguintes passos:

### Seleção dos Atributos

Com base no objetivo da análise e na hipótese a ser investigada, foi realizada a seleção manual dos atributos relevantes do dataset original. Os atributos selecionados para compor a base de dados principal foram:

* Idade
* Genero
* Cor/raca/etnia
* PCD (Pessoa com Deficiência)
* UF (Unidade Federativa)
* Regiao onde mora
* Nível de Ensino
* Área de formação
* Situação de trabalho

Estes atributos foram considerados essenciais para explorar as relações entre gênero, situação de trabalho e localização geográfica, além de fornecerem contexto demográfico e educacional dos respondentes.

### Tratamento dos Valores Faltantes ou Omissos

A presença de valores faltantes ou omissos nos dados pode impactar a análise. No processo de preparação, identificamos e tratamos esses valores:

* **Identificação de Nulos:** Foi realizada a contagem de valores nulos em cada coluna para entender a extensão do problema.
* **Remoção de Nulos na Coluna 'UF':** A coluna 'UF' (Unidade Federativa) é fundamental para a análise regional da hipótese. Dada a importância dessa informação, optou-se por remover as linhas que apresentavam valores nulos nesta coluna.

### Tratamento dos Valores Inconsistentes

Valores inconsistentes podem distorcer os resultados da análise. Foram realizados tratamentos específicos para lidar com inconsistências identificadas:

* **Tratamento na Coluna 'Genero':** As categorias 'Outro' e 'Prefiro não informar' na coluna 'Genero' foram identificadas como inconsistentes para a análise de disparidade de gênero binária. Essas linhas foram removidas do dataset.
* **Tratamento na Coluna 'PCD':** Similarmente, as linhas onde a coluna 'PCD' apresentava o valor 'Prefiro não informar' foram removidas, pois não era possível inferir a informação de deficiência a partir desse valor.
* **Tratamento na Coluna 'Área de formação':** Foram identificados valores nulos (NaN) na coluna 'Área de formação' após o mapeamento, o que indicava a falta de informação para algumas entradas. As linhas com valores nulos nesta coluna também foram removidas.
* **Agrupamento na Coluna 'Situação de trabalho':** As diversas categorias de situação de trabalho foram agrupadas em duas categorias principais: 'Empregado(a)' e 'Desempregado(a)'. Este agrupamento simplifica a análise e foca na dicotomia emprego/desemprego. (É importante verificar e corrigir quaisquer erros de digitação durante este agrupamento).
* **Tratamento de Mapeamentos Duplicados/Inconsistentes:** Durante a codificação de variáveis categóricas, foi observado que a categoria 'Outras Engenharias' na coluna 'Área de formação' foi mapeada para dois valores diferentes (2 e 8), e 'Outra opção' foi mapeada para o mesmo valor que 'Computação / Engenharia...' (0). Embora o código original mostre esses mapeamentos, para uma análise precisa, estes devem ser revisados e corrigidos para garantir a unicidade dos códigos para cada categoria.

### Conversão de Dados

Para facilitar a análise e a aplicação de métodos estatísticos, as variáveis categóricas foram convertidas para um formato numérico:

* **Codificação Manual:** As categorias em colunas como 'Genero', 'Cor/raca/etnia', 'PCD', 'UF', 'Regiao onde mora', 'Nível de Ensino', 'Área de formação' e 'Situação de trabalho' foram mapeadas manualmente para valores inteiros específicos. Esta abordagem preserva a informação de qual número corresponde a qual categoria original.
* **Conversão para Tipo Numérico:** Após o mapeamento manual, as colunas foram convertidas para o tipo de dado inteiro (`int`) para que pudessem ser tratadas como dados numéricos em análises posteriores.


## Indução de modelos

### Modelo 1: Árvore de Decisão

## Justificativa da escolha do modelo:

A **Árvore de Decisão** é uma escolha adequada para este problema devido à sua interpretabilidade e relativa simplicidade. Ela permite visualizar o processo de tomada de decisão do modelo, o que facilita a explicação dos resultados. Além disso, a Árvore de Decisão é capaz de lidar com dados categóricos e numéricos, o que parece ser o caso dos seus dados.

## Processo utilizado para amostragem de dados:

Você utilizou a técnica de **particionamento** para dividir seus dados. Especificamente, o conjunto de dados original foi dividido em conjuntos de treino e teste utilizando a função `train_test_split` da biblioteca `sklearn.model_selection`. A proporção utilizada foi de **75%** dos dados para treino (`X_treino`, `y_treino`) e **25%** para teste (`X_teste`, `y_teste`). O parâmetro `random_state=42` garante que a divisão seja consistente a cada execução, tornando os resultados reproduzíveis.

Para a otimização de hiperparâmetros com `GridSearchCV`, você empregou **validação cruzada (cross-validation)** com `cv=5`. Isso significa que o conjunto de treino foi dividido em 5 partes (folds). O modelo foi treinado em 4 partes e avaliado na parte restante, repetindo esse processo 5 vezes, cada vez utilizando uma parte diferente para avaliação. Essa abordagem fornece uma estimativa mais robusta do desempenho do modelo e ajuda a mitigar o overfitting.

## Parâmetros utilizados:

No modelo inicial (`modelo`), você utilizou os seguintes parâmetros:

* `criterion='gini'`: Define a função para medir a qualidade de uma divisão, utilizando o índice Gini como medida de impureza.
* `max_depth=5`: Limita a profundidade máxima da árvore para ajudar a prevenir o overfitting.
* `min_samples_leaf=5`: Define o número mínimo de amostras necessárias para estar em um nó folha.
* `min_samples_split=10`: Especifica o número mínimo de amostras necessárias para dividir um nó interno.
* `random_state=42`: Garante a reproduzibilidade dos resultados ao fixar o gerador de números aleatórios.

No processo de otimização com `GridSearchCV`, você explorou a seguinte grade de parâmetros para encontrar a melhor combinação:

* `criterion`: `['gini', 'entropy']` (Índice Gini ou Ganho de Informação).
* `max_depth`: `[3, 5, 7, 9, 11, None]` (Diferentes profundidades máximas, incluindo a opção de não ter limite).
* `min_samples_leaf`: `[1, 3, 5, 10]` (Diferentes números mínimos de amostras em um nó folha).
* `min_samples_split`: `[5, 15, 25]` (Diferentes números mínimos de amostras para dividir um nó).
* `class_weight`: `[None, 'balanced', {0: 1, 1: 5}, {0: 1, 1: 10}]` (Pesos para as classes, útil para lidar com conjuntos de dados desbalanceados).

O `GridSearchCV` identificou os `best_params_` (melhores hiperparâmetros), que foram impressos na saída do seu código.

## Trechos de código utilizados comentados:

```python
# Importação de bibliotecas essenciais para manipulação de dados e machine learning
import pandas as pd  # Para trabalhar com DataFrames
import seaborn as sns  # Para visualizações estatísticas (não usado diretamente para o modelo, mas útil para EDA)
from sklearn import tree  # Módulo para árvores de decisão
import matplotlib.pyplot as plt  # Para gerar gráficos

# Módulos específicos do scikit-learn para o modelo de árvore de decisão, divisão de dados e avaliação
from sklearn.tree import DecisionTreeClassifier, plot_tree  # Classe para a árvore e função para plotar
from sklearn.model_selection import train_test_split, GridSearchCV  # Funções para dividir dados e otimização
from sklearn.preprocessing import LabelEncoder  # Para codificar rótulos (não usado diretamente no código compartilhado, mas comum)
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, make_scorer, f1_score  # Métricas de avaliação

# Módulo para visualização da matriz de confusão de forma mais interativa
from yellowbrick.classifier import ConfusionMatrix

# Carregamento dos dados a partir de um arquivo CSV
base_treino = pd.read_csv("base_princ_modificado.csv")

# Exibindo as primeiras linhas e estatísticas descritivas para entender os dados
print("Primeiras linhas do DataFrame:")
display(base_treino.head())

print("\nEstatísticas descritivas do DataFrame:")
display(base_treino.describe())

# Verificando a distribuição da variável alvo para identificar desbalanceamento
print("\nDistribuição das classes na variável alvo:")
print(base_treino['Situação de trabalho'].value_counts())

# Separando as features (X) e a variável alvo (y)
X = base_treino.drop(columns=['Situação de trabalho'])  # Remove a coluna alvo para obter as features
y = base_treino['Situação de trabalho']  # Seleciona a coluna alvo

# Dividindo os dados em conjuntos de treino e teste (75% treino, 25% teste)
X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=42)

# Inicializando o modelo de Árvore de Decisão com parâmetros iniciais
modelo = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf=5, min_samples_split=10, random_state=42)

# Treinando o modelo com os dados de treino
modelo.fit(X_treino, y_treino)

# Realizando previsões no conjunto de teste
previsoes = modelo.predict(X_teste)

# Avaliando o desempenho do modelo inicial utilizando métricas comuns
print("Acurácia do modelo inicial:", accuracy_score(y_teste, previsoes))
print("\nRelatório de Classificação do modelo inicial:")
print(classification_report(y_teste, previsoes))
print("\nMatriz de Confusão do modelo inicial:")
print(confusion_matrix(y_teste, previsoes))

# Visualizando a Matriz de Confusão usando a biblioteca Yellowbrick
cm = ConfusionMatrix(modelo)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)
plt.title("Matriz de Confusão (Modelo Inicial)")
plt.show()

# --- Seção para Otimização de Hiperparâmetros com GridSearchCV ---

print("\n--- Abordagem: Ajuste de Hiperparâmetros com GridSearchCV ---")

# Definindo a grade de parâmetros a serem testados no GridSearchCV
param_grid = {
    'criterion': ['gini', 'entropy'],  # Funções de critério
    'max_depth': [3, 5, 7, 9, 11, None],  # Profundidades máximas
    'min_samples_leaf': [1, 3, 5, 10],  # Mínimo de amostras em um nó folha
    'min_samples_split': [5, 15, 25],  # Mínimo de amostras para dividir um nó
    'class_weight': [None, 'balanced', {0: 1, 1: 5}, {0: 1, 1: 10}]  # Pesos para as classes
}

# Criando um scorer personalizado para focar na métrica F1-score da classe 1
f1_classe1_scorer = make_scorer(f1_score, labels=[1], average='weighted')

# Inicializando o GridSearchCV com o modelo base, a grade de parâmetros, validação cruzada e o scorer personalizado
grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring=f1_classe1_scorer)

# Executando a busca em grade para encontrar a melhor combinação de parâmetros
grid_search.fit(X_treino, y_treino)

# Imprimindo os melhores parâmetros encontrados pelo GridSearchCV
print("\nMelhores hiperparâmetros encontrados (foco na classe 1):", grid_search.best_params_)

# Obtendo o melhor modelo encontrado pelo GridSearchCV
melhor_modelo_grid = grid_search.best_estimator_

# Avaliando o melhor modelo nos conjuntos de treino e teste
previsoes_grid = melhor_modelo_grid.predict(X_teste)
print("\nAcurácia do melhor modelo (GridSearchCV - Treino):", accuracy_score(y_treino, melhor_modelo_grid.predict(X_treino)))
print("\nAcurácia do melhor modelo (GridSearchCV - Teste):", accuracy_score(y_teste, previsoes_grid))
print("\nAvaliação do melhor modelo (GridSearchCV - foco na classe 1):")
print(f"Acurácia: {accuracy_score(y_teste, previsoes_grid)}")
print("\nRelatório de Classificação:")
print(classification_report(y_teste, previsoes_grid))
print("\nMatriz de Confusão:")
print(confusion_matrix(y_teste, previsoes_grid))

# Visualizando a Matriz de Confusão do melhor modelo com Yellowbrick
cm_grid = ConfusionMatrix(melhor_modelo_grid)
cm_grid.fit(X_treino, y_treino)
cm_grid.score(X_teste, y_teste)
plt.title("Matriz de Confusão (GridSearchCV - Foco Classe 1)")
plt.show()

# Visualizando a árvore de decisão do melhor modelo encontrado pelo GridSearchCV
previsores_grid = X_treino.columns  # Nomes das features
class_names_grid = [str(c) for c in melhor_modelo_grid.classes_]  # Nomes das classes

figura_grid, eixos_grid = plt.subplots(nrows=1, ncols=1, figsize=(30, 20))  # Cria uma figura para plotar
tree.plot_tree(melhor_modelo_grid, feature_names=previsores_grid, class_names = class_names_grid, filled=True, fontsize=10);  # Plota a árvore
plt.title("Árvore de Decisão (GridSearchCV - Foco Classe 1)")  # Título do gráfico
plt.show()  # Exibe o gráfico

# Avaliando a acurácia do modelo inicial nos conjuntos de treino e teste novamente para comparação
acuracia_treino = accuracy_score(y_treino, modelo.predict(X_treino))
print(f"\nAcurácia do modelo no conjunto de treino: {acuracia_treino:.4f}")

acuracia_teste = accuracy_score(y_teste, previsoes)
print(f"Acurácia do modelo no conjunto de teste: {acuracia_teste:.4f}")

Substitua o título pelo nome do algoritmo que será utilizado. P. ex. árvore de decisão, rede neural, SVM, etc.
Justifique a escolha do modelo.
Apresente o processo utilizado para amostragem de dados (particionamento, cross-validation).
Descreva os parâmetros utilizados. 
Apresente trechos do código utilizado comentados. Se utilizou alguma ferramenta gráfica, apresente imagens
com o fluxo de processamento.
```

### Modelo 2: Algoritmo

Repita os passos anteriores para o segundo modelo.


## Resultados

### Resultados obtidos com o modelo 1.
Observação: Fiz duas avaliações utilizando métricas diferentes, com isso obtive diferentes resultados:
Primeira métrica eu obtive uma maior acurácia e precisão e recall em ambas as classes(Empregado(a) e Desempregado(a)). Porém percebi que o modelo estava priorizando mais a classe majoritária(Empregado(a)), por haver cerca de 10 vezes mais dados em relação a outra. Segue as duas avaliações...

## Avaliação 01:

![download](https://github.com/user-attachments/assets/5115c49f-02eb-401a-bcdf-45a15cb8fd97)

![image](https://github.com/user-attachments/assets/1be4f89d-eb49-439d-a813-07189919b766)

## Acurácia do Modelo Inicial:

`0.9115537848605577`

## Relatório de Classificação do Modelo Inicial:

|               | precision | recall | f1-score | support |
|---------------|-----------|--------|----------|---------|
| 0             | 0.91      | 1.00   | 0.95     | 1146    |
| 1             | 0.33      | 0.02   | 0.03     | 109     |
| **accuracy** |           |        | **0.91** | **1255**|
| **macro avg** | 0.62      | 0.51   | 0.49     | 1255    |
| **weighted avg**| 0.86      | 0.91   | 0.87     | 1255    |

## Acurácia nos Conjuntos de Treino e Teste:

* **Acurácia de treino:** `0.9133`
* **Acurácia de teste:** `0.9116`


## Avaliação 02:

Utilizei muitos hiperparâmetros para tentar balancear os dados e fornecer uma maior importância para a classe minoritária, tendo como resultado um maior balanceameno dos dados. porém o resultado(acurácia) diminuiu significadamente, e a classificação preditiva de meus dados não foram satisfatórias. Nesse quesito, utilizei LLM para me sugerir mudanças, e por fim, elas me sugeriram testar com um novo modelo, como a Random Forest, o qual foi utilizado no modelo 2.

![download](https://github.com/user-attachments/assets/103ff659-4ef6-4e01-89d5-78b794261d50)

![download](https://github.com/user-attachments/assets/7634ae46-a069-44f1-be2a-9fdd646e07ba)

## --- Abordagem: Ajuste de Hiperparâmetros com GridSearchCV ---

**Melhores hiperparâmetros encontrados (foco na classe 1):**
{'class_weight': {0: 1, 1: 10}, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}


**Acurácia do melhor modelo (GridSearchCV - Treino):** `0.7102604997341839`

**Acurácia do melhor modelo (GridSearchCV - Teste):** `0.6772908366533864`

**Avaliação do melhor modelo (GridSearchCV - foco na classe 1):**
Acurácia: 0.6772908366533864


**Relatório de Classificação:**

|               | precision | recall | f1-score | support |
|---------------|-----------|--------|----------|---------|
| 0             | 0.93      | 0.70   | 0.80     | 1146    |
| 1             | 0.13      | 0.47   | 0.20     | 109     |
| **accuracy** |           |        | **0.68** | **1255**|
| **macro avg** | 0.53      | 0.58   | 0.50     | 1255    |
| **weighted avg**| 0.86      | 0.68   | 0.75     | 1255    |

Ao otimizar o modelo com o f1_score ponderado para a classe 1 no GridSearchCV, você estava explicitamente instruindo o algoritmo a encontrar parâmetros que equilibrassem a precisão e o recall da classe "Desempregadas", dando maior peso à capacidade do modelo de identificar todas as instâncias dessa classe. Os resultados mostram que, embora o recall da classe 1 tenha melhorado em relação a um modelo puramente focado na acurácia geral, ainda há um trade-off com a precisão dessa classe.


### Interpretação do modelo 1

Apresente os parâmetros do modelo obtido. Tentre mostrar as regras que são utilizadas no
processo de 'raciocínio' (*reasoning*) do sistema inteligente. Utilize medidas como 
o *feature importances* para tentar entender quais atributos o modelo se baseia no
processo de tomada de decisão.


### Resultados obtidos com o modelo 2.

Repita o passo anterior com os resultados do modelo 2.

### Interpretação do modelo 2

Repita o passo anterior com os parâmetros do modelo 2.


## Análise comparativa dos modelos

Discuta sobre as forças e fragilidades de cada modelo. Exemplifique casos em que um
modelo se sairia melhor que o outro. Nesta seção é possível utilizar a sua imaginação
e extrapolar um pouco o que os dados sugerem.


### Distribuição do modelo (opcional)

Tende criar um pacote de distribuição para o modelo construído, para ser aplicado 
em um sistema inteligente.


## 8. Conclusão

Apresente aqui a conclusão do seu trabalho. Discussão dos resultados obtidos no trabalho, 
onde se verifica as observações pessoais de cada aluno.

Uma conclusão deve ter 3 partes:

   * Breve resumo do que foi desenvolvido
	 * Apresenação geral dos resultados obtidos com discussão das vantagens e desvantagens do sistema inteligente
	 * Limitações e possibilidades de melhoria


# REFERÊNCIAS

Como um projeto de sistema inteligente não requer revisão bibliográfica, 
a inclusão das referências não é obrigatória. No entanto, caso você 
tenha utilizado referências na introdução ou deseje 
incluir referências relacionadas às tecnologias, padrões, ou metodologias 
que serão usadas no seu trabalho, relacione-as de acordo com a ABNT.

Verifique no link abaixo como devem ser as referências no padrão ABNT:

http://www.pucminas.br/imagedb/documento/DOC\_DSC\_NOME\_ARQUI20160217102425.pdf

Por exemplo:

**[1]** - _ELMASRI, Ramez; NAVATHE, Sham. **Sistemas de banco de dados**. 7. ed. São Paulo: Pearson, c2019. E-book. ISBN 9788543025001._

**[2]** - _COPPIN, Ben. **Inteligência artificial**. Rio de Janeiro, RJ: LTC, c2010. E-book. ISBN 978-85-216-2936-8._

**[3]** - _CORMEN, Thomas H. et al. **Algoritmos: teoria e prática**. Rio de Janeiro, RJ: Elsevier, Campus, c2012. xvi, 926 p. ISBN 9788535236996._

**[4]** - _SUTHERLAND, Jeffrey Victor. **Scrum: a arte de fazer o dobro do trabalho na metade do tempo**. 2. ed. rev. São Paulo, SP: Leya, 2016. 236, [4] p. ISBN 9788544104514._

**[5]** - _RUSSELL, Stuart J.; NORVIG, Peter. **Inteligência artificial**. Rio de Janeiro: Elsevier, c2013. xxi, 988 p. ISBN 9788535237016._



# APÊNDICES

**Colocar link:**

Do código (armazenado no repositório);

Dos artefatos (armazenado do repositório);

Da apresentação final (armazenado no repositório);

Do vídeo de apresentação (armazenado no repositório).
