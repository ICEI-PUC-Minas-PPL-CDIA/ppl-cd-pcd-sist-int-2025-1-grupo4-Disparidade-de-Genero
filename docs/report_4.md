# Disparidade de Gênero no Setor da Tecnologia


**Pedro Lansdowne Oliveira, pedro.lansdowne@sga.pucminas.br**

**Leonardo Andrade Caetano Dornelas, lacdornelas@sga.pucminas.br**

**Augusto Henrique Gonçalves Valbonetti, ahgvalbonetti@sga.pucminas.br**

**Eduardo Fraga Fonseca Gomes, eduardo.fonseca@sga.pucminas.br**

**Vitor Martins Gonçalves, vitor.goncalves@sga.pucminas.br**

**Gustavo Bacellar Nunes Soares, gbnsoares@sga.pucminas.br**


---

Professores:

**Hugo Bastos de Paula**

**Hayala Nepomuceno Curto**

---

_Curso de Ciência de Dados, Unidade Praça da Liberdade_

_Instituto de Informática e Ciências Exatas – Pontifícia Universidade de Minas Gerais (PUC MINAS), Belo Horizonte – MG – Brasil_

---

**Resumo**. 

Este estudo investiga a disparidade de gênero no setor da tecnologia no Brasil, analisando os desafios enfrentados pelas mulheres. A pesquisa utiliza dados do State of Data Brazil 2023 para identificar diferenças na participação, salários e oportunidades de crescimento entre homens e mulheres no mercado de trabalho de dados. Um dos objetivos será  fornecer dados e insights que possam embasar políticas de inclusão, contribuindo para um mercado de trabalho mais diverso e inovador.

---


## Introdução

  É notório que o pensamento, tanto feminino quanto masculino, apresenta-se extremamente válido para o avanço tecnológico, inclusive no Setor da tecnologia no Brasil. Entretanto, tal realidade apresenta-se desvirtuada e validada por uma análise descritiva que pode ser realizada ao observar o banco de dados servindo como referência para esta pesquisa. Através de uma análise descritiva, esse estudo busca, primeiramente, validar tal infeliz realidade da disparidade (em todas as suas vertentes) de gênero no Setor da tecnologia no Brasil e então, propor alternativas válidas para a promoção da inclusão de gênero equalitária nesse nicho.  
  
  As causas que podem ser inferidas para esse desafio são várias e serão abordadas abaixo. Dentre elas, observa-se o imaginário social enraizado de que mulheres não são tão ábeis em tecnologia quanto os homens, além haver uma ausência de representatividade feminina nesse nicho, fora a dupla-jornada de trabalho que,normalmente, mulheres enfrentam, limitando ainda mais sua capacidade de cresimento, contribuição e evolução nesse ramo.  

  Essa pesquisa é importante uma vez que, com sua validação e correta execução, mais mulheres poderão ter lugar e espaço no Setor da tecnologia no Brasil. Com isso, além de fornecer mais rotatividade de empregos no mercado, mais vidas serão positivamente contribuídas pelo trabalho, com o incentivo, mesmo que sutil, a mais mulheres ingressando nesse ramo, sem haver disparidades, desigualdades ou destratamentos, haverão mais mentes pensantes dentro desse mercado, contribuindo para mais avanços científicos úteis para o mundo e o futuro, os quais podem estar sendo retardados pela presença de desvalorização da força feminina dentro desse mercado, tema pelo qual abordaremos com mais detalhes a seguir.

###    Contextualização

A área de ciência de dados cresce a passos largos, movimentando bilhões e influenciando decisões no mundo todo. Mas, quando olhamos para quem está por trás dessas análises e algoritmos, percebemos uma realidade preocupante: a disparidade de gênero ainda é grande. As mulheres continuam sub-representadas no setor, enfrentando barreiras que vão desde a entrada no mercado até a progressão na carreira.
Os números refletem essa realidade. Pesquisas mostram que a presença feminina na ciência de dados ainda é muito menor do que a masculina, e as chances de ocupar cargos de liderança são ainda mais reduzidas. Entender essa disparidade e buscar soluções para torná-la coisa do passado não é apenas uma questão de justiça – é também uma maneira de tornar o setor mais diverso, inovador e eficiente.

###    Problema

No Brasil, as mulheres que trabalham em setores da Tecnologia são prejudicadas por haver, intrinsicamente, uma disparidade de gênero em seu setor laboral. Tal problema ocorre por um viés social, por exemplo, por meio de esteriótipos sobre empregos ou, também, por um viés econômico, em que as mulheres perdem oportunidades de empregos ou de salários melhores para homens.
Dito isso, observa-se uma notória discrepância de gênero em um mercado de trabalho na área da computação.



###    Objetivo geral

 Desenvolver um sistema inteligente para classificar se a pessoa vai estar empregada ou desempregada conforme o gênero e a região onde ela mora.


####    Objetivos específicos

1- Analisar a distribuição de gênero entre os profissionais do setor de tecnologia

2-Comparar os salários médios entre homens e mulheres no setor de dados

3- Comparar as oportunidades de crescimento entre homens e mulheres no setor de dados

4- Identificar os principais desafios enfrentados por mulheres no setor de dados

5- Comparar a representatividade feminina em cargos de liderança no setor de dados

6- Examinar a relação entre nível de escolaridade e empregabilidade de mulheres no setor

7- Estudar a presença de viés de gênero nos processos seletivos do setor de tecnologia



###    Justificativas

A razão pela a escolha do tema Disparidade de gênero no setor de T.I vem da necessidade de apoiar a igualdade entre gêneros no mercado de dados, 
um lugar que ainda mostra diferenças grandes entre homens e mulheres. Ao olharmos para a diferença por gênero, 
tentamos achar as causas dessas desigualdades e dar números que podem ajudar políticas e ações de inclusão. 



##    Público alvo

O nosso público-alvo são gerentes de empresa que buscam uma menor disparidade de mulheres nos diversos setores da tecnologia, como gerentes de RH e chefes de setor de tecnologia.
Temos como público alvo diretores e coordenadores de instiruições de ensino da área, ja que podemos observar uma grande falta de mulheres nos cursos da área. Além de estudantes que buscam se graduar na área de tecnologia.

###  Personas

1️⃣ Persona: Desenvolvedora Plena em Tecnologia

- Nome: Carla Nunes

- Idade: 29 anos

- Objetivo: Entender se está sendo remunerada de forma justa em comparação aos colegas homens com funções similares.

- Desafios: Dificuldade em acessar dados transparentes e atualizados sobre salários com recorte de gênero.

2️⃣ Persona: Coordenadora de Diversidade e Inclusão

- Nome: Priscila Duarte

- Idade: 35 anos

- Objetivo: Desenvolver políticas internas que reduzam a desigualdade salarial de gênero.

- Desafios: Falta de indicadores específicos sobre mulheres em cargos técnicos e de liderança na empresa.

3️⃣ Persona: Engenheiro de Software Sênior

- Nome: Rafael Lima

- Idade: 41 anos

- Objetivo: Apoiar iniciativas de equidade de gênero no setor, incluindo revisão salarial.

- Desafios: Não tem acesso a comparativos salariais por gênero que possam embasar ações efetivas.

4️⃣ Persona: Consultora de Igualdade de Gênero em ONGs

- Nome: Sônia Ferreira

- Idade: 47 anos

- Objetivo: Promover ações públicas e privadas que eliminem a diferença salarial entre homens e mulheres na tecnologia.

- Desafios: Precisa de estudos aprofundados com dados desagregados por cargo, gênero, região e senioridade.


# Análise Exploratória - Disparidade de Gênero no Mercado de Trabalho

**Hipótese**: Investigar como a disparidade de gênero interfere na situação atual de trabalho conforme a região onde a pessoa mora.

---

###    Dicionário de dados

## Análise de Dados da Pesquisa State of Data BR 2023

## 1. Base de Dados Principal

* **Fonte:** Arquivo CSV 'State_of_data_BR_2023_Kaggle - df_survey_2023.csv' (processado no notebook).
* **Descrição:** Esta base de dados contém informações sobre profissionais e estudantes da área de dados no Brasil em 2023. Os dados foram processados para facilitar a análise, incluindo a seleção de colunas relevantes e a codificação de variáveis categóricas.

## 2. Dicionário de Dados da Base Principal

| Atributo             | Significado                                     | Tipo        |
|----------------------|-------------------------------------------------|-------------|
| Idade                | Idade do respondente.                          | Inteiro     |
| Genero               | Gênero do respondente (codificado).             | Categórico  |
| Cor/raca/etnia       | Cor/raça/etnia do respondente (codificado).     | Categórico  |
| PCD                  | Indica se o respondente é Pessoa com Deficiência (codificado). | Categórico  |
| UF                   | Unidade Federativa onde o respondente mora (codificado). | Categórico  |
| Regiao onde mora     | Região do Brasil onde o respondente mora (codificado). | Categórico  |
| Nível de Ensino      | Nível de ensino do respondente (codificado).    | Categórico  |
| Área de formação     | Área de formação acadêmica do respondente (codificado). | Categórico  |
| Situação de trabalho | Situação atual de trabalho do respondente (codificado). | Categórico  |

**Observação:** No código, as colunas categóricas foram transformadas em tipos `int`. No entanto, do ponto de vista conceitual do dicionário de dados, elas representam categorias, embora armazenadas como números após o processamento.


##  Resumo das Transformações em `base_princ`

Esta seção detalha as transformações aplicadas às colunas da base de dados `base_princ` para converter variáveis categóricas em numéricas.

### 1. Gênero

| Classe Original        | Valor Numérico |
|------------------------|----------------|
| Masculino              | 0              |
| Feminino               | 1              |
| Outro                  | Removido       |

*Linhas com valor “Outro” foram removidas do DataFrame.*

### 2. Cor/Raça/Etnia

| Classe Original        | Valor Numérico |
|------------------------|----------------|
| Branca                 | 0              |
| Preta                  | 1              |
| Amarela                | 2              |
| Parda                  | 3              |
| Indígena               | 4              |
| Prefiro não informar   | 5              |
| Outra                  | 6              |

### 3. PCD (Pessoa com Deficiência)

| Classe Original        | Valor Numérico |
|------------------------|----------------|
| Sim                    | 1              |
| Não                    | 0              |
| Prefiro não informar   | Removido       |

*Linhas com valor “Prefiro não informar” foram removidas do DataFrame.*

### 4. Região onde mora

| Classe Original   | Valor Numérico |
|-------------------|----------------|
| Norte             | 0              |
| Nordeste          | 1              |
| Sudeste           | 2              |
| Sul               | 3              |
| Centro-oeste      | 4              |

### 5. UF (Unidade da Federação)

| UF | Valor Numérico | | UF | Valor Numérico |   | UF | Valor Numérico |   | UF | Valor Numérico |
|----|----------------|---|----|----------------|---|----|----------------|---|----|----------------|
| AC | 0              |   | AL | 1              |   | AP | 2              |   | AM | 3              |
| BA | 4              |   | CE | 5              |   | DF | 6              |   | ES | 7              |
| GO | 8              |   | MA | 9              |   | MT | 10             |   | MS | 11             |
| MG | 12             |   | PA | 13             |   | PB | 14             |   | PR | 15             |
| PE | 16             |   | PI | 17             |   | RJ | 18             |   | RN | 19             |
| RS | 20             |   | RO | 21             |   | RR | 22             |   | SC | 23             |
| SP | 24             |   | SE | 25             |   | TO | 26             |   |    |                |

### 6. Nível de Ensino

| Classe Original             | Valor Numérico |
|-----------------------------|----------------|
| Não tenho graduação formal  | 0              |
| Estudante de Graduação      | 1              |
| Graduação/Bacharelado       | 2              |
| Pós-graduação               | 3              |
| Mestrado                    | 4              |
| Doutorado ou PhD            | 5              |
| Prefiro não informar        | 6              |

### 7. Área de Formação

| Classe Original                                                                | Valor Numérico |
|--------------------------------------------------------------------------------|----------------|
| Computação / Engenharia / Sistemas de Informação / TI                            | 0              |
| Economia / Administração / Contabilidade / Finanças / Negócios                   | 1              |
| Outras Engenharias                                       | 2 / 8          |
| Química / Física                                                               | 3              |
| Estatística / Matemática / Ciências Atuariais                                  | 4              |
| Marketing / Publicidade / Comunicação / Jornalismo                             | 5              |
| Ciências Sociais                                                               | 6              |
| Ciências Biológicas / Farmácia / Medicina / Área da Saúde                      | 7              |
| Outra opção                                                                    | 0  |

 **Observações:**

* A categoria "Outras Engenharias" foi removida, pois não há dados nessa classe; 'nan' - nulos.
* "Outra opção" recebeu o mesmo valor que "Computação / Engenharia / Sistemas de Informação / TI" (0), pois a moda da àrea de fomação era a classe '0', então atribui 'Outra opção' a essa classe.
* Linhas com valores NaN nesta coluna foram removidas durante o processamento.

### 8. Situação de Trabalho

| Classe Original                                                                 | Valor Final      | Valor Numérico |
|---------------------------------------------------------------------------------|------------------|----------------|
| Empregado (CLT)                                                                 | Empregado(a)     | 0              |
| Empreendedor ou Empregado (CNPJ)                                                | Empregado(a)     | 0              |
| Estagiário                                                                      | Empregado(a)     | 0              |
| Trabalho na área Acadêmica/Pesquisador                                          | Empregado(a)     | 0              |
| Servidor Público                                                                | Empregado(a)     | 0              |
| Vivo no Brasil e trabalho remoto para empresa de fora do Brasil                 | Empregado(a)     | 0              |
| Vivo fora do Brasil e trabalho para empresa de fora do Brasil                   | Empregado(a)     | 0              |
| Freelancer                                                                      | Empregado(a)     | 0              |
| Desempregado, buscando recolocação                                              | Desempregado(a)  | 1              |
| Desempregado e não estou buscando recolocação                                   | Desempregado(a)  | 1              |
| Somente Estudante (graduação ou pós-graduação)                                  | Desempregado(a)  | 1              |
| Prefiro não informar                                                            | Desempregado(a)  | 1              |



## 3. Análise Descritiva dos Dados utilizando Estatísticas de Primeira Ordem

* **Descrição:** Esta seção apresenta uma análise descritiva das colunas da base de dados processada (`base_princ`), utilizando estatísticas de primeira ordem para descrever a distribuição e as características dos dados.

## Descrição de Dados Numéricos

As colunas na base de dados processada foram convertidas para o tipo `int` após a codificação das variáveis categóricas. Embora representem categorias, sua análise estatística descritiva pode fornecer insights sobre a distribuição dos valores codificados. A coluna 'Idade' é a única numérica original antes do processamento extenso das demais colunas.

Para dados numéricos, as estatísticas de primeira ordem incluem:

* **Média:** Medida de tendência central.
* **Mediana:** Valor central dos dados ordenados.
* **Moda:** Valor mais frequente nos dados.
* **Desvio Padrão:** Medida de dispersão dos dados em torno da média.
* **Variância:** Quadrado do desvio padrão, outra medida de dispersão.
* **Mínimo e Máximo:** Limites inferior e superior dos dados.
* **Quartis:** Valores que dividem os dados em quatro partes iguais (25%, 50% - mediana, 75%).

Considerando a saída do seu código para a análise estatística, podemos descrever cada coluna:

### Análise da Coluna 'Idade'

* **Média:** 31.96 anos.
* **Mediana:** 30.00 anos.
* **Moda:** 27.00 anos (o valor mais frequente de idade).
* **Desvio Padrão:** 7.55 anos (indica a dispersão das idades em torno da média).
* **Mínimo:** 18.00 anos.
* **Máximo:** 73.00 anos.
* **Quartis:** 25% dos respondentes têm 27 anos ou menos, 50% têm 30 anos ou menos, e 75% têm 36 anos ou menos.

### Análise da Coluna 'Genero'

* **Média:** 0.25 (considerando a codificação, indica a proporção relativa entre os gêneros).
* **Mediana:** 0.00.
* **Moda:** 1.00 (o gênero com maior frequência na codificação).
* **Desvio Padrão:** 0.43.
* **Mínimo:** 0.00.
* **Máximo:** 1.00.
* **Quartis:** 75% dos valores codificados de gênero são 0.

### Análise da Coluna 'Cor/raca/etnia'

* **Média:** 0.91 (valor médio da codificação da cor/raça/etnia).
* **Mediana:** 0.00.
* **Moda:** 3.00 (a cor/raça/etnia com maior frequência na codificação).
* **Desvio Padrão:** 1.34.
* **Mínimo:** 0.00.
* **Máximo:** 6.00.
* **Quartis:** 75% dos valores codificados de cor/raça/etnia são 3 ou menos.

### Análise da Coluna 'PCD'

* **Média:** 0.02 (indica a proporção de respondentes que se identificam como PCD na codificação).
* **Mediana:** 0.00.
* **Moda:** 1.00 (a categoria de PCD com maior frequência na codificação).
* **Desvio Padrão:** 0.14.
* **Mínimo:** 0.00.
* **Máximo:** 1.00.
* **Quartis:** 75% dos valores codificados para PCD são 0.

### Análise da Coluna 'UF'

* **Média:** 17.87 (valor médio da codificação da Unidade Federativa).
* **Mediana:** 20.00.
* **Moda:** 24.00 (a UF com maior frequência na codificação).
* **Desvio Padrão:** 6.71.
* **Mínimo:** 1.00.
* **Máximo:** 26.00.
* **Quartis:** 25% dos respondentes moram em UFs codificadas como 12 ou menos, 50% em UFs codificadas como 20 ou menos, e 75% em UFs codificadas como 24 ou menos.

### Análise da Coluna 'Regiao onde mora'

* **Média:** 2.17 (valor médio da codificação da região).
* **Mediana:** 2.00.
* **Moda:** 2.00 (a região com maior frequência na codificação).
* **Desvio Padrão:** 0.77.
* **Mínimo:** 0.00.
* **Máximo:** 4.00.
* **Quartis:** 75% dos respondentes moram em regiões codificadas como 3 ou menos.

### Análise da Coluna 'Nível de Ensino'

* **Média:** 2.59 (valor médio da codificação do nível de ensino).
* **Mediana:** 3.00.
* **Moda:** 3.00 (o nível de ensino com maior frequência na codificação).
* **Desvio Padrão:** 1.00.
* **Mínimo:** 1.00.
* **Máximo:** 5.00.
* **Quartis:** 75% dos respondentes têm nível de ensino codificado como 3 ou menos.

### Análise da Coluna 'Área de formação'

* **Média:** 1.32 (valor médio da codificação da área de formação).
* **Mediana:** 1.00.
* **Moda:** 2.00 (a área de formação com maior frequência na codificação).
* **Desvio Padrão:** 1.72.
* **Mínimo:** 0.00.
* **Máximo:** 7.00.
* **Quartis:** 75% dos respondentes têm área de formação codificada como 2 ou menos.

### Análise da Coluna 'Situação de trabalho'

* **Média:** 0.09 (indica a proporção de respondentes em uma das categorias de situação de trabalho na codificação).
* **Mediana:** 0.00.
* **Moda:** 1.00 (a situação de trabalho com maior frequência na codificação).
* **Desvio Padrão:** 0.28.
* **Mínimo:** 0.00.
* **Máximo:** 1.00.
* **Quartis:** 75% dos valores codificados para situação de trabalho são 0.

**Observação:** É crucial lembrar que a interpretação dessas estatísticas para as colunas codificadas deve ser feita com cautela, pois os números representam categorias e não possuem uma escala numérica inerente. A análise é mais útil para entender a distribuição dos códigos dentro de cada coluna. Para a coluna 'Idade', a interpretação é direta, pois se trata de uma variável numérica contínua.



## Preparação dos Dados

A fase de preparação dos dados é crucial para garantir a qualidade e adequação do dataset para a análise. Neste projeto, a preparação dos dados consistiu nos seguintes passos:

### Seleção dos Atributos

Com base no objetivo da análise e na hipótese a ser investigada, foi realizada a seleção manual dos atributos relevantes do dataset original. Os atributos selecionados para compor a base de dados principal foram:

* Idade
* Genero
* Cor/raca/etnia
* PCD (Pessoa com Deficiência)
* UF (Unidade Federativa)
* Regiao onde mora
* Nível de Ensino
* Área de formação
* Situação de trabalho

Estes atributos foram considerados essenciais para explorar as relações entre gênero, situação de trabalho e localização geográfica, além de fornecerem contexto demográfico e educacional dos respondentes.

### Tratamento dos Valores Faltantes ou Omissos

A presença de valores faltantes ou omissos nos dados pode impactar a análise. No processo de preparação, identificamos e tratamos esses valores:

* **Identificação de Nulos:** Foi realizada a contagem de valores nulos em cada coluna para entender a extensão do problema.
* **Remoção de Nulos na Coluna 'UF':** A coluna 'UF' (Unidade Federativa) é fundamental para a análise regional da hipótese. Dada a importância dessa informação, optou-se por remover as linhas que apresentavam valores nulos nesta coluna.

### Tratamento dos Valores Inconsistentes

Valores inconsistentes podem distorcer os resultados da análise. Foram realizados tratamentos específicos para lidar com inconsistências identificadas:

* **Tratamento na Coluna 'Genero':** As categorias 'Outro' e 'Prefiro não informar' na coluna 'Genero' foram identificadas como inconsistentes para a análise de disparidade de gênero binária. Essas linhas foram removidas do dataset.
* **Tratamento na Coluna 'PCD':** Similarmente, as linhas onde a coluna 'PCD' apresentava o valor 'Prefiro não informar' foram removidas, pois não era possível inferir a informação de deficiência a partir desse valor.
* **Tratamento na Coluna 'Área de formação':** Foram identificados valores nulos (NaN) na coluna 'Área de formação' após o mapeamento, o que indicava a falta de informação para algumas entradas. As linhas com valores nulos nesta coluna também foram removidas.
* **Agrupamento na Coluna 'Situação de trabalho':** As diversas categorias de situação de trabalho foram agrupadas em duas categorias principais: 'Empregado(a)' e 'Desempregado(a)'. Este agrupamento simplifica a análise e foca na dicotomia emprego/desemprego. (É importante verificar e corrigir quaisquer erros de digitação durante este agrupamento).
* **Tratamento de Mapeamentos Duplicados/Inconsistentes:** Durante a codificação de variáveis categóricas, foi observado que a categoria 'Outras Engenharias' na coluna 'Área de formação' foi mapeada para dois valores diferentes (2 e 8), e 'Outra opção' foi mapeada para o mesmo valor que 'Computação / Engenharia...' (0). Embora o código original mostre esses mapeamentos, para uma análise precisa, estes devem ser revisados e corrigidos para garantir a unicidade dos códigos para cada categoria.

### Conversão de Dados

Para facilitar a análise e a aplicação de métodos estatísticos, as variáveis categóricas foram convertidas para um formato numérico:

* **Codificação Manual:** As categorias em colunas como 'Genero', 'Cor/raca/etnia', 'PCD', 'UF', 'Regiao onde mora', 'Nível de Ensino', 'Área de formação' e 'Situação de trabalho' foram mapeadas manualmente para valores inteiros específicos. Esta abordagem preserva a informação de qual número corresponde a qual categoria original.
* **Conversão para Tipo Numérico:** Após o mapeamento manual, as colunas foram convertidas para o tipo de dado inteiro (`int`) para que pudessem ser tratadas como dados numéricos em análises posteriores.


## Indução de modelos

### Modelo 1: Árvore de Decisão

## Justificativa da escolha do modelo:

A **Árvore de Decisão** é uma escolha adequada para este problema devido à sua interpretabilidade e relativa simplicidade. Ela permite visualizar o processo de tomada de decisão do modelo, o que facilita a explicação dos resultados. Além disso, a Árvore de Decisão é capaz de lidar com dados categóricos e numéricos, o que parece ser o caso dos seus dados.

## Processo utilizado para amostragem de dados:

Você utilizou a técnica de **particionamento** para dividir seus dados. Especificamente, o conjunto de dados original foi dividido em conjuntos de treino e teste utilizando a função `train_test_split` da biblioteca `sklearn.model_selection`. A proporção utilizada foi de **75%** dos dados para treino (`X_treino`, `y_treino`) e **25%** para teste (`X_teste`, `y_teste`). O parâmetro `random_state=42` garante que a divisão seja consistente a cada execução, tornando os resultados reproduzíveis.

Para a otimização de hiperparâmetros com `GridSearchCV`, você empregou **validação cruzada (cross-validation)** com `cv=5`. Isso significa que o conjunto de treino foi dividido em 5 partes (folds). O modelo foi treinado em 4 partes e avaliado na parte restante, repetindo esse processo 5 vezes, cada vez utilizando uma parte diferente para avaliação. Essa abordagem fornece uma estimativa mais robusta do desempenho do modelo e ajuda a mitigar o overfitting.

## Parâmetros utilizados:

No modelo inicial (`modelo`), você utilizou os seguintes parâmetros:

* `criterion='gini'`: Define a função para medir a qualidade de uma divisão, utilizando o índice Gini como medida de impureza.
* `max_depth=5`: Limita a profundidade máxima da árvore para ajudar a prevenir o overfitting.
* `min_samples_leaf=5`: Define o número mínimo de amostras necessárias para estar em um nó folha.
* `min_samples_split=10`: Especifica o número mínimo de amostras necessárias para dividir um nó interno.
* `random_state=42`: Garante a reproduzibilidade dos resultados ao fixar o gerador de números aleatórios.

No processo de otimização com `GridSearchCV`, você explorou a seguinte grade de parâmetros para encontrar a melhor combinação:

* `criterion`: `['gini', 'entropy']` (Índice Gini ou Ganho de Informação).
* `max_depth`: `[3, 5, 7, 9, 11, None]` (Diferentes profundidades máximas, incluindo a opção de não ter limite).
* `min_samples_leaf`: `[1, 3, 5, 10]` (Diferentes números mínimos de amostras em um nó folha).
* `min_samples_split`: `[5, 15, 25]` (Diferentes números mínimos de amostras para dividir um nó).
* `class_weight`: `[None, 'balanced', {0: 1, 1: 5}, {0: 1, 1: 10}]` (Pesos para as classes, útil para lidar com conjuntos de dados desbalanceados).

O `GridSearchCV` identificou os `best_params_` (melhores hiperparâmetros), que foram impressos na saída do seu código.

## Trechos de código utilizados comentados:

```python
# Importação de bibliotecas essenciais para manipulação de dados e machine learning
import pandas as pd  # Para trabalhar com DataFrames
import seaborn as sns  # Para visualizações estatísticas (não usado diretamente para o modelo, mas útil para EDA)
from sklearn import tree  # Módulo para árvores de decisão
import matplotlib.pyplot as plt  # Para gerar gráficos
```

```python
# Módulos específicos do scikit-learn para o modelo de árvore de decisão, divisão de dados e avaliação
from sklearn.tree import DecisionTreeClassifier, plot_tree  # Classe para a árvore e função para plotar
from sklearn.model_selection import train_test_split, GridSearchCV  # Funções para dividir dados e otimização
from sklearn.preprocessing import LabelEncoder  # Para codificar rótulos (não usado diretamente no código compartilhado, mas comum)
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, make_scorer, f1_score  # Métricas de avaliação
```

```python
# Módulo para visualização da matriz de confusão de forma mais interativa
from yellowbrick.classifier import ConfusionMatrix
```

```python
# Carregamento dos dados a partir de um arquivo CSV
base_treino = pd.read_csv("base_princ_modificado.csv")
```

```python
# Exibindo as primeiras linhas e estatísticas descritivas para entender os dados
print("Primeiras linhas do DataFrame:")
display(base_treino.head())

print("\nEstatísticas descritivas do DataFrame:")
display(base_treino.describe())
```

```python
# Verificando a distribuição da variável alvo para identificar desbalanceamento
print("\nDistribuição das classes na variável alvo:")
print(base_treino['Situação de trabalho'].value_counts())
```

```python
# Separando as features (X) e a variável alvo (y)
X = base_treino.drop(columns=['Situação de trabalho'])  # Remove a coluna alvo para obter as features
y = base_treino['Situação de trabalho']  # Seleciona a coluna alvo
```

```python
# Dividindo os dados em conjuntos de treino e teste (75% treino, 25% teste)
X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=42)
```

```python
# Inicializando o modelo de Árvore de Decisão com parâmetros iniciais
modelo = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf=5, min_samples_split=10, random_state=42)
```

```python
# Treinando o modelo com os dados de treino
modelo.fit(X_treino, y_treino)
```

```python
# Realizando previsões no conjunto de teste
previsoes = modelo.predict(X_teste)
```

```python
# Avaliando o desempenho do modelo inicial utilizando métricas comuns
print("Acurácia do modelo inicial:", accuracy_score(y_teste, previsoes))
print("\nRelatório de Classificação do modelo inicial:")
print(classification_report(y_teste, previsoes))
print("\nMatriz de Confusão do modelo inicial:")
print(confusion_matrix(y_teste, previsoes))
```

```python
# Visualizando a Matriz de Confusão usando a biblioteca Yellowbrick
cm = ConfusionMatrix(modelo)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)
plt.title("Matriz de Confusão (Modelo Inicial)")
plt.show()
```

```python
# --- Seção para Otimização de Hiperparâmetros com GridSearchCV ---

print("\n--- Abordagem: Ajuste de Hiperparâmetros com GridSearchCV ---")
```

```python
# Definindo a grade de parâmetros a serem testados no GridSearchCV
param_grid = {
    'criterion': ['gini', 'entropy'],  # Funções de critério
    'max_depth': [3, 5, 7, 9, 11, None],  # Profundidades máximas
    'min_samples_leaf': [1, 3, 5, 10],  # Mínimo de amostras em um nó folha
    'min_samples_split': [5, 15, 25],  # Mínimo de amostras para dividir um nó
    'class_weight': [None, 'balanced', {0: 1, 1: 5}, {0: 1, 1: 10}]  # Pesos para as classes
}
```

```python
# Criando um scorer personalizado para focar na métrica F1-score da classe 1
f1_classe1_scorer = make_scorer(f1_score, labels=[1], average='weighted')

# Inicializando o GridSearchCV com o modelo base, a grade de parâmetros, validação cruzada e o scorer personalizado
grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring=f1_classe1_scorer)
```

```python
# Executando a busca em grade para encontrar a melhor combinação de parâmetros
grid_search.fit(X_treino, y_treino)
```

```python
# Imprimindo os melhores parâmetros encontrados pelo GridSearchCV
print("\nMelhores hiperparâmetros encontrados (foco na classe 1):", grid_search.best_params_)
```

```python
# Obtendo o melhor modelo encontrado pelo GridSearchCV
melhor_modelo_grid = grid_search.best_estimator_
```

```python
# Avaliando o melhor modelo nos conjuntos de treino e teste
previsoes_grid = melhor_modelo_grid.predict(X_teste)
print("\nAcurácia do melhor modelo (GridSearchCV - Treino):", accuracy_score(y_treino, melhor_modelo_grid.predict(X_treino)))
print("\nAcurácia do melhor modelo (GridSearchCV - Teste):", accuracy_score(y_teste, previsoes_grid))
print("\nAvaliação do melhor modelo (GridSearchCV - foco na classe 1):")
print(f"Acurácia: {accuracy_score(y_teste, previsoes_grid)}")
print("\nRelatório de Classificação:")
print(classification_report(y_teste, previsoes_grid))
print("\nMatriz de Confusão:")
print(confusion_matrix(y_teste, previsoes_grid))
```

```python
# Visualizando a Matriz de Confusão do melhor modelo com Yellowbrick
cm_grid = ConfusionMatrix(melhor_modelo_grid)
cm_grid.fit(X_treino, y_treino)
cm_grid.score(X_teste, y_teste)
plt.title("Matriz de Confusão (GridSearchCV - Foco Classe 1)")
plt.show()
```

```python
# Visualizando a árvore de decisão do melhor modelo encontrado pelo GridSearchCV
previsores_grid = X_treino.columns  # Nomes das features
class_names_grid = [str(c) for c in melhor_modelo_grid.classes_]  # Nomes das classes

figura_grid, eixos_grid = plt.subplots(nrows=1, ncols=1, figsize=(30, 20))  # Cria uma figura para plotar
tree.plot_tree(melhor_modelo_grid, feature_names=previsores_grid, class_names = class_names_grid, filled=True, fontsize=10);  # Plota a árvore
plt.title("Árvore de Decisão (GridSearchCV - Foco Classe 1)")  # Título do gráfico
plt.show()  # Exibe o gráfico
```

```python
# Avaliando a acurácia do modelo inicial nos conjuntos de treino e teste novamente para comparação
acuracia_treino = accuracy_score(y_treino, modelo.predict(X_treino))
print(f"\nAcurácia do modelo no conjunto de treino: {acuracia_treino:.4f}")

acuracia_teste = accuracy_score(y_teste, previsoes)
print(f"Acurácia do modelo no conjunto de teste: {acuracia_teste:.4f}")

Substitua o título pelo nome do algoritmo que será utilizado. P. ex. árvore de decisão, rede neural, SVM, etc.
Justifique a escolha do modelo.
Apresente o processo utilizado para amostragem de dados (particionamento, cross-validation).
Descreva os parâmetros utilizados. 
Apresente trechos do código utilizado comentados. Se utilizou alguma ferramenta gráfica, apresente imagens
com o fluxo de processamento.
```

### Modelo 2: Random Forest

## Justificativa da escolha do modelo:

Ao tentar utilizar a árvore de decisão, percebi que possuia limites quanto ao seu desempenho e aprofundamento, mesmo testando vários hiperparâmetros. Com isso, foi recomendado utilizar a árvore de decisão para a mesma hipótese, relacionado à classificação preditiva, no qual desejo classificar se uma pessoa vai estar empregada ou não, no mercado de dados, dependendo de seu gênero e região onde mora.

## 1. Divisão dos Dados (Amostragem Inicial):

**Processo:** Você utilizou a função `train_test_split` da biblioteca `sklearn.model_selection` para dividir seu conjunto de dados original em conjuntos de treino e teste.

**Parâmetros utilizados:**

* `X` e `y`: As variáveis independentes e a variável alvo do seu DataFrame.
* `test_size=0.25`: Indica que 25% dos dados serão usados para o conjunto de teste e os 75% restantes para o conjunto de treino.
* `stratify=y`: Garante que a distribuição da variável alvo (`y`) seja a mesma nos conjuntos de treino e teste. Isso é importante para lidar com conjuntos de dados desbalanceados, onde a proporção das classes é significativamente diferente.
* `random_state=42`: Define uma semente para o gerador de números aleatórios, garantindo que a divisão dos dados seja a mesma sempre que o código for executado com a mesma semente.

## 2. Balanceamento com ADASYN (Amostragem para o Treinamento):

**Processo:** Você aplicou a técnica de oversampling ADASYN (Adaptive Synthetic Sampling) da biblioteca `imblearn.over_sampling` para balancear o conjunto de treino. O ADASYN gera amostras sintéticas para a classe minoritária, adaptando o número de amostras sintéticas geradas com base na densidade da distribuição da classe minoritária. Isso ajuda o modelo a aprender melhor as características da classe minoritária.

**Parâmetros utilizados:**

* `ADASYN(random_state=42)`: Você instanciou o objeto ADASYN.
    * `random_state=42`: Define uma semente para o gerador de números aleatórios do ADASYN, garantindo a reprodutibilidade do processo de balanceamento.
* `adasyn.fit_resample(X_train, y_train)`: Aplica a técnica ADASYN aos dados de treino. `fit_resample` combina as etapas de ajuste e reamostragem.

## Em resumo:

Primeiro, seus dados foram divididos em treino e teste de forma estratificada para manter a proporção das classes. Em seguida, o conjunto de treino foi balanceado usando o método ADASYN para criar amostras sintéticas da classe minoritária, tornando o conjunto de treino mais equilibrado para o treinamento do modelo. O conjunto de teste original (não balanceado) é utilizado para a avaliação final do modelo, pois ele reflete a distribuição real dos dados.

## Trechos de código utilizados comentados:

```python
#Importação das bibliotecas necessárias
from IPython.display import display

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, precision_recall_curve, f1_score
)

from imblearn.over_sampling import ADASYN
```

```python
# Carregamento e Visualização Inicial dos Dados
df = pd.read_csv('base_princ_modificado.csv', sep=',', encoding='utf-8')
print("Primeiras linhas do DataFrame:")
display(df.head())
```

```python
# Carregamento e Visualização Inicial dos Dados
df = pd.read_csv('base_princ_modificado.csv', sep=',', encoding='utf-8')
print("Primeiras linhas do DataFrame:")
display(df.head())
```

```python
#Mapeamento da Variável Alvo e Verificação de Classes
print("\nPrimeiras linhas após o mapeamento:")
display(df.head())

print("\nDistribuição da variável alvo:")
print(df['Situação de trabalho'].value_counts(dropna=False))
```

```python
# Selecionar as variáveis independentes e dependente
X = df[['Genero','UF', 'Regiao onde mora', 'Nível de Ensino', 'Área de formação', 'Cor/raca/etnia']]
y = df['Situação de trabalho']

# Codificação one-hot para variáveis categóricas
X = pd.get_dummies(X)
```

```python
# Divisão dos Dados em Treino e Teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=42
)
```

```python
#Balanceamento das classes com ADASYN
adasyn = ADASYN(random_state=42)
X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)
```

```python
# Definir os parâmetros a serem testados
param_grid = {
    'n_estimators': [100],
    'max_depth': [10, None],
    'min_samples_split': [2],
    'min_samples_leaf': [1],
    'max_features': ['sqrt'],
    'class_weight': ['balanced']
}


# Criar o Grid Search
grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42, class_weight='balanced'),
    param_grid=param_grid,
    cv=5,  # 5 folds para validação cruzada
    scoring='f1_macro'  # Métrica de avaliação
)

# Executar o Grid Search nos dados balanceados
grid_search.fit(X_train_resampled, y_train_resampled)

# Exibir os melhores parâmetros e a melhor pontuação
print("Melhores parâmetros:", grid_search.best_params_)
print("Melhor pontuação (F1-macro):", grid_search.best_score_)

# Avaliar o modelo com os melhores parâmetros no conjunto de teste original
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test)
print("\nRelatório de classificação com melhores parâmetros:")
print(classification_report(y_test, y_pred_best))
```

```python
#Treinamento do Modelo (Random Forest)
model = RandomForestClassifier(random_state=42, class_weight='balanced')
model.fit(X_train_resampled, y_train_resampled)
```

```python
#Avaliação com Múltiplos Limiares de Decisão
y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades da classe 1

# Função para avaliar diferentes limiares
def avaliar_limiais(probas, y_real, thresholds=[0.5]):
    for thresh in thresholds:
        y_pred = (probas >= thresh).astype(int)
        report = classification_report(y_real, y_pred, output_dict=True)
        recall_0 = report['0']['recall']
        precision_0 = report['0']['precision']
        f1_0 = report['0']['f1-score']
        print(f"\nLimiar: {thresh}")
        print(f" - Recall classe 0: {recall_0:.2f}")
        print(f" - Precision classe 0: {precision_0:.2f}")
        print(f" - F1-score classe 0: {f1_0:.2f}")
    return y_pred  # Retorna o último y_pred
```

```python
#Aplicar Avaliação e Exibir Resultados
y_pred = avaliar_limiais(y_proba, y_test)

print("\nMatriz de confusão (último limiar avaliado):")
print(confusion_matrix(y_test, y_pred))

print("\nRelatório de classificação:")
print(classification_report(y_test, y_pred))
```

```python
# Gerar a acuracia de treino e de teste

from sklearn.metrics import accuracy_score

# Acurácia no conjunto de treino (balanceado)
y_train_pred = best_model.predict(X_train_resampled)
train_accuracy = accuracy_score(y_train_resampled, y_train_pred)
print(f"Acurácia de treino: {train_accuracy:.4f}")

# Acurácia no conjunto de teste (original)
test_accuracy = accuracy_score(y_test, y_pred_best) # Usando as previsões do best_model no conjunto de teste original
print(f"Acurácia de teste: {test_accuracy:.4f}")
```

```python
# Gráfico da matriz de confusão

import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])
plt.xlabel('Previsão')
plt.ylabel('Real')
plt.title('Matriz de Confusão')
plt.show()
```

```python
#Importância das Variáveis
importances = model.feature_importances_
feature_names = X_train.columns

feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)
feat_imp.plot(kind='bar', figsize=(10, 5), title='Importância das variáveis')
plt.tight_layout()
plt.show()
```

```python
#Curvas de Precisão, Recall e F1 por Limiar
precision, recall, thresholds = precision_recall_curve(y_test, y_proba)
f1 = 2 * (precision * recall) / (precision + recall)

plt.plot(thresholds, precision[:-1], label='Precisão')
plt.plot(thresholds, recall[:-1], label='Recall')
plt.plot(thresholds, f1[:-1], label='F1-score')
plt.xlabel('Limiar de decisão')
plt.ylabel('Score')
plt.title('Scores por limiar de decisão')
plt.legend()
plt.grid()
plt.show()
```



# Resultados obtidos com o modelo 1 (Árvore de decisão).
Observação: Fiz duas avaliações utilizando métricas diferentes, com isso obtive diferentes resultados:
Primeira métrica eu obtive uma maior acurácia e precisão e recall em ambas as classes(Empregado(a) e Desempregado(a)). Porém percebi que o modelo estava priorizando mais a classe majoritária(Empregado(a)), por haver cerca de 10 vezes mais dados em relação a outra. Segue as duas avaliações...

## Avaliação 01:


![2d52dec8-827e-4dae-8efe-1e85e52eb25d](https://github.com/user-attachments/assets/d2c22032-1f0a-4085-ad8f-1cecb2c0da41)

![image](https://github.com/user-attachments/assets/1be4f89d-eb49-439d-a813-07189919b766)

## Acurácia do Modelo Inicial:

`0.9115537848605577`

## Relatório de Classificação do Modelo Inicial:

|               | precision | recall | f1-score | support |
|---------------|-----------|--------|----------|---------|
| 0             | 0.91      | 1.00   | 0.95     | 1146    |
| 1             | 0.33      | 0.02   | 0.03     | 109     |
| **accuracy** |           |        | **0.91** | **1255**|
| **macro avg** | 0.62      | 0.51   | 0.49     | 1255    |
| **weighted avg**| 0.86      | 0.91   | 0.87     | 1255    |

## Acurácia nos Conjuntos de Treino e Teste:

* **Acurácia de treino:** `0.9133`
* **Acurácia de teste:** `0.9116`


## Avaliação 02:

Utilizei muitos hiperparâmetros para tentar balancear os dados e fornecer uma maior importância para a classe minoritária, tendo como resultado um maior balanceameno dos dados. porém o resultado(acurácia) diminuiu significadamente, e a classificação preditiva de meus dados não foram satisfatórias. Nesse quesito, utilizei LLM para me sugerir mudanças, e por fim, elas me sugeriram testar com um novo modelo, como a Random Forest, o qual foi utilizado no modelo 2.

![download](https://github.com/user-attachments/assets/103ff659-4ef6-4e01-89d5-78b794261d50)

![download](https://github.com/user-attachments/assets/7634ae46-a069-44f1-be2a-9fdd646e07ba)

## --- Abordagem: Ajuste de Hiperparâmetros com GridSearchCV ---

**Melhores hiperparâmetros encontrados (foco na classe 1):**
{'class_weight': {0: 1, 1: 10}, 'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5}


**Acurácia do melhor modelo (GridSearchCV - Treino):** `0.7102604997341839`

**Acurácia do melhor modelo (GridSearchCV - Teste):** `0.6772908366533864`

**Avaliação do melhor modelo (GridSearchCV - foco na classe 1):**
Acurácia: 0.6772908366533864


**Relatório de Classificação:**

|               | precision | recall | f1-score | support |
|---------------|-----------|--------|----------|---------|
| 0             | 0.93      | 0.70   | 0.80     | 1146    |
| 1             | 0.13      | 0.47   | 0.20     | 109     |
| **accuracy** |           |        | **0.68** | **1255**|
| **macro avg** | 0.53      | 0.58   | 0.50     | 1255    |
| **weighted avg**| 0.86      | 0.68   | 0.75     | 1255    |

Ao otimizar o modelo com o f1_score ponderado para a classe 1 no GridSearchCV, você estava explicitamente instruindo o algoritmo a encontrar parâmetros que equilibrassem a precisão e o recall da classe "Desempregadas", dando maior peso à capacidade do modelo de identificar todas as instâncias dessa classe. Os resultados mostram que, embora o recall da classe 1 tenha melhorado em relação a um modelo puramente focado na acurácia geral, ainda há um trade-off com a precisão dessa classe.


### Interpretação do modelo 1

![download](https://github.com/user-attachments/assets/88f497c9-c5ba-416b-8707-017f70fd520d)

## Importância das Features na Árvore de Decisão

**Idade: A Feature Mais Importante**

O fato de "Idade" estar em primeiro lugar significa que, de todas as features consideradas pelo modelo, a idade da pessoa é a informação que mais impacta a decisão do modelo sobre a `Situação de trabalho`. O modelo encontra na idade padrões muito fortes que o ajudam a separar as diferentes classes da variável alvo. Isso sugere que há uma relação significativa entre a faixa etária e a situação de trabalho no seu conjunto de dados.

**Nível de Ensino: A Segunda Feature Mais Importante**

"Nível de Ensino" é a segunda feature mais importante. Isso indica que a escolaridade da pessoa também é uma informação crucial para o modelo. A Árvore de Decisão provavelmente usa o nível de ensino para criar divisões importantes nos seus nós, mostrando que o grau de instrução tem um forte poder preditivo sobre a situação de trabalho.

**Região onde mora e Gênero: Importância Moderada**

"Região onde mora" e "Gênero" aparecem depois de "Idade" e "Nível de Ensino". Isso sugere que, embora sejam importantes, a influência deles nas decisões do modelo é menor do que a idade e o nível de ensino. O modelo provavelmente utiliza essas informações para refinar as suas previsões dentro dos grupos já definidos pela idade e escolaridade.

**UF, Cor/Raça/Etnia e Área de Formação: Features Menos Importantes**

"UF", "Cor/Raça/Etnia" e "Área de Formação" são as features menos importantes na lista que você forneceu. Isso não significa que elas não tenham nenhuma importância, mas sim que, no contexto deste modelo específico e deste conjunto de dados, elas contribuíram menos para as decisões finais do que as features no topo da lista. A "Área de Formação" ser a menos importante pode indicar que, para este problema específico e a forma como os dados estão representados, essa informação não é tão discriminatória quanto as outras para determinar a situação de trabalho.

**Em Resumo:**

Seu modelo de Árvore de Decisão considera a **idade** e o **nível de ensino** como os fatores mais determinantes para prever a situação de trabalho. Features demográficas como **região**, **gênero**, **UF**, **cor/raça/etnia** e **área de formação** também são consideradas, mas com menor peso na tomada de decisão do modelo.

![download](https://github.com/user-attachments/assets/b2e4b1b2-1df8-433b-b063-b03ba1ed065b)



# Resultados obtidos com o modelo 2 (Random Forest).


### Avaliação 01:

![download](https://github.com/user-attachments/assets/5c253440-4bf8-465d-859e-fbb9ff592562)

## Melhores Parâmetros Encontrados:

{'class_weight': 'balanced', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}


## Melhor Pontuação (F1-macro) Obtida:

`0.7106123941935574`

## Acurácia de treino: 
0.7817
## Acurácia de teste: 
0.7458

## Relatório de Classificação com Melhores Parâmetros no Conjunto de Teste:

|               | precision | recall | f1-score | support |
|---------------|-----------|--------|----------|---------|
| 0             | 0.93      | 0.78   | 0.85     | 1144    |
| 1             | 0.16      | 0.42   | 0.23     | 111     |
| **accuracy** |           |        | **0.75** | **1255**|
| **macro avg** | 0.54      | 0.60   | 0.54     | 1255    |
| **weighted avg**| 0.86      | 0.75   | 0.79     | 1255    |

### Avaliação 02:
Utilizei novos parâmetros para análise, tentei equilibrar os resultados das classes, porém não consegui ter um valor satisfatório no recall e na precisão.

![download](https://github.com/user-attachments/assets/5ab5f6c2-d17d-4685-879f-133a05abb3b5)

## Avaliação com Limiar de Decisão de 0.5:

**Limiar:** `0.5`
* **Recall classe 0:** `0.76`
* **Precision classe 0:** `0.93`
* **F1-score classe 0:** `0.84`

**Matriz de Confusão (Limiar 0.5):**

[[871 273]
[ 63  48]]


**Relatório de Classificação (Limiar 0.5):**

|               | precision | recall | f1-score | support |
|---------------|-----------|--------|----------|---------|
| 0             | 0.93      | 0.76   | 0.84     | 1144    |
| 1             | 0.15      | 0.43   | 0.22     | 111     |
| **accuracy** |           |        | **0.73** | **1255**|
| **macro avg** | 0.54      | 0.60   | 0.53     | 1255    |
| **weighted avg**| 0.86      | 0.73   | 0.78     | 1255    |

Repita o passo anterior com os resultados do modelo 2.





### Interpretação do modelo 2

![download](https://github.com/user-attachments/assets/30568082-b86e-4478-acda-920538c83799)

1-UF (Unidade Federativa): A variável mais importante, indicando que o estado de residência é o fator mais preditivo da situação de trabalho.

2-Nível de Ensino: A segunda variável mais importante. O nível de escolaridade de uma pessoa tem uma forte influência na sua situação de trabalho.

3-Área de formação: A área de formação é o terceiro fator mais importante, sugerindo que a área de estudo ou profissão também é um preditor relevante.

4-Regiao onde mora: A região geográfica de residência tem uma influência menor que as três primeiras.

5-Cor/raca/etnia: A cor, raça ou etnia apresenta uma importância ainda menor, mas não desprezível.

6-Genero: O gênero é a variável com a menor importância relativa para o modelo.


![download](https://github.com/user-attachments/assets/914d4929-d532-4b1c-98c6-895b7556a551)

Recall Alto com Limiar Pequeno:

Isso significa que quando você define um limiar baixo, o modelo tende a classificar mais observações como pertencentes à classe positiva (a classe que você está tentando prever com maior sensibilidade).
Em outras palavras, o modelo está capturando uma grande proporção de todas as instâncias reais da classe positiva.
A consequência é que você está incluindo mais verdadeiros positivos, mas também mais falsos positivos.

Precisão e F1-score Baixos com Limiar Pequeno:

A precisão baixa indica que, embora o modelo esteja encontrando muitos dos casos reais da classe positiva, ele também está classificando incorretamente muitas observações negativas como positivas.
Há muitos falsos positivos, o que diminui a confiabilidade das previsões positivas.
O F1-score baixo é uma consequência direta da baixa precisão, pois o F1-score é a média harmônica entre precisão e recall.

Encontro dos Scores Próximo ao Limiar 0.8:

O ponto onde a precisão, o recall e o F1-score se aproximam geralmente indica um ponto de equilíbrio.
Nesse limiar, o modelo está encontrando um melhor compromisso entre classificar corretamente a maioria dos casos positivos e evitar falsos positivos.
Esse limiar pode ser considerado um ponto "ótimo" para este modelo e conjunto de dados.

O Que Isso Quer Dizer na Prática?

Trade-off: Seu gráfico ilustra claramente o trade-off entre precisão e recall.
Se você precisa capturar o máximo possível de casos positivos (alto recall), você terá que aceitar uma precisão mais baixa.
Se você precisa ter alta confiança em suas previsões positivas (alta precisão), você pode perder alguns casos positivos.
Desbalanceamento: A situação descrita sugere que seus dados podem estar desbalanceados, com uma classe sendo muito mais frequente que a outra. Modelos tendem a ter mais dificuldade em prever a classe minoritária.

Aplicação: A escolha do limiar depende do contexto da sua aplicação.
Se o custo de um falso negativo for alto, você pode preferir um limiar mais baixo para maximizar o recall.
Se o custo de um falso positivo for alto, você pode preferir um limiar mais alto para maximizar a precisão.

Exemplo:

Imagine que você está tentando prever se pacientes têm uma doença rara.

Se você usar um limiar baixo, você identificará a maioria dos pacientes doentes (alto recall), mas também classificará erroneamente muitos pacientes saudáveis como doentes (baixa precisão). Isso pode levar a mais testes e ansiedade desnecessários.
Se você usar um limiar alto, você terá alta confiança de que os pacientes que você identifica como doentes realmente têm a doença, mas você pode perder alguns pacientes doentes que precisam de tratamento.
No seu caso, a classe "Desempregado" é geralmente a classe minoritária. Se for muito importante identificar o máximo de pessoas desempregadas para oferecer ajuda, você pode trabalhar com um limiar mais baixo, mesmo que isso signifique que algumas pessoas empregadas sejam classificadas como desempregadas.


## Análise comparativa dos modelos

## Comparativo entre Árvore de Decisão e Random Forest

Com base nas métricas e informações fornecidas, podemos comparar as forças e fragilidades dos modelos de Árvore de Decisão e Random Forest para a sua tarefa de prever a situação de trabalho.

**Árvore de Decisão:**

* **Acurácia (Teste):** 0.68
* **Precisão (Classe 0 - Empregado):** 0.93
* **Precisão (Classe 1 - Desempregado):** 0.13
* **Recall (Classe 0 - Empregado):** 0.70
* **Recall (Classe 1 - Desempregado):** 0.47
* **F1-Score (Classe 0 - Empregado):** 0.80
* **F1-Score (Classe 1 - Desempregado):** 0.20
* **Interpretabilidade:** Alta. A estrutura da árvore pode ser visualizada e as decisões são facilmente rastreáveis através dos nós e regras.
* **Importância das Features:** Idade > Nível de Ensino > Região onde mora > Gênero > UF > Cor/Raça/Etnia > Área de Formação (conforme sua análise anterior).

**Random Forest:**

* **Acurácia (Teste):** 0.73 (com limiar de 0.5)
* **Precisão (Classe 0 - Empregado):** 0.93
* **Precisão (Classe 1 - Desempregado):** 0.15
* **Recall (Classe 0 - Empregado):** 0.76
* **Recall (Classe 1 - Desempregado):** 0.43
* **F1-Score (Classe 0 - Empregado):** 0.84
* **F1-Score (Classe 1 - Desempregado):** 0.22
* **Interpretabilidade:** Baixa. O modelo é um conjunto de muitas árvores, tornando a interpretação das decisões individuais complexa. A importância das features pode ser avaliada, mas o caminho decisório para uma única previsão não é tão claro.
* **Importância das Features:** UF > Nível de Ensino > Área de formação > Região onde mora > Cor/raca/etnia > Genero (conforme sua análise anterior da Random Forest).

**Forças e Fragilidades:**

| Característica        | Árvore de Decisão                                     | Random Forest                                                |
| :-------------------- | :---------------------------------------------------- | :----------------------------------------------------------- |
| **Acurácia** | Menor (0.68)                                          | Maior (0.73)                                                 |
| **Precisão (Classe 0)** | Similar (0.93)                                        | Similar (0.93)                                               |
| **Precisão (Classe 1)** | Menor (0.13)                                          | Maior (0.15)                                                 |
| **Recall (Classe 0)** | Menor (0.70)                                          | Maior (0.76)                                                 |
| **Recall (Classe 1)** | Maior (0.47)                                          | Menor (0.43)                                                 |
| **F1-Score (Classe 0)** | Menor (0.80)                                          | Maior (0.84)                                                 |
| **F1-Score (Classe 1)** | Menor (0.20)                                          | Maior (0.22)                                                 |
| **Interpretabilidade** | Alta                                                  | Baixa                                                        |
| **Robustez a Overfitting** | Mais suscetível, especialmente árvores profundas      | Menos suscetível devido à agregação de múltiplas árvores      |
| **Lida com Não Linearidades** | Bem                                                   | Bem                                                          |
| **Estabilidade** | Pequenas variações nos dados podem mudar a estrutura | Mais estável, menos sensível a pequenas variações nos dados |

**Casos em que um modelo se sairia melhor que o outro:**

* **Cenário 1: Necessidade de Interpretabilidade para Ações Diretas**
    * **Melhor Modelo:** Árvore de Decisão.
    * **Exemplo:** Imagine que você precisa entender exatamente quais regras levam à previsão de desemprego para criar políticas públicas direcionadas. Uma árvore de decisão, com sua estrutura clara de regras "SE...ENTÃO...", pode fornecer insights diretos sobre combinações de idade, nível de ensino e região que estão fortemente associadas ao desemprego. Você pode visualizar o caminho que leva a essa previsão e identificar grupos específicos para intervenção. A interpretabilidade aqui é mais valiosa do que um pequeno ganho em acurácia.

* **Cenário 2: Previsão com Foco na Robustez e Generalização em Dados Complexos**
    * **Melhor Modelo:** Random Forest.
    * **Exemplo:** Considere um cenário onde os fatores que influenciam a situação de trabalho são altamente não lineares e interagem de maneiras complexas (por exemplo, combinações sutis de área de formação, experiência profissional não capturada diretamente e fatores econômicos regionais). O Random Forest, ao agregar as decisões de muitas árvores treinadas em diferentes subconjuntos dos dados e features, tende a ser mais robusto a essas complexidades e generaliza melhor para novos dados não vistos durante o treinamento. Mesmo que você não consiga interpretar o caminho de cada previsão, a maior acurácia e a menor chance de overfitting podem ser cruciais para uma ferramenta de previsão em larga escala.

* **Cenário 3: Desbalanceamento Extremo da Classe Alvo**
    * **Consideração:** Ambos os modelos podem ter dificuldades com desbalanceamento extremo. No entanto, o Random Forest, com seus mecanismos de amostragem e a possibilidade de ajuste de `class_weight`, pode ser mais flexível para lidar com isso, especialmente se o foco for em métricas como F1-score para a classe minoritária. A Árvore de Decisão pode se tornar enviesada para a classe majoritária mais facilmente.
    * **Exemplo:** Se a taxa de desemprego na sua amostra fosse extremamente baixa (por exemplo, apenas 5%), o Random Forest, com a sua capacidade de explorar diferentes subespaços de features e amostras, poderia capturar melhor os padrões da classe minoritária se bem ajustado.

* **Cenário 4: Necessidade de Previsões Rápidas em Tempo Real**
    * **Consideração:** Árvores de Decisão geralmente são mais rápidas para prever uma vez treinadas, pois envolvem percorrer uma única árvore. Random Forests exigem a agregação das previsões de muitas árvores, o que pode ser mais computacionalmente intensivo durante a previsão.
    * **Exemplo:** Se você precisasse de um sistema de previsão em tempo real com baixíssima latência para classificar rapidamente candidatos a empregos ou pessoas em busca de assistência, uma Árvore de Decisão bem otimizada poderia ser preferível devido à sua velocidade de previsão.

**Conclusão:**

Ambos os modelos têm seus méritos e desvantagens. A escolha do melhor modelo depende fortemente dos seus objetivos específicos, da natureza dos seus dados e das prioridades do seu projeto (interpretabilidade, acurácia, robustez, velocidade). O Random Forest geralmente oferece melhor desempenho preditivo e robustez, enquanto a Árvore de Decisão brilha na interpretabilidade. Analisar as métricas detalhadas para a classe minoritária (desempregado) e considerar o custo de falsos positivos e falsos negativos em seu contexto específico ajudará a tomar a decisão mais informada.

### Distribuição do modelo (opcional)

Tende criar um pacote de distribuição para o modelo construído, para ser aplicado 
em um sistema inteligente.


## 8. Conclusão

Apresente aqui a conclusão do seu trabalho. Discussão dos resultados obtidos no trabalho, 
onde se verifica as observações pessoais de cada aluno.

Uma conclusão deve ter 3 partes:

   * Breve resumo do que foi desenvolvido
	 * Apresenação geral dos resultados obtidos com discussão das vantagens e desvantagens do sistema inteligente
	 * Limitações e possibilidades de melhoria


# REFERÊNCIAS

Como um projeto de sistema inteligente não requer revisão bibliográfica, 
a inclusão das referências não é obrigatória. No entanto, caso você 
tenha utilizado referências na introdução ou deseje 
incluir referências relacionadas às tecnologias, padrões, ou metodologias 
que serão usadas no seu trabalho, relacione-as de acordo com a ABNT.

Verifique no link abaixo como devem ser as referências no padrão ABNT:

http://www.pucminas.br/imagedb/documento/DOC\_DSC\_NOME\_ARQUI20160217102425.pdf

Por exemplo:

**[1]** - _ELMASRI, Ramez; NAVATHE, Sham. **Sistemas de banco de dados**. 7. ed. São Paulo: Pearson, c2019. E-book. ISBN 9788543025001._

**[2]** - _COPPIN, Ben. **Inteligência artificial**. Rio de Janeiro, RJ: LTC, c2010. E-book. ISBN 978-85-216-2936-8._

**[3]** - _CORMEN, Thomas H. et al. **Algoritmos: teoria e prática**. Rio de Janeiro, RJ: Elsevier, Campus, c2012. xvi, 926 p. ISBN 9788535236996._

**[4]** - _SUTHERLAND, Jeffrey Victor. **Scrum: a arte de fazer o dobro do trabalho na metade do tempo**. 2. ed. rev. São Paulo, SP: Leya, 2016. 236, [4] p. ISBN 9788544104514._

**[5]** - _RUSSELL, Stuart J.; NORVIG, Peter. **Inteligência artificial**. Rio de Janeiro: Elsevier, c2013. xxi, 988 p. ISBN 9788535237016._



# APÊNDICES

**Colocar link:**

Do código (armazenado no repositório);

Dos artefatos (armazenado do repositório);

Da apresentação final (armazenado no repositório);

Do vídeo de apresentação (armazenado no repositório).
