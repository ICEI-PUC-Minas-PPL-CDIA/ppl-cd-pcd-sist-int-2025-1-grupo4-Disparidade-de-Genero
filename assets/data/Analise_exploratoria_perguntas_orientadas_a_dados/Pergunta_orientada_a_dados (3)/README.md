# ğŸ Sprint 4 â€“ RelatÃ³rio Completo

## 1. IntroduÃ§Ã£o

**Objetivo do projeto:**  
Prever a **intenÃ§Ã£o de saÃ­da** de colaboradores nos prÃ³ximos 6 meses, auxiliando equipes de RH a identificar riscos de turnover.

**Utilidade do modelo:**  
- Antecipar demandas de retenÃ§Ã£o  
- Apoiar decisÃµes de programas de engajamento  
- Reduzir custos de substituiÃ§Ã£o e treinamento

---

## 2. HipÃ³tese

> â€œA combinaÃ§Ã£o de caracterÃ­sticas demogrÃ¡ficas, salariais e de satisfaÃ§Ã£o no trabalho permite prever com boa acurÃ¡cia quem pretende mudar de emprego.â€

- **VariÃ¡vel-alvo (target):** `PretenÃ§Ã£o de sair - TARGET` (binÃ¡ria: 1 = procura saÃ­da, 0 = nÃ£o procura)
- **Features principais:** Idade mÃ©dia, GÃªnero, NÃ­vel, Cargo, SalÃ¡rio, SatisfaÃ§Ã£o, Forma de trabalho, Trabalho ideal

---

## 3. Bases de Dados e TransformaÃ§Ãµes
### 3.1. Base Original
A base original foi fornecida em formato .csv contendo 5294 linhas e 550 colunas. Ela reÃºne informaÃ§Ãµes diversas sobre colaboradores, abrangendo dados demogrÃ¡ficos, profissionais, salariais e de satisfaÃ§Ã£o.

- [Base de Dados principal pura e crua (State_of_data_BR_2023_Kaggle - df_survey_2023.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/blob/main/assets/data/Base_principal_State_of_data_2023/State_of_data_BR_2023_Kaggle%20-%20df_survey_2023.csv)

- ObservaÃ§Ã£o: A base contÃ©m muitas colunas irrelevantes ou redundantes para o objetivo da anÃ¡lise.

---

### 3.2. SeleÃ§Ã£o de Colunas Relevantes
* Para tornar a anÃ¡lise mais eficiente e alinhada Ã  hipÃ³tese, filtrei apenas as colunas necessÃ¡rias para a modelagem preditiva. O processo foi feito com base em critÃ©rios de relevÃ¢ncia para o problema de previsÃ£o de saÃ­da de colaboradores.

  |     CÃ³digo        |      Coluna             | Tipo de dado | Atributos correspondentes |
  | -----------|---------------------|----------------------------|------------------------|
   | 'P1_a_1'|       Faixa idade | Qualitativo intervalar |17-21 <br>22-24<br>25-29<br>30-34<br>35-39<br>40-44<br>45-49<br>50-54<br>55+ |
  |  'P1_b'  |       GÃªnero |  Qualitativo | Feminino<br>Masculino<br>Outro<br>Prefiro nÃ£o informar |
  |  'P2_f'   |      Cargo Atual | Qualitativo | Analista de BI/BI Analyst<br>Analista de Dados/Data Analyst<br>Analista de InteligÃªncia de Mercado/Market Intelligence<br>Analista de NegÃ³cios/Business Analyst<br>Analista de Suporte/Analista TÃ©cnico<br>Analytics Engineer<br>Cientista de Dados/Data Scientist<br>Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)<br>DBA/Administrador de Banco de Dados<br>Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas<br>Economista<br>Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect<br>Engenheiro de Machine Learning/ML Engineer/AI Engineer<br>EstatÃ­stico<br>Outra OpÃ§Ã£o<br>Outras Engenharias (nÃ£o inclui dev)<br>Professor/Pesquisador<br>(vazio) |
  |  'P2_g'   |     NÃ­vel | Qualitativo |JÃºnior<br>Pleno<br>SÃªnior<br>(vazio) |
  |  'P2_h'   |     Faixa salarial | Qualitativo intervalar | Acima de R$ 40.001/mÃªs<br>de R$ 1.001/mÃªs a R$ 2.000/mÃªs<br>de R$ 1001/mÃªs a R$ 2.000/mÃªs<br>de R$ 12.001/mÃªs a R$ 16.000/mÃªs<br>de R$ 16.001/mÃªs a R$ 20.000/mÃªs<br>de R$ 2.001/mÃªs a R$ 3.000/mÃªs<br>de R$ 20.001/mÃªs a R$ 25.000/mÃªs<br>de R$ 25.001/mÃªs a R$ 30.000/mÃªs<br>de R$ 3.001/mÃªs a R$ 4.000/mÃªs<br>de R$ 30.001/mÃªs a R$ 40.000/mÃªs<br>de R$ 4.001/mÃªs a R$ 6.000/mÃªs<br>de R$ 6.001/mÃªs a R$ 8.000/mÃªs<br>de R$ 8.001/mÃªs a R$ 12.000/mÃªs<br>Menos de R$ 1.000/mÃªs<br>(vazio) |
  |  'P2_k'   |     SatisfaÃ§Ã£o empresa | Bool | 0<br>1<br>(vazio) |
  |  'P2_n'   |      PretensÃ£o mudar emprego | Qualitativo | Estou em busca de oportunidades dentro ou fora do Brasil<br>Estou em busca de oportunidades, mas apenas fora do Brasil<br>NÃ£o estou buscando e nÃ£o pretendo mudar de emprego nos prÃ³ximos 6 meses<br>NÃ£o estou buscando, mas me considero aberto a outras oportunidades<br>(vazio) |
  |  'P2_r'    |     Forma de trabalho | Qualitativo |Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo hÃ­brido com dias fixos de trabalho presencial<br>Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)<br>(vazio) |
  |  'P2_s'     |     Forma de trabalho ideal | Qualitativo | Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo hÃ­brido com dias fixos de trabalho presencial<br>Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)<br>(vazio) |


### 3.3. Base Refinada e TransformaÃ§Ãµes
ApÃ³s a filtragem, realizei uma sÃ©rie de limpezas e transformaÃ§Ãµes para preparar os dados para a modelagem. As principais etapas foram:

  #### 3.3.1. ConversÃ£o de faixas para valores mÃ©dios (idade, salÃ¡rio)
  * 3.3.1.1 MÃ©dia intervalos das faixas salariais:
  O programa precisava ler atributos float para ter uma noÃ§Ã£o boa do salÃ¡rio. A ideia foi tirar a mÃ©dia dos extremos dos intervalos.
  CÃ³digo usado no excel:
  > =SE(Ã‰CÃ‰L.VAZIA(H2);10000;
  SE(H2="Acima de R$ 40.001/mÃªs";45000;
  SE(H2="de R$ 1.001/mÃªs a R$ 2.000/mÃªs";1500;
  SE(H2="de R$ 1001/mÃªs a R$ 2.000/mÃªs";1500;
  SE(H2="de R$ 12.001/mÃªs a R$ 16.000/mÃªs";14000;
  SE(H2="de R$ 16.001/mÃªs a R$ 20.000/mÃªs";18000;
  SE(H2="de R$ 2.001/mÃªs a R$ 3.000/mÃªs";2500;
  SE(H2="de R$ 20.001/mÃªs a R$ 25.000/mÃªs";22500;
  SE(H2="de R$ 25.001/mÃªs a R$ 30.000/mÃªs";27500;
  SE(H2="de R$ 3.001/mÃªs a R$ 4.000/mÃªs";3500;
  SE(H2="de R$ 30.001/mÃªs a R$ 40.000/mÃªs";35000;
  SE(H2="de R$ 4.001/mÃªs a R$ 6.000/mÃªs";5000;
  SE(H2="de R$ 6.001/mÃªs a R$ 8.000/mÃªs";7000;
  SE(H2="de R$ 8.001/mÃªs a R$ 12.000/mÃªs";10000;
  SE(H2="Menos de R$ 1.000/mÃªs";500;"")))))))))))))))

  para a linha 2. Nas linhas subsequentes o cÃ³digo Ã© o mesmo, sÃ³ alterando a linha.
  * 3.3.1.2 MÃ©dia intervalos das idades. O programa precisava ter um atributo int ou float. A ideia foi tirar a mÃ©dia dos extremos dos intervalos.
  CÃ³digo usado no excel:
  > =SE(A2="17-21"; 19;
  SE(A2="22-24"; 23;
  SE(A2="25-29"; 27;
  SE(A2="30-34"; 32;
  SE(A2="35-39"; 37;
  SE(A2="40-44"; 42;
  SE(A2="45-49"; 47;
  SE(A2="50-54"; 52;
  SE(A2="55+"; 57,5)))))))))

  para a linha 2. Nas linhas subsequentes o cÃ³digo Ã© o mesmo, sÃ³ alterando a linha.
    
  #### 3.3.2. Agrupamento de cargos em categorias macro
  Havia muitos cargos, alguns "parecidos", podendo ser agrupados em macro-categorias. AlteraÃ§Ãµes feitas:
  |Cargo Original|	Cargo Agrupado|
  |---------------|----------------|
  |Cientista de Dados/Data Scientist<br>Analista de Dados/Data Analyst<br>Analista de BI/BI Analyst<br>Analista de InteligÃªncia de Mercado/Market Intelligence	|AnÃ¡lise de Dados|
  |Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect<br>Analytics Engineer	|Engenharia de Dados|
  |Engenheiro de Machine Learning/ML Engineer/AI |Engineer	ML/IA|
  |Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas	|Desenvolvimento|
  Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)	|Produto|
  |EstatÃ­stico<br>Economista	|CientÃ­fico/Quantitativo|
  |DBA/Administrador de Banco de Dados<br>Analista de Suporte/Analista TÃ©cnico|	Infraestrutura|
  |Outras Engenharias (nÃ£o inclui dev)|	Outras Engenharias|
  |Professor/Pesquisador	|AcadÃªmico|
  |Analista de NegÃ³cios/Business Analyst|	NegÃ³cios|
  |Outra OpÃ§Ã£o	|Outro|
  |(vazio)	|NÃ£o informado|
  
  CÃ³digo usado no excel:
  > =SE(Ã‰CÃ‰L.VAZIA(D2);"NÃ£o informado";
  SE(OU(D2="Cientista de Dados/Data Scientist";D2="Analista de Dados/Data Analyst";D2="Analista de BI/BI Analyst";D2="Analista de InteligÃªncia de Mercado/Market Intelligence");"AnÃ¡lise    de Dados";
  SE(OU(D2="Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect";D2="Analytics Engineer");"Engenharia de Dados";
  SE(D2="Engenheiro de Machine Learning/ML Engineer/AI Engineer";"ML/IA";
  SE(D2="Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas";"Desenvolvimento";
  SE(D2="Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)";"Produto";
  SE(OU(D2="EstatÃ­stico";D2="Economista");"CientÃ­fico/Quantitativo";
  SE(OU(D2="DBA/Administrador de Banco de Dados";D2="Analista de Suporte/Analista TÃ©cnico");"Infraestrutura";
  SE(D2="Outras Engenharias (nÃ£o inclui dev)";"Outras Engenharias";
  SE(D2="Professor/Pesquisador";"AcadÃªmico";
  SE(D2="Analista de NegÃ³cios/Business Analyst";"NegÃ³cios";
  SE(D2="Outra OpÃ§Ã£o";"Outro";"Outro"))))))))))))

  para a linha 2. Nas linhas subsequentes o cÃ³digo Ã© o mesmo, sÃ³ alterando a linha.
  
  #### 3.3.3. ConversÃ£o de variÃ¡veis categÃ³ricas em numÃ©ricas (ordinal ou binÃ¡ria)
  * 3.3.3.1 NÃ­vel (jÃºnior, pleno e sÃªnior) sÃ£o um atributo ordinal. EntÃ£o decidi transformÃ¡-los em jÃºnior=0, pleno=1 e sÃªnior=2, porque sÃªnior>pleno>jÃºnior.
  CÃ³digo usado:
  > =SE(F2="JÃºnior";0;
  SE(F2="Pleno";1;
  SE(F2="SÃªnior";2;
  SE(Ã‰CÃ‰L.VAZIA(F2);ALEATÃ“RIOENTRE(0;2);""""))))

  para a linha 2. Nas linhas subsequentes o cÃ³digo Ã© o mesmo, sÃ³ alterando a linha.
  * 3.3.3.2 PretensÃ£o de mudar de emprego estÃ¡ como atributo qualitativo. Para aquelas pessoas que apresentam qualquer vontade em sair de seu emprego, vou considerar que vÃ£o sair. 
  Inclusive, esse serÃ¡ o atributo-alvo. Segue abaixo o exemplo:

  |('P2_n ', 'VocÃª pretende mudar de emprego nos prÃ³ximos 6 meses?') | A pessoa vai sair da empresa?|
  |------------------------------------------------------------------|-------------------------------|
  |Estou em busca de oportunidades dentro ou fora do Brasil | Sim (1) |
  |Estou em busca de oportunidades, mas apenas fora do Brasil | Sim (1) |
  |NÃ£o estou buscando e nÃ£o pretendo mudar de emprego nos prÃ³ximos 6 meses | NÃ£o (0) |
  |NÃ£o estou buscando, mas me considero aberto a outras oportunidades | Sim (1) |
  |(vazio) | (vazio por enquanto) | 

  CÃ³digo usado no excel: 
  > =SE(Ã‰CÃ‰L.VAZIA(L2);
    SE(ALEATÃ“RIO()<=0,75;1;0);
    SE(OU(
        L2="Estou em busca de oportunidades dentro ou fora do Brasil";
        L2="Estou em busca de oportunidades, mas apenas fora do Brasil";
        L2="NÃ£o estou buscando, mas me considero aberto a outras oportunidades"
    );1;0))
  
  para a linha 2. Nas linhas subsequentes o cÃ³digo Ã© o mesmo, sÃ³ alterando a linha.

  
  #### 3.3.4. Preenchimento de valores ausentes de forma proporcional ou por estatÃ­stica do grupo remoÃ§Ã£o de linhas. 
  * VocÃª deve ter percebido que os cÃ³digos citados acima apresentam algo a mais que sÃ³ transformar dados qualitativos em quantitativos ou outras funÃ§Ãµes como a de agrupamento.
  Foram implementados nos cÃ³digos a tarefa de preencherem os dados faltantes proporcionalmente Ã  frequÃªncia com que os dados reais aparecem.
  * Vamos analisar coluna por coluna:
  * `('P1_a_1 ', 'Faixa idade')`:
    - nÃ£o apresenta dados faltantes.
  * `('P1_b ', 'Genero')`:
    - NÃ£o apresenta dados faltantes. Entretanto, apresenta dados que podem nÃ£o contribuir para a anÃ¡lise, como `Outro` e `Prefiro nÃ£o informar`. Como esses dados sÃ£o quase       insignificantes na base (veja a tabela abaixo), resolvi tirar.

  
  
   |('P1_b ', 'Genero')|	Porcentagem do total geral) |
   |-------------------|---------------------------------|
   |Feminino|	24,43%|
   |Masculino|	75,10%|
   |Outro	|0,17%|
   |Prefiro nÃ£o informar|	0,30%|
  
  * `('P2_f ', 'Cargo Atual')`:
    - Nos dados faltantes, adicionei "NÃ£o foi informado"
  
  * `('P2_g ', 'Nivel')`
    - Haviam muitos dados faltantes. Para isso, distribuÃ­ proporcionalmente conforme eles aparecem realmente pelos dados faltantes, jÃ¡ que representam 27% de toda base e seria ruim removÃª-los. Na base, eles aparecem de forma equilibrada, confira:

  |NÃ­vel   |Quantidade|
  |--------|----------|
  |JÃºnior	| 1046|
  |Pleno	| 1392|
  |SÃªnior	| 1419|
  |(vazio) | 1437|	

  * `('P2_r ', 'Atualmente qual a sua forma de trabalho?')`
    - Haviam muitos dados faltantes. Para isso, distribuÃ­ proporcionalmente conforme eles aparecem realmente pelos dados faltantes, jÃ¡ que representam 10% de toda base e seria ruim removÃª-los. Na base, eles aparecem de forma que o Modelo 100% remoto se destaca. Confira:
   
  |('P2_r ', 'Atualmente qual a sua forma de trabalho?')|	Porcentaegm|
  |-----------------------------------------------------|--------------------------------|
  |Modelo 100% presencial	|14,93%|
  |Modelo 100% remoto	|41,58%|
  |Modelo hÃ­brido com dias fixos de trabalho presencial|	14,93%|
  |Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)|	18,36%|
  |(vazio)	|10,20%|
   
  * `('P2_s ', 'Qual a forma de trabalho ideal para vocÃª?')`
    - Haviam muitos dados faltantes. Para isso, distribuÃ­ proporcionalmente conforme eles aparecem realmente pelos dados faltantes, jÃ¡ que representam 10% de toda base e seria ruim removÃª-los. Na base, eles aparecem de forma que o Modelo 100% remoto se destaca mais uma vez. Confira:
  
  |('P2_s ', 'Qual a forma de trabalho ideal para vocÃª?')|	Porcentagem|
  |------------------------------------------------------|--------------|
  |Modelo 100% presencial|	1,81%|
  |Modelo 100% remoto|	40,13%|
  |Modelo hÃ­brido com dias fixos de trabalho presencial|	7,35%|
  |Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)|	40,51%|
  |(vazio)	|10,20%|
  
  #### 3.3.5. CriaÃ§Ã£o de uma nova feature: `Estou no trabalho ideal para mim?`
  * Aqui a ideia foi pegar a coluna do trabalho que a pessoa estÃ¡, juntamente com a coluna do trabalho que seria ideal para ela. Se a resposta for sim, eu criei uma nova coluna       simbolizando a satisfaÃ§Ã£o pessoal da pessoa com seu trabalho. Se ela estÃ¡ no trabalho que Ã© ideal para ela, as possibilidades de ela querer sair sÃ£o reduzidas. Exemplo:

  |Forma de trabalho atual | Forma de trabalho ideal | Estou no trabalho ideal para mim? |
  |-------------------------------------------------------------------|---------------------------------------------|-----------|
  |Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)|Modelo 100% remoto| NÃ£o = 0|
  |Modelo 100% remoto |Modelo 100% remoto| Sim = 1|
  |Modelo 100% remoto|Modelo 100% remoto| Sim = 1|
  |Modelo 100% remoto|Modelo 100% remoto| Sim = 1|
  |Modelo hÃ­brido com dias fixos de trabalho presencial|Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)| NÃ£o = 0|
  |Modelo 100% remoto|Modelo 100% remoto| Sim = 1|
  |Modelo hÃ­brido com dias fixos de trabalho presencial|Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)| NÃ£o = 0|
  |Modelo hÃ­brido flexÃ­vel|Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)| NÃ£o = 0|
  |Modelo 100% presencial|Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)| NÃ£o = 0|

  CÃ³digo para excel usado: 
  > =SE(O2=Q2;1;0)

  para a linha 2. Nas linhas subsequentes o cÃ³digo Ã© o mesmo, sÃ³ alterando a linha.

  
### 3.6. Base Refinada

* ApÃ³s todas essas alteraÃ§Ãµes, a base ficou assim: [base para modelo preditivo refinada.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/blob/main/assets/data/Base_principal_State_of_data_2023/State_of_data_BR_2023_Kaggle%20-%20df_survey_2023.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/blob/main/assets/data/Analise_exploratoria_perguntas_orientadas_a_dados/Pergunta_orientada_a_dados%20(3)/base%20para%20modelo%20preditivo%20refinada.csv))

  - Base original: 5294 linhas, 550 colunas
  - Base filtrada: 5294 linhas, 10 colunas
  - Base refinada: 5294 linhas, 18 colunas (apÃ³s feature engineering)

* ObservaÃ§Ãµes:

  - Todas as etapas foram documentadas e os cÃ³digos utilizados estÃ£o nos blocos acima.
  - As transformaÃ§Ãµes garantem que os dados estejam prontos para a modelagem preditiva.
  
---
## 4. ConstruÃ§Ã£o do 1Âº Modelo Induzido

Usei o Google Colab, programando em Python. CÃ³digo usado:


> from google.colab import files
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import csv
uploaded = files.upload()
nome_arquivo = next(iter(uploaded))
data = pd.read_csv(
    nome_arquivo,
    sep=';',
    engine='python',
    encoding='latin1',
    quoting=csv.QUOTE_NONE
)
print("Dados carregados com sucesso!\n")
print(data.head())
print("\nColunas detectadas:")
print(data.columns.tolist())
target = 'PretenÃ§Ã£o de sair - TARGET'
features = [
    'MÃ©dia_Idades',
    "('P1_b ', 'Genero')",
    'Agrupamento_Cargo_Atual',
    'NÃ­vel_Ordinal',
    'MÃ‰DIA_FAIXA_SALARIAL',
    'SatisfaÃ§Ã£o na empresa dados preenchidos',
    'Forma de trabalho com dados faltantes preenchidos',
    'Estou no trabalho que quero?'
]
data = data.dropna(subset=[target])
X = data[features].copy()
y = data[target].copy()
X['MÃ©dia_Idades'] = (
    X['MÃ©dia_Idades']
      .astype(str)
      .str.replace(',', '.')
      .astype(float)
)
X['NÃ­vel_Ordinal'] = X['NÃ­vel_Ordinal'].astype(float)
X['MÃ©dia_Idades'] = X['MÃ©dia_Idades'].fillna(X['MÃ©dia_Idades'].mean())
X['NÃ­vel_Ordinal'] = X['NÃ­vel_Ordinal'].fillna(X['NÃ­vel_Ordinal'].median())
X = pd.get_dummies(
    X,
    columns=[
        "('P1_b ', 'Genero')",
        'Agrupamento_Cargo_Atual',
        'Forma de trabalho com dados faltantes preenchidos'
    ],
    drop_first=True
    )
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(f'\nAcurÃ¡cia:  {accuracy_score(y_test, y_pred):.2f}')
print(f'PrecisÃ£o:  {precision_score(y_test, y_pred):.2f}')
print(f'Recall:    {recall_score(y_test, y_pred):.2f}')
print(f'F1-score:  {f1_score(y_test, y_pred):.2f}')
plt.figure(figsize=(20,10))
plot_tree(
    model,
    feature_names=X.columns,
    class_names=['Ficar','Sair'],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("Ãrvore de DecisÃ£o â€“ IntenÃ§Ã£o de SaÃ­da")
plt.show()

### ExplicaÃ§Ã£o do CÃ³digo de Modelagem Preditiva

Este cÃ³digo implementa um fluxo completo de modelagem preditiva usando uma Ãrvore de DecisÃ£o para prever a intenÃ§Ã£o de saÃ­da de colaboradores. Veja o passo a passo:

* 1. ImportaÃ§Ã£o das Bibliotecas
`python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score`

  - `pandas`: manipulaÃ§Ã£o e anÃ¡lise de dados.

  - `sklearn.model_selection.train_test_split`: separa os dados em conjuntos de treino e teste.

  - `sklearn.tree.DecisionTreeClassifier`: algoritmo de Ã¡rvore de decisÃ£o para classificaÃ§Ã£o.

  - `sklearn.metrics`: mÃ©tricas para avaliaÃ§Ã£o do modelo.

* 2. Carregamento da Base de Dados
`python
data = pd.read_csv('base para modelo preditivo refinada.csv')
print(data.head())`
  - Carrega o arquivo CSV com os dados jÃ¡ refinados e prontos para modelagem.

  - Exibe as primeiras linhas para conferÃªncia.

* 3. DefiniÃ§Ã£o das VariÃ¡veis
`target = 'PretenÃ§Ã£o de sair - TARGET'
features = [
    'MÃ©dia_Idades',
    'Genero',
    'Agrupamento_Cargo_Atual',
    'NÃ­vel de forma Ordinal',
    'MÃ‰DIA_FAIXA_SALARIAL',
    'SatisfaÃ§Ã£o na empresa dados preenchidos',
    'Forma de trabalho com dados faltantes preenchidos',
    'Estou no trabalho ideal para mim?'
]`

  - X = data[features]
  - y = data[target]
  - *target*: coluna que indica se o colaborador pretende sair (variÃ¡vel a ser prevista).

  - features: lista das colunas preditoras utilizadas pelo modelo.

  - X: DataFrame com as variÃ¡veis preditoras.

  - y: SÃ©rie com a variÃ¡vel alvo.

* 4. DivisÃ£o dos Dados em Treinamento e Teste

`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`
  - Separa os dados em 80% para treino e 20% para teste, garantindo aleatoriedade reprodutÃ­vel (random_state=42).

* 5. Treinamento do Modelo
`model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)`
  - Inicializa o modelo de Ãrvore de DecisÃ£o.

  - Treina o modelo usando os dados de treino.

* 6. RealizaÃ§Ã£o de PrevisÃµes
`y_pred = model.predict(X_test)`
  - Utiliza o modelo treinado para prever a intenÃ§Ã£o de saÃ­da nos dados de teste.

* 7. AvaliaÃ§Ã£o do Modelo
`accuracy = accuracy_score(y_test, y_pred)
print(f'AcurÃ¡cia do modelo: {accuracy:.2f}')
precision = precision_score(y_test, y_pred)
print(f'PrecisÃ£o do modelo: {precision:.2f}')
recall = recall_score(y_test, y_pred)
print(f'Recall do modelo: {recall:.2f}')
f1 = f1_score(y_test, y_pred)
print(f'F1-score do modelo: {f1:.2f}')`

  - *AcurÃ¡cia*: proporÃ§Ã£o de previsÃµes corretas.

  - *PrecisÃ£o*: entre as previsÃµes positivas, quantas estavam corretas.

  - *Recall*: entre os casos positivos reais, quantos foram identificados corretamente.

  - *F1-score*: mÃ©dia harmÃ´nica entre precisÃ£o e recall.

---

## 5. Resultados

### AvaliaÃ§Ã£o do modelo:

  - AcurÃ¡cia = 0.68
  - PrecisÃ£o = 0.80
  - Recall = 0.78
  - F1-score = 0.79
  - cm = [[98,159],[178,619]]

### Ãrvore de decisÃ£o:

![arvore of the decisions](https://github.com/user-attachments/assets/5f882d5c-2e05-4c0d-9495-a391e5899638)


### Matriz de confusÃ£o:

![matriz confusao](https://github.com/user-attachments/assets/a0b3fdd8-f068-4555-9f72-40cff6184e96)




# ğŸ Sprint 4 ATUALIZADA â€“ RelatÃ³rio Completo

## 1. IntroduÃ§Ã£o
**Objetivo do projeto:**
Antecipar a intenÃ§Ã£o de saÃ­da (turnover) de colaboradores no setor de tecnologia, fornecendo ao RH indicadores para programas de retenÃ§Ã£o.

**Por que este modelo?**

- Identificar riscos de desligamento antecipadamente
- Minimizar custos de substituiÃ§Ã£o e treinamento
- Melhorar estratÃ©gias de engajamento e satisfaÃ§Ã£o
- Em comparaÃ§Ã£o com o a versÃ£o anterior, este modelo visa aumentar a acurÃ¡cia, a precisÃ£o, o recall, o f1-score, AUROC, e aumentar os acertos da Matriz de ConfusÃ£o, proporcionalmente ao conjunto analisado e testado.

## 2. Finalidade e explicaÃ§Ãµes de o que foi feito
> â€œQuero otimizar o modelo preditivo anteriorâ€

- **O que mudou em comparaÃ§Ã£o Ã  versÃ£o anterior do modelo?**
- Adicionei mais colunas: `('P1_a ', 'Idade')`(achei as idades numÃ©ricas sem estarem em faixas), `('P2_d ', 'Gestor?')`(vou remover todos os gestores porque o foco sÃ£o os funcionÃ¡rios que pretendem sair), `('P0', 'id')`(para me ajudar nas anÃ¡lises no excel (vou remover posteriormente na hora do modelo)).
- Removi colunas: `('P1_a_1 ', 'Faixa idade')`(achei as idades numÃ©ricas sem estarem em faixas), `MÃ©dia_Idades`(pelo mesmo motivo).
- Considerei remover todas as linhas as quais suas respectivas colunas continham algum atributo faltante ao invÃ©s de prever o dado vazio. (fiz isso na prÃ³pria tabela do excel).
- Anteriormente, estive usando o Google Colab. Agora, adotei o Jupyter Notebook.
- Eu tinha separado 75% do modelo para aprendizado e 25% para teste. Mas agora separei 80% para aprendizado e 20% para teste.

- **O que foi mantido?**
- Optei por manter o algoritmo de Ã¡rvore de decisÃ£o, uma vez que quero prever um conceito, mesmo que seja booleano (no caso, sair ou ficar, 1/0)
- O TARGET - `PretenÃ§Ã£o de sair - TARGET`
- As outras colunas nÃ£o citadas, como podemos ver na tabela abaixo: 


|      **Coluna**       | **Tipo de dado** | **Atributos correspondentes** | **AlteraÃ§Ã£o** |
|-----------------------|------------------|-------------------------------|---------------|
|     `Faixa idade` | Qualitativo intervalar |17-21 <br>22-24<br>25-29<br>30-34<br>35-39<br>40-44<br>45-49<br>50-54<br>55+ | Removido |
|     `GÃªnero` |  Qualitativo | Feminino<br>Masculino<br>Outro<br>Prefiro nÃ£o informar | Mantido |
|  `Cargo Atual` | Qualitativo | Analista de BI/BI Analyst<br>Analista de Dados/Data Analyst<br>Analista de InteligÃªncia de Mercado/Market Intelligence<br>Analista de NegÃ³cios/Business Analyst<br>Analista de Suporte/Analista TÃ©cnico<br>Analytics Engineer<br>Cientista de Dados/Data Scientist<br>Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)<br>DBA/Administrador de Banco de Dados<br>Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas<br>Economista<br>Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect<br>Engenheiro de Machine Learning/ML Engineer/AI Engineer<br>EstatÃ­stico<br>Outra OpÃ§Ã£o<br>Outras Engenharias (nÃ£o inclui dev)<br>Professor/Pesquisador<br>(vazio) | Mantido |
|   `NÃ­vel` | Qualitativo |JÃºnior<br>Pleno<br>SÃªnior<br>(vazio) | Mantido |
|   `Faixa salarial` | Qualitativo intervalar | Acima de R$ 40.001/mÃªs<br>de R$ 1.001/mÃªs a R$ 2.000/mÃªs<br>de R$ 1001/mÃªs a R$ 2.000/mÃªs<br>de R$ 12.001/mÃªs a R$ 16.000/mÃªs<br>de R$ 16.001/mÃªs a R$ 20.000/mÃªs<br>de R$ 2.001/mÃªs a R$ 3.000/mÃªs<br>de R$ 20.001/mÃªs a R$ 25.000/mÃªs<br>de R$ 25.001/mÃªs a R$ 30.000/mÃªs<br>de R$ 3.001/mÃªs a R$ 4.000/mÃªs<br>de R$ 30.001/mÃªs a R$ 40.000/mÃªs<br>de R$ 4.001/mÃªs a R$ 6.000/mÃªs<br>de R$ 6.001/mÃªs a R$ 8.000/mÃªs<br>de R$ 8.001/mÃªs a R$ 12.000/mÃªs<br>Menos de R$ 1.000/mÃªs<br>(vazio) | Mantido |
|   `SatisfaÃ§Ã£o empresa` | Bool | 0<br>1<br>(vazio) | Mantido |
|   `PretensÃ£o mudar emprego` | Qualitativo | Estou em busca de oportunidades dentro ou fora do Brasil<br>Estou em busca de oportunidades, mas apenas fora do Brasil<br>NÃ£o estou buscando e nÃ£o pretendo mudar de emprego nos prÃ³ximos 6 meses<br>NÃ£o estou buscando, mas me considero aberto a outras oportunidades<br>(vazio) | Mantido |
|     `Forma de trabalho` | Qualitativo | Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo hÃ­brido com dias fixos de trabalho presencial<br>Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)<br>(vazio) | Mantido |
|     `Forma de trabalho ideal` | Qualitativo | Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo hÃ­brido com dias fixos de trabalho presencial<br>Modelo hÃ­brido flexÃ­vel (o funcionÃ¡rio tem liberdade para escolher quando estar no escritÃ³rio presencialmente)<br>(vazio) | Mantido |
| `ID` | Qualitativo | cÃ³digos especÃ­ficos como 001b2d1qtli8t9z7oqgdhj001b2d4i0g | Acrescido |
|`Gestor?` | Bool | 0 ou 1 | Acrescido |
|`Idade` | Quantitativo discreto | NÃºmeros inteiros entre 18 e 73 incluindo os extremos | Acrescido |


---

- Como dessa vez eu vou manter as cÃ©lulas vazias vazias para entÃ£o removÃª-las, os cÃ³digos que adicionei Ã s colunas mudaram: 

| **Qual coluna da base 2.0?** |**Nome da coluna na base 2.0** | **CÃ³digo usado na filtragem dos dados** |
|------------------------------|-------------------------------|-----------------------------------------|
| A | `('P0', 'id')` | - |
| B | `('P1_a ', 'Idade')` | - |
| C | `('P1_b ', 'Genero')`| - |
| D | `('P1_e ', 'experiencia_profissional_prejudicada')` | - |
| E | `EXPERIÃŠNCIA PREJUDICADA SIM OU NAO` | =SE(Ã‰CÃ‰L.VAZIA(D2);; SE(D2="NÃ£o acredito que minha experiÃªncia profissional seja afetada devido a esses fatores";0;1)) |
| F | `('P2_d ', 'Gestor?')` | - |
| G | `('P2_f ', 'Cargo Atual')` | - |
| H | `AGRUPAMENTO CARGOS` | =SE(Ã‰CÃ‰L.VAZIA(G2);"NÃ£o informado"; SE(OU(G2="Cientista de Dados/Data Scientist";G2="Analista de Dados/Data Analyst";G2="Analista de BI/BI Analyst";G2="Analista de InteligÃªncia de Mercado/Market Intelligence");"AnÃ¡lise de Dados"; SE(OU(G2="Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect";G2="Analytics Engineer");"Engenharia de Dados"; SE(G2="Engenheiro de Machine Learning/ML Engineer/AI Engineer";"ML/IA"; SE(G2="Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas";"Desenvolvimento"; SE(G2="Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)";"Produto"; SE(OU(G2="EstatÃ­stico";G2="Economista");"CientÃ­fico/Quantitativo"; SE(OU(G2="DBA/Administrador de Banco de Dados";G2="Analista de Suporte/Analista TÃ©cnico");"Infraestrutura"; SE(G2="Outras Engenharias (nÃ£o inclui dev)";"Outras Engenharias"; SE(G2="Professor/Pesquisador";"AcadÃªmico"; SE(G2="Analista de NegÃ³cios/Business Analyst";"NegÃ³cios"; SE(G2="Outra OpÃ§Ã£o";"Outro";"Outro")))))))))))) |
| I | `('P2_h ', 'Faixa salarial')` | - |
| J | `MÃ‰DIA FAIXA SALARIAL` | =SE(Ã‰CÃ‰L.VAZIA(I2);; SE(I2="Acima de R$ 40.001/mÃªs";45000; SE(I2="de R$ 1.001/mÃªs a R$ 2.000/mÃªs";1500; SE(I2="de R$ 1001/mÃªs a R$ 2.000/mÃªs";1500; SE(I2="de R$ 12.001/mÃªs a R$ 16.000/mÃªs";14000; SE(I2="de R$ 16.001/mÃªs a R$ 20.000/mÃªs";18000; SE(I2="de R$ 2.001/mÃªs a R$ 3.000/mÃªs";2500; SE(I2="de R$ 20.001/mÃªs a R$ 25.000/mÃªs";22500; SE(I2="de R$ 25.001/mÃªs a R$ 30.000/mÃªs";27500; SE(I2="de R$ 3.001/mÃªs a R$ 4.000/mÃªs";3500; SE(I2="de R$ 30.001/mÃªs a R$ 40.000/mÃªs";35000; SE(I2="de R$ 4.001/mÃªs a R$ 6.000/mÃªs";5000; SE(I2="de R$ 6.001/mÃªs a R$ 8.000/mÃªs";7000; SE(I2="de R$ 8.001/mÃªs a R$ 12.000/mÃªs";10000; SE(I2="Menos de R$ 1.000/mÃªs";500;""))))))))))))))) |
| K | `('P2_g ', 'Nivel')` | - |
| L | `NÃVEL COM NÃšMEROS ORDINAIS` | =SE(K2="JÃºnior";0; SE(K2="Pleno";1; SE(K2="SÃªnior";2; SE(Ã‰CÃ‰L.VAZIA(K2);ALEATÃ“RIOENTRE(0;2);"""")))) |
| M | `('P2_k ', 'VocÃª estÃ¡ satisfeito na sua empresa atual?')` | - |
| N | `('P2_n ', 'VocÃª pretende mudar de emprego nos prÃ³ximos 6 meses?')` | - |
| O | `PRETENDE SAIR SIM OU NAO - TARGET` | =SE(Ã‰CÃ‰L.VAZIA(N2); SE(ALEATÃ“RIO()<=0,75;1;0); SE(OU(N2="Estou em busca de oportunidades dentro ou fora do Brasil"; N2="Estou em busca de oportunidades, mas apenas fora do Brasil"; N2="NÃ£o estou buscando, mas me considero aberto a outras oportunidades");1;0)) |
 | P | `('P2_r ', 'Atualmente qual a sua forma de trabalho?')` | - |
 | Q | `('P2_s ', 'Qual a forma de trabalho ideal para vocÃª?')` | - |
 | R | `ESTOU NO TRABALHO IDEAL?` | =SE(P2=Q2;1;0) |

Esta Ã© a base refinada 2.0
---

- Para a base refinada 2.1, removi as colunas que nÃ£o ajudariam na anÃ¡lise preditiva, removi todas as linhas com o atributo `1` correspondente Ã  coluna `Gestor?`, depois removi a coluna `Gestor?` e removi todas as linhas com atributos faltantes, ficando assim:

Base 2.1: atributos: `('P1_a ', 'Idade')`, `('P1_b ', 'Genero')`, `EXPERIÃŠNCIA PREJUDICADA SIM OU NAO`, `AGRUPAMENTO CARGOS`, `MÃ‰DIA FAIXA SALARIAL`, `NÃVEL COM NÃšMEROS ORDINAIS`, `('P2_k ', 'VocÃª estÃ¡ satisfeito na sua empresa atual?')`, `PRETENDE SAIR SIM OU NAO - TARGET`, `ESTOU NA FORMA DE TRABALHO IDEAL?`.

Esta Ã© a base refinada 2.1
---

## 3. Acesso Ã s bases de dados

**Base refinada 2.0**
- [BASE SPRINT 4 VERSAO 2.0.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/commit/ed36a3a91a3095fc8c5fae1bcc7e1fb274cc9beb#diff-10b6f2cedd9707c28d337d832fd8dbc297debcce65626a4b2f86fd78f9b67988)

**Base refinada 2.1**
- [BASE SPRINT 4 VERSAO 2.1.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/commit/c49d6555503f50f1eb98dc6c77e0e72bea512f7e)

| Base de dados | NÃºmero de linhas | NÃºmero de colunas |
|-----------------|------------------|-------------------|
| State of Data Brazil | 5294 | 399 |
| Refinada 1.0 | 5294 | 10 |
| Refinada 1.1 | 5294 | 18 |
| Refinada 2.0 | 5294 | 18 |
| Refinada 2.1 | 3857 | 9 |


---

## 4. Resultados

## 4.1. Modelo Anterior (Ã¡rvore de decisÃ£o padrÃ£o)

- Accuracy: 0.68
- Precision: 0.80
- Recall: 0.78
- F1-score: 0.79

Matriz de ConfusÃ£o:

| | Modelo disse que ficou | Modelo disse que saiu | 
|-|------------------------|-----------------------|
| Ficou | 98 | 159 |
| Saiu | 178 | 619 |

 
## 4.2. Modelo Atual (Ã¡rvore otimizada via GridSearchCV)

- Melhores parÃ¢metros:
> criterion='gini', max_depth=None, min_samples_leaf=1, class_weight=None

- Accuracy: 0.7552 (+11,7 pp)
- Precision: 0.7599 (â€“4,0 pp)
- Recall: 0.9880 (+20,8 pp)
- F1-score: 0.8591 (+6,9 pp)
- AUROC: 0.6878

Matriz de ConfusÃ£o:

| | Modelo disse que ficou | Modelo disse que saiu | 
|-|------------------------|-----------------------|
| Ficou | 7 | 182 |
| Saiu | 7 | 576 |



### 4.2.1. Melhorias

- Recall saltou de 78 % para 98,8 %: o modelo quase nÃ£o perde nenhum colaborador que vai sair.
- F1 subiu de 0,79 para 0,859: melhor equilÃ­brio geral.
- Accuracy cresceu de 0,68 para 0,755: bem acima do baseline de ~0,75.

### 4.2.2. Pioras
- Precision caiu de 0,80 para 0,76, aumentando falsos positivos (de 159 em 1024 (15%) para 182 em 772 (23%)).

- Justificativa: ao priorizar recall, o modelo ficou mais â€œconservadorâ€ em prever saÃ­da, aceitando mais alarmes falsos para nÃ£o perder verdadeiros turnover â€” estratÃ©gia adequada quando perder um turnover real Ã© mais custoso que lidar com intervenÃ§Ãµes desnecessÃ¡rias.

---

## 5. DiscussÃ£o e ConclusÃ£o
Trade-off recall Ã— precision:
O novo modelo opta por maximizar recall, garantindo que quase ninguÃ©m que tenha intenÃ§Ã£o de sair seja ignorado.

### Impacto prÃ¡tico:

- Vantagem: RH consegue agir sobre praticamente 100 % dos potenciais turnover.
- Custo: maior nÃºmero de falsos positivos (intervenÃ§Ãµes que nÃ£o eram necessÃ¡rias).

### RecomendaÃ§Ã£o:
Este modelo Ã© ideal quando o custo de perder um turnover (e permitir a saÃ­da sem reaÃ§Ã£o) Ã© maior que o custo de abordagens preventivas em falsos alarmes.

---

## 6. Reprodutibilidade
* CÃ³digo em python 3 feito no jupyter notebook utilizado para o modelo 2.0 da SPRINT 4:


```
# 0. InstalaÃ§Ã£o (executar apenas se necessÃ¡rio)
!pip install --upgrade pandas scikit-learn matplotlib

# 1. ImportaÃ§Ãµes
import os
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.dummy import DummyClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn import metrics

# 2. Carregar CSV (mesmo diretÃ³rio do notebook)
filename = 'BASE SPRINT 4 VERSAO 2.1.csv'
df = pd.read_csv(filename, sep=';', encoding='latin1')

# 3. Renomear colunas para simplificar
df.rename(columns={
    "('P1_a ', 'Idade')": "Idade",
    "EXPERIÃŠNCIA PREJUDICADA SIM OU NAO": "ExperienciaPrejudicada",
    "AGRUPAMENTO CARGOS": "AgrupamentoCargos",
    "MÃ‰DIA FAIXA SALARIAL": "MediaFaixaSalarial",
    "NÃVEL COM NÃšMEROS ORDINAIS": "NivelOrdinal",
    "('P2_k ', 'VocÃª estÃ¡ satisfeito na sua empresa atual?')": "Satisfeito",
    "PRETENDE SAIR SIM OU NAO - TARGET": "PretendeSair",
    "ESTOU NA FORMA DE TRABALHO IDEAL?": "TrabalhoIdeal"
}, inplace=True)

# 4. Definir features e target
feature_cols = [
    'Idade', 'ExperienciaPrejudicada', 'AgrupamentoCargos',
    'MediaFaixaSalarial', 'NivelOrdinal', 'Satisfeito', 'TrabalhoIdeal'
]
X = df[feature_cols]
y = df['PretendeSair']

# 5. PrÃ©-processamento: One-Hot Encoding em AgrupamentoCargos
preproc = ColumnTransformer([
    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['AgrupamentoCargos'])
], remainder='passthrough')
X_proc = preproc.fit_transform(X)

# 6. Dividir treino/teste 80% / 20% (estratificado)
X_train, X_test, y_train, y_test = train_test_split(
    X_proc, y, test_size=0.20, random_state=42, stratify=y
)

# 7. Baseline DummyClassifier
baseline = DummyClassifier(strategy='most_frequent', random_state=42)
baseline.fit(X_train, y_train)
y_base = baseline.predict(X_test)
print("=== Baseline Metrics ===")
print("Accuracy :", metrics.accuracy_score(y_test, y_base))
print("Precision:", metrics.precision_score(y_test, y_base, zero_division=0))
print("Recall   :", metrics.recall_score(y_test, y_base, zero_division=0))
print("F1 Score :", metrics.f1_score(y_test, y_base, zero_division=0))
print()

# 8. Hyperparameter Tuning com GridSearchCV
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [3, 5, 7, None],
    'min_samples_leaf': [1, 5, 10, 20],
    'class_weight': [None, 'balanced']
}
dt = DecisionTreeClassifier(random_state=42)
grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1)
grid.fit(X_train, y_train)

print("Melhores parÃ¢metros:", grid.best_params_)
print("Melhor F1 em CV :", grid.best_score_, "\n")

# 9. Avaliar o melhor modelo no conjunto de teste
best_tree = grid.best_estimator_
y_pred = best_tree.predict(X_test)
y_proba = best_tree.predict_proba(X_test)[:, 1]

print("=== Test Metrics (Best Tree) ===")
print("Accuracy :", metrics.accuracy_score(y_test, y_pred))
print("Precision:", metrics.precision_score(y_test, y_pred, zero_division=0))
print("Recall   :", metrics.recall_score(y_test, y_pred, zero_division=0))
print("F1 Score :", metrics.f1_score(y_test, y_pred, zero_division=0))
print("AUROC    :", metrics.roc_auc_score(y_test, y_proba))
print()

# 10. Matriz de ConfusÃ£o
cm = metrics.confusion_matrix(y_test, y_pred, labels=[0,1])
disp = metrics.ConfusionMatrixDisplay(cm, display_labels=['Fica (0)', 'Sai (1)'])
disp.plot(cmap=plt.cm.Blues)
plt.show()

# 11. Plot & exportar a Ã¡rvore de decisÃ£o
plt.figure(figsize=(30,15), dpi=100)
plot_tree(
    best_tree,
    feature_names=preproc.get_feature_names_out(),
    class_names=['Fica','Sai'],
    filled=True, rounded=True, fontsize=12
)
plt.title("Ãrvore de DecisÃ£o Otimizada")
plt.savefig("decision_tree.png", dpi=300)
plt.show()

print("âœ… Ãrvore exportada: decision_tree.png")

```
### Matriz de confusÃ£o:
![matriz de confusao 2](https://github.com/user-attachments/assets/2c3897dd-070b-4d92-90aa-d8bb22893583)

### Ãrvore de decisÃ£o: 
![arvore de decisao 2](https://github.com/user-attachments/assets/5ef9a7f3-7c81-4d12-ab86-ebc9ead490a5)


---
# Sprint 4.1 (pequeno bÃ´nus)
* Fiz uma alteraÃ§Ã£o no cÃ³digo para que ele me mostre as informaÃ§Ãµes separadamente dos Ã­ndices na parte de treinamendo do modelo e na parte de teste.
CÃ³digo utilizado:
```
# ğŸ““ Notebook: v2.3 â€“ Poda para Reduzir Overfitting

# 1. InstalaÃ§Ã£o (se necessÃ¡rio)
!pip install scikit-learn imbalanced-learn matplotlib seaborn graphviz

# 2. Imports
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, classification_report
)
from imblearn.over_sampling import SMOTE

# 3. Carregar dados
df = pd.read_csv('BASE SPRINT 4 VERSAO 2.1.csv', sep=';', encoding='latin1')
df = df.rename(columns={
    "('P1_a ', 'Idade')"     : "Idade",
    "EXPERIÃŠNCIA PREJUDICADA SIM OU NAO":"ExperienciaPrejudicada",
    "AGRUPAMENTO CARGOS"     : "AgrupamentoCargos",
    "MÃ‰DIA FAIXA SALARIAL"   : "MediaFaixaSalarial",
    "NÃVEL COM NÃšMEROS ORDINAIS":"NivelOrdinal",
    "('P2_k ', 'VocÃª estÃ¡ satisfeito na sua empresa atual?')":"Satisfeito",
    "PRETENDE SAIR SIM OU NAO - TARGET":"PretendeSair",
    "ESTOU NA FORMA DE TRABALHO IDEAL?":"TrabalhoIdeal"
})
df = df[['Idade','ExperienciaPrejudicada','AgrupamentoCargos',
         'MediaFaixaSalarial','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']].dropna()

# 4. ConversÃ£o de tipos
df['Idade'] = df['Idade'].astype(str).str.replace(',','.').astype(float)
df['MediaFaixaSalarial'] = df['MediaFaixaSalarial'].astype(str).str.replace(',','.').astype(float)
df['NivelOrdinal'] = df['NivelOrdinal'].astype(float)
df['Satisfeito'] = df['Satisfeito'].astype(int)
df['TrabalhoIdeal'] = df['TrabalhoIdeal'].astype(int)
df['PretendeSair'] = df['PretendeSair'].astype(int)

# 5. One-Hot Encoding em AgrupamentoCargos
preproc = ColumnTransformer([
    ('ohe', OneHotEncoder(handle_unknown='ignore'), ['AgrupamentoCargos'])
], remainder='passthrough')
X = preproc.fit_transform(df.drop('PretendeSair', axis=1))
y = df['PretendeSair']

# 6. DivisÃ£o Treino/Teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 7. Balanceamento com SMOTE
sm = SMOTE(random_state=42)
X_tr, y_tr = sm.fit_resample(X_train, y_train)

print("DistribuiÃ§Ã£o TREINO antes SMOTE:", y_train.value_counts().to_dict())
print("DistribuiÃ§Ã£o TREINO apÃ³s SMOTE:", pd.Series(y_tr).value_counts().to_dict())

# 8. GridSearchCV com poda mais forte
param_grid = {
    'criterion'       : ['entropy'],
    'max_depth'       : [3, 4, 5],       # profundidades menores
    'min_samples_leaf': [10, 20, 50],    # folhas maiores
    'class_weight'    : ['balanced']
}
dt = DecisionTreeClassifier(random_state=42)
grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)
grid.fit(X_tr, y_tr)

best = grid.best_estimator_
print("\nâ†’ Melhores parÃ¢metros (poda):", grid.best_params_)
print("â†’ Melhor F1 CV:", grid.best_score_)

# 9. AvaliaÃ§Ã£o â€“ TREINO
y_tr_pred  = best.predict(X_tr)
y_tr_prob  = best.predict_proba(X_tr)[:,1]
print("\n=== MÃ©tricas no TREINO ===")
print(classification_report(y_tr, y_tr_pred, target_names=['Fica','Sai']))
print("AUC train:", roc_auc_score(y_tr, y_tr_prob))
cm_tr = confusion_matrix(y_tr, y_tr_pred)
sns.heatmap(cm_tr, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("ConfusÃ£o (Treino)"); plt.show()

# 10. AvaliaÃ§Ã£o â€“ TESTE
y_te_pred = best.predict(X_test)
y_te_prob = best.predict_proba(X_test)[:,1]
print("\n=== MÃ©tricas no TESTE ===")
print(classification_report(y_test, y_te_pred, target_names=['Fica','Sai']))
print("AUC test:", roc_auc_score(y_test, y_te_prob))
cm_te = confusion_matrix(y_test, y_te_pred)
sns.heatmap(cm_te, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("ConfusÃ£o (Teste)"); plt.show()

# 11. Plot Ã¡rvore limitada a 3 nÃ­veis
plt.figure(figsize=(16,8))
plot_tree(best,
          feature_names=preproc.get_feature_names_out(),
          class_names=['Fica','Sai'],
          filled=True, rounded=True,
          max_depth=3, fontsize=10)
plt.title("Ãrvore de DecisÃ£o (max_depth=3, min_samples_leafâ‰¥10)")
plt.show()
```
## RelatÃ³rio de ConclusÃ£o da atualizaÃ§Ã£o do modelo:

### 1. Contexto
- **Objetivo**: Prever a intenÃ§Ã£o de saÃ­da (`PretendeSair`) de profissionais de dados nÃ£o-gestores.
- **Dados**: Base refinada com colunas numÃ©ricas, categÃ³ricas binarizadas e variÃ¡veis derivadas (ex.: experiÃªncia prejudicada, satisfaÃ§Ã£o, trabalho ideal).
- **Tamanho**: 5.294 linhas originais â†’ apÃ³s remoÃ§Ã£o de NaNs e filtragem de gestores: ~4.654 linhas.

---

### 2. PrÃ©-processamento
1. **SeleÃ§Ã£o de colunas**:  
   - NumÃ©ricas: `Idade`, `MediaFaixaSalarial`, `NivelOrdinal`.  
   - BinÃ¡rias/booleanas: `ExperienciaPrejudicada`, `Satisfeito`, `TrabalhoIdeal`.  
   - CategÃ³rica nominal: `AgrupamentoCargos` (One-Hot Encoding).

2. **ConversÃ£o de tipos**  
   - SubstituiÃ§Ã£o de vÃ­rgulas por pontos em colunas numÃ©ricas.  
   - Cast para `float` ou `int` conforme apropriado.

3. **DivisÃ£o treino/teste**  
   - 80% treino, 20% teste, estratificado por `PretendeSair`.

4. **Balanceamento (SMOTE)**  
   - Antes:  
     - Classe â€œSaiâ€ (1): 2.327  
     - Classe â€œFicaâ€ (0): 757  
   - Depois SMOTE no treino:  
     - Ambas as classes com 2.327 exemplos.

---

## 3. Baseline
- **DummyClassifier (most_frequent)** no teste:
  - Accuracy: 24,5%  
  - Precision/Recall/F1: 0 â†’ demonstra que prever sempre a classe majoritÃ¡ria nÃ£o atende ao problema.

---

## 4. Treinamento & Tuning
- **Modelo**: `DecisionTreeClassifier`  
- **GridSearchCV** (5-fold) sobre:
  - `criterion`: `['gini','entropy']`  
  - `max_depth`: `[4,6,8,None]`  
  - `min_samples_leaf`: `[1,5,10]`  
  - `class_weight`: `[None, 'balanced']`

- **Melhores parÃ¢metros (SMOTE)**:  
{
`criterion`: `entropy`
`max_depth`: `None`
`min_samples_leaf`: 1
`class_weight`: `balanced`
}

- **F1 CV mÃ©dio**: 0.800

---

## 5. AvaliaÃ§Ã£o

### 5.1. Conjunto de Treino
| Classe | Precision | Recall | F1-score | Support |
|--------|-----------|--------|----------|---------|
| Fica   | 0.93      | 0.96   | 0.94     | 2327    |
| Sai    | 0.96      | 0.92   | 0.94     | 2327    |
| **Accuracy** | **0.94** |       |          |         |
| **AUC**      | 0.99   |       |          |         |

> **InterpretaÃ§Ã£o**: Excelente performance e balanceamento em treino â€“ indicativo de possÃ­vel _overfitting_.

### 5.2. Conjunto de Teste
| Classe | Precision | Recall | F1-score | Support |
|--------|-----------|--------|----------|---------|
| Fica   | 0.33      | 0.42   | 0.37     | 189     |
| Sai    | 0.79      | 0.72   | 0.76     | 583     |
| **Accuracy** | **0.65** |       |          |         |
| **AUC**      | 0.57   |       |          |         |

> **InterpretaÃ§Ã£o**:  
> - **Fica**: baixa precisÃ£o e recall â€“ o modelo acerta menos da metade dos que realmente ficaram.  
> - **Sai**: performance moderada, mas pior do que no treino.  
> - **AUC 0.57**: discriminador fraco em dados nÃ£o vistos.  

---

## 6. DiagnÃ³stico
- **Overfitting**: Treino (F1=0.94) Ã— Teste (F1 mÃ©dio=0.56)  
- **Classe minoritÃ¡ria (â€œFicaâ€) mal detectada** apesar de SMOTE.  
- **Ãrvore profunda + folhas pequenas** capturam ruÃ­do.

---

## 7. Pontos Fortes
- Pipeline organizado de _preprocessing_ â†’ SMOTE â†’ Tuning.  
- Baseline e mÃ©tricas completas (accuracy, precision, recall, f1, AUC) em treino e teste.  
- VisualizaÃ§Ã£o da Ã¡rvore simplificada e matrizes de confusÃ£o.

---

## 8. PrÃ³ximos Passos
1. **Podar a Ã¡rvore**: reduzir `max_depth` (ex.: 4 ou 5) e aumentar `min_samples_leaf` (ex.: 20+).  
2. **Experimentar ensembles**: Random Forest / Gradient Boosting.  
3. **Refinar features**: eliminar variÃ¡veis irrelevantes ou criar interaÃ§Ãµes.  
4. **Balanceamento alternativo**: SMOTE+Tomek, Borderline-SMOTE.  
5. **Validar com CV mais extenso** (cv=10) para mÃ©tricas mais estÃ¡veis.

---

> **ConclusÃ£o**: O modelo atual generaliza mal para a classe â€œFicaâ€. Ajustes de poda e uso de mÃ©todos ensemble devem melhorar o recall dessa classe e elevar o AUC no teste.
---
* Dito isso, alterei o cÃ³digo conforme o ponto 8, presente em 4.1:
```python
# ğŸ““ Notebook: v2.3 â€“ Poda para Reduzir Overfitting

# 1. InstalaÃ§Ã£o (se necessÃ¡rio)
!pip install scikit-learn imbalanced-learn matplotlib seaborn graphviz

# 2. Imports
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, classification_report
)
from imblearn.over_sampling import SMOTE

# 3. Carregar dados
df = pd.read_csv('BASE SPRINT 4 VERSAO 2.1.csv', sep=';', encoding='latin1')
df = df.rename(columns={
    "('P1_a ', 'Idade')"     : "Idade",
    "EXPERIÃŠNCIA PREJUDICADA SIM OU NAO":"ExperienciaPrejudicada",
    "AGRUPAMENTO CARGOS"     : "AgrupamentoCargos",
    "MÃ‰DIA FAIXA SALARIAL"   : "MediaFaixaSalarial",
    "NÃVEL COM NÃšMEROS ORDINAIS":"NivelOrdinal",
    "('P2_k ', 'VocÃª estÃ¡ satisfeito na sua empresa atual?')":"Satisfeito",
    "PRETENDE SAIR SIM OU NAO - TARGET":"PretendeSair",
    "ESTOU NA FORMA DE TRABALHO IDEAL?":"TrabalhoIdeal"
})
df = df[['Idade','ExperienciaPrejudicada','AgrupamentoCargos',
         'MediaFaixaSalarial','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']].dropna()

# 4. ConversÃ£o de tipos
df['Idade'] = df['Idade'].astype(str).str.replace(',','.').astype(float)
df['MediaFaixaSalarial'] = df['MediaFaixaSalarial'].astype(str).str.replace(',','.').astype(float)
df['NivelOrdinal'] = df['NivelOrdinal'].astype(float)
df['Satisfeito'] = df['Satisfeito'].astype(int)
df['TrabalhoIdeal'] = df['TrabalhoIdeal'].astype(int)
df['PretendeSair'] = df['PretendeSair'].astype(int)

# 5. One-Hot Encoding em AgrupamentoCargos
preproc = ColumnTransformer([
    ('ohe', OneHotEncoder(handle_unknown='ignore'), ['AgrupamentoCargos'])
], remainder='passthrough')
X = preproc.fit_transform(df.drop('PretendeSair', axis=1))
y = df['PretendeSair']

# 6. DivisÃ£o Treino/Teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 7. Balanceamento com SMOTE
sm = SMOTE(random_state=42)
X_tr, y_tr = sm.fit_resample(X_train, y_train)

print("DistribuiÃ§Ã£o TREINO antes SMOTE:", y_train.value_counts().to_dict())
print("DistribuiÃ§Ã£o TREINO apÃ³s SMOTE:", pd.Series(y_tr).value_counts().to_dict())

# 8. GridSearchCV com poda mais forte
param_grid = {
    'criterion'       : ['entropy'],
    'max_depth'       : [3, 4, 5],       # profundidades menores
    'min_samples_leaf': [10, 20, 50],    # folhas maiores
    'class_weight'    : ['balanced']
}
dt = DecisionTreeClassifier(random_state=42)
grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)
grid.fit(X_tr, y_tr)

best = grid.best_estimator_
print("\nâ†’ Melhores parÃ¢metros (poda):", grid.best_params_)
print("â†’ Melhor F1 CV:", grid.best_score_)

# 9. AvaliaÃ§Ã£o â€“ TREINO
y_tr_pred  = best.predict(X_tr)
y_tr_prob  = best.predict_proba(X_tr)[:,1]
print("\n=== MÃ©tricas no TREINO ===")
print(classification_report(y_tr, y_tr_pred, target_names=['Fica','Sai']))
print("AUC train:", roc_auc_score(y_tr, y_tr_prob))
cm_tr = confusion_matrix(y_tr, y_tr_pred)
sns.heatmap(cm_tr, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("ConfusÃ£o (Treino)"); plt.show()

# 10. AvaliaÃ§Ã£o â€“ TESTE
y_te_pred = best.predict(X_test)
y_te_prob = best.predict_proba(X_test)[:,1]
print("\n=== MÃ©tricas no TESTE ===")
print(classification_report(y_test, y_te_pred, target_names=['Fica','Sai']))
print("AUC test:", roc_auc_score(y_test, y_te_prob))
cm_te = confusion_matrix(y_test, y_te_pred)
sns.heatmap(cm_te, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("ConfusÃ£o (Teste)"); plt.show()

# 11. Plot Ã¡rvore limitada a 3 nÃ­veis
plt.figure(figsize=(16,8))
plot_tree(best,
          feature_names=preproc.get_feature_names_out(),
          class_names=['Fica','Sai'],
          filled=True, rounded=True,
          max_depth=3, fontsize=10)
plt.title("Ãrvore de DecisÃ£o (max_depth=3, min_samples_leafâ‰¥10)")
plt.show()

```


## Tivemos entÃ£o algumas melhoras:

### Resultados da VersÃ£o v2.3 (Ãrvore Poda `max_depth=3`, `min_samples_leaf=10`)

#### DistribuiÃ§Ã£o de Classes no Treino
- Antes do SMOTE:
  - Sai (1): 2 327  
  - Fica (0):   757  
- ApÃ³s SMOTE:
  - Sai (1): 2 327  
  - Fica (0): 2 327  

---

### HiperparÃ¢metros Otimizados
- criterion: `entropy`
- max_depth': `3`
- min_samples_leaf': `10`
- class_weight': `balanced`
* Melhor F1 CV (5-fold): 0.6939

### MÃ©tricas no Conjunto de Treino
|Classe  |	Precision|	Recall|	F1-score	|Support|
|--------|-----------|--------|-----------|-------|
|Fica	   |0.69	     |0.76    |	0.72    	|2327   |
|Sai     |0.73	     |0.66	  |0.69       |	2327  |
|Accuracy|0.71       |        |           |		    |	
|AUC     |0.79       |        |           |			  |

### Matriz de ConfusÃ£o (Treino)

|  |Modelo disse que saiu| Modelo disse que ficou|
|--|---------------------|-----------------------|
|Saiu|   1769    |  558 |
|Ficou|  799     | 1528 |
 
### MÃ©tricas no Conjunto de Teste
|Classe  |	Precision|	Recall|	F1-score	|Support|
|--------|-----------|--------|-----------|-------|
|Fica	   |0.35	     |0.63    |	0.45    	|189   |
|Sai     |0.84       |0.62	  |0.71       |	583  |
|Accuracy|0.62       |        |           |		    |	
|AUC     |0.68       |        |           |			  |


### Matriz de ConfusÃ£o (Teste)

|  |Modelo disse que saiu| Modelo disse que ficou|
|--|---------------------|-----------------------|
|Saiu|   119    |  70 |
|Ficou|  222     | 361 |

### Principais ObservaÃ§Ãµes:
- Recall â€œFicaâ€ subiu de 0.42 â†’ 0.63, melhorando em +0.21.
- AUC avanÃ§ou de 0.57 â†’ 0.68, indicando melhor poder de discriminaÃ§Ã£o.
- Trade-off: leve queda em F1 â€œSaiâ€ (0.76 â†’ 0.71) e acurÃ¡cia geral (0.65 â†’ 0.62).
---

# Planejamento da Sprint 5.
# Sprint 5 â€“ 2Âº Modelo Induzido: Rede Neural

## 1. Algoritmo Escolhido e Justificativa

- **Algoritmo:** Rede Neural Feed-Forward (MLP)
- **Justificativa:**  
  - Lida bem com variÃ¡veis numÃ©ricas e codificadas (idade, salÃ¡rio, ordinalidade, binÃ¡rias).  
  - Capta relaÃ§Ãµes nÃ£o-lineares entre atributos (e.g. interaÃ§Ãµes entre satisfaÃ§Ã£o e experiÃªncia prejudicada).  
  - Permite ajustarmos arquitetura (camadas, neurÃ´nios) e regularizaÃ§Ã£o (dropout, batch-norm).

## 1.1 AlteraÃ§Ãµes na base de dados

### 1.1.1 ConversÃ£o de Atributos CategÃ³ricos

Algumas variÃ¡veis categÃ³ricas foram transformadas para formato numÃ©rico com o objetivo de permitir o uso em algoritmos de machine learning, que nÃ£o operam diretamente com strings. As seguintes conversÃµes foram aplicadas:

---

#### a) GÃªnero

A coluna original `('P1_b ', 'Genero')` foi transformada na coluna binÃ¡ria `GENERO binÃ¡rio`, de acordo com a seguinte lÃ³gica:

- `"Masculino"` â†’ `1`
- `"Feminino"` â†’ `0`

Essa conversÃ£o possibilita a utilizaÃ§Ã£o da variÃ¡vel de gÃªnero como variÃ¡vel binÃ¡ria, simplificando o tratamento nos modelos supervisionados.

---

#### b) Agrupamento de Cargos

A variÃ¡vel categÃ³rica `AGRUPAMENTO CARGOS` foi convertida em `CARGOS numericamente` atravÃ©s de um mapeamento manual, com base em categorias semÃ¢nticas predefinidas. O mapeamento ficou da seguinte forma:

| Categoria Original          | Valor NumÃ©rico |
|----------------------------|----------------|
| AcadÃªmico                  | 0              |
| AnÃ¡lise de Dados           | 1              |
| CientÃ­fico/Quantitativo    | 2              |
| Desenvolvimento            | 3              |
| Engenharia de Dados        | 4              |
| Infraestrutura             | 5              |
| ML/IA                      | 6              |
| NegÃ³cios                   | 7              |
| Outras Engenharias         | 8              |
| Outro                      | 9              |
| Produto                    | 10             |

Essa transformaÃ§Ã£o foi realizada para garantir que os modelos possam trabalhar com essa variÃ¡vel como ordinal ou categÃ³rica codificada numericamente.

---

### 1.1.2 Justificativa

Essas transformaÃ§Ãµes foram necessÃ¡rias para atender os prÃ©-requisitos do algoritmo de machine learning supervisionado que usarei, redes neural, que exige entradas numÃ©ricas. AlÃ©m disso, essa padronizaÃ§Ã£o facilita o tratamento de variÃ¡veis durante o pipeline de modelagem, validaÃ§Ã£o e explicaÃ§Ã£o dos resultados.

Acesso Ã  nova base:  
[BASE SPRINT 4 VERSAO 2 TODA NUMERICA(in).csv)](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/commit/a0d61a7739c08b5a2b6cd0e09188858860ae5490#diff-23212db9ecadfda8498670d8fdeb232b9233a1ebbaaf71a1b962074a55bf4c0e))

## 2. Baseline

- **DummyClassifier (maior frequÃªncia):**  
  - Accuracy ~ 0.76 (prevÃª sempre â€œSaiâ€).  
  - Precision/Recall/F1 da classe â€œFicaâ€ = 0.0.  
- **Meta:** superar baseline em pelo menos uma mÃ©trica chave (F1 ou AUROC).

## 3. Hiper-parÃ¢metros Documentados

| ParÃ¢metro         | Valor usado           | ObservaÃ§Ãµes                                    |
|-------------------|-----------------------|------------------------------------------------|
| camadas ocultas   | [64, 32]              | Duas camadas densas de 64 e 32 neurÃ´nios       |
| ativaÃ§Ã£o ocultas  | `relu`                | ConvergÃªncia mais rÃ¡pida em deep learning      |
| ativaÃ§Ã£o saÃ­da    | `sigmoid`             | BinÃ¡rio (0/1)                                  |
| otimizador        | `adam`                | Ajuste automÃ¡tico de learning rate             |
| loss              | `binary_crossentropy` | Adequado para classificaÃ§Ã£o binÃ¡ria            |
| mÃ©tricas          | `accuracy`, `AUC`     | Avalia tanto acurÃ¡cia quanto separaÃ§Ã£o de classes |
| batch_size        | 32                    | Tamanho de mini-batch                          |
| epochs            | 50                    | Early-stopping opcional (com validation_split) |
| validation_split  | 0.1                   | 10% dos dados de treino para validaÃ§Ã£o interna |

## 4. CÃ³digo ReproduzÃ­vel (Usei Google Colab)

```python 
# 1. InstalaÃ§Ã£o (se necessÃ¡rio)
!pip install tensorflow scikit-learn pandas matplotlib seaborn

# 2. ImportaÃ§Ãµes
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.dummy import DummyClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, classification_report
)

import tensorflow as tf
from tensorflow.keras import Input, Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

# 3. Carregar e preparar dados
df = pd.read_csv('BASE_SPRINT5_REFINADA.csv', sep=';', encoding='latin1')

# Renomear colunas para nomes limpos
df.rename(columns={
    "('P1_a ', 'Idade')": 'Idade',
    'GENERO binÃ¡rio': 'Genero',
    'EXPERIÃŠNCIA PREJUDICADA SIM OU NAO': 'ExperienciaPrejudicada',
    'CARGOS numÃ©ricamente': 'AgrupamentoCargos', 
    'MÃ‰DIA FAIXA SALARIAL': 'MediaFaixaSalarial',
    'NÃVEL COM NÃšMEROS ORDINAIS': 'NivelOrdinal',
    "('P2_k ', 'VocÃª estÃ¡ satisfeito na sua empresa atual?')": 'Satisfeito',
    'ESTOU NA FORMA DE TRABALHO IDEAL?': 'TrabalhoIdeal',
    'PRETENDE SAIR SIM OU NAO - TARGET': 'PretendeSair'
}, inplace=True)

# SeleÃ§Ã£o de features e target; drop de missing
features = [
    'Idade','Genero','ExperienciaPrejudicada','AgrupamentoCargos',
    'MediaFaixaSalarial','NivelOrdinal','Satisfeito','TrabalhoIdeal'
]
df = df[features + ['PretendeSair']].dropna()

# Converter tipos
df['Idade']                = df['Idade'].astype(float)
df['MediaFaixaSalarial']   = df['MediaFaixaSalarial'].astype(float)
df[['Genero','ExperienciaPrejudicada','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']] = \
    df[['Genero','ExperienciaPrejudicada','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']].astype(int)

# 4.1 Baseline Dummy
X_base = df[features]
y_base = df['PretendeSair']
baseline = DummyClassifier(strategy='most_frequent', random_state=42)
baseline.fit(X_base, y_base)
y_base_pred = baseline.predict(X_base)
print("Baseline Accuracy:", accuracy_score(y_base, y_base_pred))

# 5. Split treino/teste
X = df[features]
y = df['PretendeSair']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, stratify=y, random_state=42
)

# 6. Escalar numÃ©ricos
num_cols = ['Idade','MediaFaixaSalarial','NivelOrdinal']
scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols]  = scaler.transform(X_test[num_cols])

# 7. Construir Rede Neural
model = Sequential([
    Input(shape=(len(features),)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid'),
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.AUC(name='auroc')]
)

# Early stopping opcional
es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    validation_split=0.1,
    epochs=50,
    batch_size=32,
    callbacks=[es],
    verbose=1
)

# 8. AvaliaÃ§Ã£o
y_pred_prob = model.predict(X_test).ravel()
y_pred      = (y_pred_prob > 0.5).astype(int)

acc   = accuracy_score(y_test, y_pred)
auc   = roc_auc_score(y_test, y_pred_prob)
prec  = precision_score(y_test, y_pred)
rec   = recall_score(y_test, y_pred)
f1    = f1_score(y_test, y_pred)

print(f"Accuracy: {acc:.4f}")
print(f"AUC     : {auc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall   : {rec:.4f}")
print(f"F1-score : {f1:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['Fica','Sai']))

# 9. Matriz de ConfusÃ£o
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("Matriz de ConfusÃ£o â€“ Rede Neural v1.1")
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.show()
```
## 5. MÃ©tricas Chave e InterpretaÃ§Ã£o (Teste)
|MÃ©trica	      |Valor    |
|---------------|---------|
|Accuracy       |	0.7293  |
|AUROC          |	0.6929  |
|Precision(Fica)|	0.36    |
|Recall(Fica)   |	0.14    |
|F1(Fica)      	|0.20     |
|Precision(Sai) |	0.77    |
|Recall(Sai)    |	0.92    |
|F1(Sai)	      |0.84     |

* AcurÃ¡cia global (72.9 %) supera baseline (~76 % na base inteira, mas baseline â€œSaiâ€ falha em â€œFicaâ€).

* AUROC ~ 0.69 indica poder discriminativo moderado.

* Modelo Ã© forte em prever quem sai (alta recall = 92 %), mas ainda fraco em capturar quem fica (recall = 14 %).

## 6. Pontos Fortes e LimitaÃ§Ãµes
* Pontos fortes:

  * Supera baseline trivial em F1 geral.

  * Alto recall na classe â€œSaiâ€ (detecÃ§Ã£o de turnover).

  * Arquitetura simples e treinamento estÃ¡vel.

* LimitaÃ§Ãµes:

  * DesequilÃ­brio de classes persiste: fraco recall em â€œFicaâ€.

  * Over/under-fitting leve (treino ~ 78 % vs teste ~ 73 %).

  * AUROC < 0.70 sugere melhorias no poder preditivo.
 
## 6.1 Matriz de ConfusÃ£o

Abaixo estÃ¡ a matriz de confusÃ£o gerada pelo modelo de rede neural:

![Matriz de confusao segundo modelo induzido 1 1](https://github.com/user-attachments/assets/06e5286d-25ba-4d26-8216-f3ff0de8e9bb)


### InterpretaÃ§Ã£o:

- **Verdadeiros Positivos (VP - "Sai" predito corretamente)**: 537  
  O modelo acertou **537 pessoas** que realmente **pretendiam sair**.

- **Verdadeiros Negativos (VN - "Fica" predito corretamente)**: 26  
  O modelo acertou **26 pessoas** que realmente **pretendiam ficar**.

- **Falsos Positivos (FP - "Sai" predito, mas na verdade fica)**: 136  
  O modelo previu que **136 pessoas sairiam**, mas **na verdade ficariam**.

- **Falsos Negativos (FN - "Fica" predito, mas na verdade sai)**: 46  
  O modelo previu que **46 pessoas ficariam**, mas **na verdade sairiam**.

### AvaliaÃ§Ã£o:

- O modelo teve **bom desempenho em identificar quem vai sair (classe majoritÃ¡ria)**, com alta quantidade de acertos (537 VP).
- PorÃ©m, apresenta **dificuldade em prever corretamente quem ficarÃ¡ (classe minoritÃ¡ria)**: apenas 26 VN contra 136 FP.
- Esse comportamento Ã© tÃ­pico em datasets **desbalanceados**, onde a classe â€œSaiâ€ Ã© muito mais frequente do que â€œFicaâ€.

### ImplicaÃ§Ãµes:

- Apesar da acurÃ¡cia global razoÃ¡vel, o modelo tende a **superestimar o risco de saÃ­da**, o que pode ser problemÃ¡tico em cenÃ¡rios de RH.
- Para reduzir os falsos positivos, Ã© possÃ­vel:
  - Aplicar **tÃ©cnicas de balanceamento** (ex: SMOTE, undersampling).
  - Ajustar o **threshold de decisÃ£o** (atualmente Ã© 0.5).
  - Usar **mÃ©tricas especÃ­ficas da minoria**, como _Recall_ para a classe â€œFicaâ€.

---

> **Resumo:** O modelo Ã© eficaz para identificar potenciais desligamentos, mas ainda falha bastante em prever corretamente quem irÃ¡ permanecer, o que limita sua utilidade prÃ¡tica em algumas decisÃµes estratÃ©gicas.



 
## 7. SugestÃµes para PrÃ³xima IteraÃ§Ã£o

* *Balanceamento*: usar SMOTE ou class weights para reforÃ§ar â€œFicaâ€.

* *Ajuste de threshold*: escolher ponto de corte que maximize F1 mÃ©dio.

* *Arquitetura*: experimentar mais camadas, dropout ou batch-norm.

* *Novos atributos*: criar interaÃ§Ãµes (e.g. idade Ã— satisfaÃ§Ã£o).

* *Algoritmo adicional*: comparar com XGBoost / Random Forest para validar robustez.

## 8. AnÃ¡lise das Curvas de Treinamento

### GrÃ¡fico: Curva de Perda e AcurÃ¡cia ao Longo das Ã‰pocas

![graficos rede neural hipotese vai sair 2](https://github.com/user-attachments/assets/f62ba981-e8f5-4776-9910-eb4298b58ac2)

### InterpretaÃ§Ã£o

#### Curva de Perda (Loss)
- A **linha azul** representa a perda (erro) nos dados de **treinamento**, enquanto a **linha laranja** mostra a perda na **validaÃ§Ã£o**.
- Observamos que:
  - A perda de **treinamento** segue diminuindo de forma suave.
  - A perda de **validaÃ§Ã£o** tambÃ©m decresce no inÃ­cio, mas apresenta **variaÃ§Ãµes instÃ¡veis** a partir da 7Âª Ã©poca.
  - Isso pode ser um **indÃ­cio inicial de overfitting**, pois o modelo continua melhorando no treino, mas oscila na validaÃ§Ã£o.

#### Curva de AcurÃ¡cia
- A **linha azul** indica a acurÃ¡cia nos dados de **treinamento**, e a **linha laranja**, a acurÃ¡cia na **validaÃ§Ã£o**.
- AcurÃ¡cia de **treinamento aumenta continuamente**, atingindo mais de 77%.
- JÃ¡ a **acurÃ¡cia de validaÃ§Ã£o oscila** e estabiliza por volta de 72â€“73%, sem grande melhora apÃ³s a 6Âª Ã©poca.
- Esse comportamento reforÃ§a a hipÃ³tese de que o modelo comeÃ§a a **memorizar** o treino, mas **nÃ£o generaliza tÃ£o bem** nos dados de validaÃ§Ã£o.

### ConclusÃ£o da Curva
- O modelo teve um bom inÃ­cio de aprendizado, com melhora tanto em loss quanto em acurÃ¡cia.
- A partir de um certo ponto (Ã©poca ~6 a 8), os ganhos de validaÃ§Ã£o se estagnam ou oscilam, sugerindo a necessidade de:
  - **RegularizaÃ§Ã£o** (ex: dropout, L2).
  - **Early stopping** com base na validaÃ§Ã£o.
  - **Ajuste da arquitetura** (menos neurÃ´nios ou camadas).
  - **Balanceamento de classes**, para melhorar a generalizaÃ§Ã£o, principalmente para a classe minoritÃ¡ria (â€œFicaâ€).

---

> **Resumo:** As curvas reforÃ§am a anÃ¡lise quantitativa: o modelo aprende bem o padrÃ£o do treino, mas ainda nÃ£o generaliza de forma robusta. Ã‰ um bom ponto de partida, mas hÃ¡ margem para ajustes estruturais e de dados.



## ConclusÃ£o:
> O modelo de rede neural v1.1 validou a viabilidade de prever â€œPretendeSairâ€ com performance melhor que baseline trivial. HÃ¡ ganho modesto em recall da classe minoritÃ¡ria, mas ainda requer refinamentos de balanceamento e arquitetura para capturar quem fica com mais fidelidade.
