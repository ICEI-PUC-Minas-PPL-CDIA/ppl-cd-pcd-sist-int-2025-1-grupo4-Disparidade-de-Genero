# √çndice

1. [üèÅ Sprint 4 ‚Äì Relat√≥rio Completo](#üèÅ-sprint-4-‚Äì-relat√≥rio-completo)  
   1. [1. Introdu√ß√£o](#1-introdu√ß√£o)  
   2. [2. Hip√≥tese](#2-hip√≥tese)  
   3. [3. Bases de Dados e Transforma√ß√µes](#3-bases-de-dados-e-transforma√ß√µes)  
      1. [3.1. Base Original](#31-base-original)  
      2. [3.2. Sele√ß√£o de Colunas Relevantes](#32-sele√ß√£o-de-colunas-relevantes)  
      3. [3.3. Base Refinada e Transforma√ß√µes](#33-base-refinada-e-transforma√ß√µes)  
         1. [3.3.1. Convers√£o de faixas para valores m√©dios (idade, sal√°rio)](#331-convers√£o-de-faixas-para-valores-m√©dios-idade-sal√°rio)  
      4. [3.6. Base Refinada](#36-base-refinada)  
   4. [4. Constru√ß√£o do 1¬∫ Modelo Induzido](#4-constru√ß√£o-do-1¬∫-modelo-induzido)  
      1. [Explica√ß√£o do C√≥digo de Modelagem Preditiva](#explica√ß√£o-do-c√≥digo-de-modelagem-preditiva)  
   5. [5. Resultados](#5-resultados)  
      1. [Avalia√ß√£o do modelo](#avalia√ß√£o-do-modelo)  
      2. [√Årvore de decis√£o](#√°rvore-de-decis√£o)  
      3. [Matriz de confus√£o](#matriz-de-confus√£o)  

2. [üèÅ Sprint 4 ATUALIZADA ‚Äì Relat√≥rio Completo](#üèÅ-sprint-4-atualizada-‚Äì-relat√≥rio-completo)  
   1. [1. Introdu√ß√£o](#1-introdu√ß√£o-1)  
   2. [2. Finalidade e explica√ß√µes de o que foi feito](#2-finalidade-e-explica√ß√µes-de-o-que-foi-feito)  
   3. [3. Acesso √†s bases de dados](#3-acesso-√†s-bases-de-dados)  
   4. [4. Resultados](#4-resultados-1)  
      1. [4.1. Modelo Anterior (√°rvore de decis√£o padr√£o)](#41-modelo-anterior-√°rvore-de-decis√£o-padr√£o)  
      2. [4.2. Modelo Atual (√°rvore otimizada via GridSearchCV)](#42-modelo-atual-√°rvore-otimizada-via-gridsearchcv)  
         1. [4.2.1. Melhorias](#421-melhorias)  
         2. [4.2.2. Pioras](#422-pioras)  
   5. [5. Discuss√£o e Conclus√£o](#5-discuss√£o-e-conclus√£o)  
      1. [Impacto pr√°tico](#impacto-pr√°tico)  
      2. [Recomenda√ß√£o](#recomenda√ß√£o)  
   6. [6. Reprodutibilidade](#6-reprodutibilidade)  
      1. [Matriz de confus√£o](#matriz-de-confus√£o-1)  
      2. [√Årvore de decis√£o](#√°rvore-de-decis√£o-1)  

3. [Sprint 4.1 (pequeno b√¥nus)](#sprint-41-pequeno-b√¥nus)  
   1. [Relat√≥rio de Conclus√£o da atualiza√ß√£o do modelo](#relat√≥rio-de-conclus√£o-da-atualiza√ß√£o-do-modelo)  
      1. [1. Contexto](#1-contexto)  
      2. [2. Pr√©-processamento](#2-pr√©-processamento)  
      3. [3. Baseline](#3-baseline)  
      4. [4. Treinamento & Tuning](#4-treinamento--tuning)  
      5. [5. Avalia√ß√£o](#5-avalia√ß√£o)  
         1. [5.1. Conjunto de Treino](#51-conjunto-de-treino)  
         2. [5.2. Conjunto de Teste](#52-conjunto-de-teste)  
      6. [6. Diagn√≥stico](#6-diagn√≥stico)  
      7. [7. Pontos Fortes](#7-pontos-fortes)  
      8. [8. Pr√≥ximos Passos](#8-pr√≥ximos-passos)  
      9. [Tivemos ent√£o algumas melhoras](#tivemos-ent√£o-algumas-melhoras)  
         1. [Resultados da Vers√£o v2.3 (√Årvore Poda `max_depth=3`, `min_samples_leaf=10`)](#resultados-da-vers√£o-v23-√°rvore-poda-max_depth3-min_samples_leaf10)  
            1. [Distribui√ß√£o de Classes no Treino](#distribui√ß√£o-de-classes-no-treino)  
         2. [Hiperpar√¢metros Otimizados](#hiperpar√¢metros-otimizados)  
         3. [M√©tricas no Conjunto de Treino](#m√©tricas-no-conjunto-de-treino)  
         4. [Matriz de Confus√£o (Treino)](#matriz-de-confus√£o-treino)  
         5. [M√©tricas no Conjunto de Teste](#m√©tricas-no-conjunto-de-teste)  
         6. [Matriz de Confus√£o (Teste)](#matriz-de-confus√£o-teste)  
         7. [Principais Observa√ß√µes](#principais-observa√ß√µes)  

4. [1. Algoritmo Escolhido e Justificativa](#1-algoritmo-escolhido-e-justificativa)  
   1. [1.1 Altera√ß√µes na base de dados](#11-altera√ß√µes-na-base-de-dados)  
      1. [1.1.1 Convers√£o de Atributos Categ√≥ricos](#111-convers√£o-de-atributos-categ√≥ricos)  
         1. [b) Agrupamento de Cargos](#b-agrupamento-de-cargos)  
      2. [1.1.2 Justificativa](#112-justificativa)  
   2. [2. Baseline](#2-baseline-1)  
   3. [3. Hiper-par√¢metros Documentados](#3-hiper-par√¢metros-documentados)  
   4. [4. C√≥digo Reproduz√≠vel (Usei Google Colab)](#4-c√≥digo-reproduz√≠vel-usei-google-colab)  
   5. [5. M√©tricas Chave e Interpreta√ß√£o (Teste)](#5-m√©tricas-chave-e-interpreta√ß√£o-teste)  
   6. [6. Pontos Fortes e Limita√ß√µes](#6-pontos-fortes-e-limita√ß√µes)  
      1. [6.1 Matriz de Confus√£o](#61-matriz-de-confus√£o)  
         1. [Interpreta√ß√£o](#interpreta√ß√£o)  
         2. [Avalia√ß√£o](#avalia√ß√£o-1)  
         3. [Implica√ß√µes](#implica√ß√µes)  
   7. [7. Sugest√µes para Pr√≥xima Itera√ß√£o](#7-sugest√µes-para-pr√≥xima-itera√ß√£o)  
   8. [8. An√°lise das Curvas de Treinamento](#8-an√°lise-das-curvas-de-treinamento)  
      1. [Gr√°fico: Curva de Perda e Acur√°cia ao Longo das √âpocas](#gr√°fico-curva-de-perda-e-acur√°cia-ao-longo-das-√©pocas)  
      2. [Interpreta√ß√£o](#interpreta√ß√£o-1)  
         1. [Curva de Perda (Loss)](#curva-de-perda-loss)  
         2. [Curva de Acur√°cia](#curva-de-acur√°cia)  
      3. [Conclus√£o da Curva](#conclus√£o-da-curva)  

      4. [Conclus√£o](#conclus√£o)  



# üèÅ Sprint 4 ‚Äì Relat√≥rio Completo

## 1. Introdu√ß√£o

**Objetivo do projeto:**  
Prever a **inten√ß√£o de sa√≠da** de colaboradores nos pr√≥ximos 6 meses, auxiliando equipes de RH a identificar riscos de turnover.

**Utilidade do modelo:**  
- Antecipar demandas de reten√ß√£o  
- Apoiar decis√µes de programas de engajamento  
- Reduzir custos de substitui√ß√£o e treinamento

---

## 2. Hip√≥tese

> ‚ÄúA combina√ß√£o de caracter√≠sticas demogr√°ficas, salariais e de satisfa√ß√£o no trabalho permite prever com boa acur√°cia quem pretende mudar de emprego.‚Äù

- **Vari√°vel-alvo (target):** `Preten√ß√£o de sair - TARGET` (bin√°ria: 1 = procura sa√≠da, 0 = n√£o procura)
- **Features principais:** Idade m√©dia, G√™nero, N√≠vel, Cargo, Sal√°rio, Satisfa√ß√£o, Forma de trabalho, Trabalho ideal

---

## 3. Bases de Dados e Transforma√ß√µes
### 3.1. Base Original
A base original foi fornecida em formato .csv contendo 5294 linhas e 550 colunas. Ela re√∫ne informa√ß√µes diversas sobre colaboradores, abrangendo dados demogr√°ficos, profissionais, salariais e de satisfa√ß√£o.

- [Base de Dados principal pura e crua (State_of_data_BR_2023_Kaggle - df_survey_2023.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/blob/main/assets/data/Base_principal_State_of_data_2023/State_of_data_BR_2023_Kaggle%20-%20df_survey_2023.csv)

- Observa√ß√£o: A base cont√©m muitas colunas irrelevantes ou redundantes para o objetivo da an√°lise.

---

### 3.2. Sele√ß√£o de Colunas Relevantes
* Para tornar a an√°lise mais eficiente e alinhada √† hip√≥tese, filtrei apenas as colunas necess√°rias para a modelagem preditiva. O processo foi feito com base em crit√©rios de relev√¢ncia para o problema de previs√£o de sa√≠da de colaboradores.

  |     C√≥digo        |      Coluna             | Tipo de dado | Atributos correspondentes |
  | -----------|---------------------|----------------------------|------------------------|
   | 'P1_a_1'|       Faixa idade | Qualitativo intervalar |17-21 <br>22-24<br>25-29<br>30-34<br>35-39<br>40-44<br>45-49<br>50-54<br>55+ |
  |  'P1_b'  |       G√™nero |  Qualitativo | Feminino<br>Masculino<br>Outro<br>Prefiro n√£o informar |
  |  'P2_f'   |      Cargo Atual | Qualitativo | Analista de BI/BI Analyst<br>Analista de Dados/Data Analyst<br>Analista de Intelig√™ncia de Mercado/Market Intelligence<br>Analista de Neg√≥cios/Business Analyst<br>Analista de Suporte/Analista T√©cnico<br>Analytics Engineer<br>Cientista de Dados/Data Scientist<br>Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)<br>DBA/Administrador de Banco de Dados<br>Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas<br>Economista<br>Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect<br>Engenheiro de Machine Learning/ML Engineer/AI Engineer<br>Estat√≠stico<br>Outra Op√ß√£o<br>Outras Engenharias (n√£o inclui dev)<br>Professor/Pesquisador<br>(vazio) |
  |  'P2_g'   |     N√≠vel | Qualitativo |J√∫nior<br>Pleno<br>S√™nior<br>(vazio) |
  |  'P2_h'   |     Faixa salarial | Qualitativo intervalar | Acima de R$ 40.001/m√™s<br>de R$ 1.001/m√™s a R$ 2.000/m√™s<br>de R$ 1001/m√™s a R$ 2.000/m√™s<br>de R$ 12.001/m√™s a R$ 16.000/m√™s<br>de R$ 16.001/m√™s a R$ 20.000/m√™s<br>de R$ 2.001/m√™s a R$ 3.000/m√™s<br>de R$ 20.001/m√™s a R$ 25.000/m√™s<br>de R$ 25.001/m√™s a R$ 30.000/m√™s<br>de R$ 3.001/m√™s a R$ 4.000/m√™s<br>de R$ 30.001/m√™s a R$ 40.000/m√™s<br>de R$ 4.001/m√™s a R$ 6.000/m√™s<br>de R$ 6.001/m√™s a R$ 8.000/m√™s<br>de R$ 8.001/m√™s a R$ 12.000/m√™s<br>Menos de R$ 1.000/m√™s<br>(vazio) |
  |  'P2_k'   |     Satisfa√ß√£o empresa | Bool | 0<br>1<br>(vazio) |
  |  'P2_n'   |      Pretens√£o mudar emprego | Qualitativo | Estou em busca de oportunidades dentro ou fora do Brasil<br>Estou em busca de oportunidades, mas apenas fora do Brasil<br>N√£o estou buscando e n√£o pretendo mudar de emprego nos pr√≥ximos 6 meses<br>N√£o estou buscando, mas me considero aberto a outras oportunidades<br>(vazio) |
  |  'P2_r'    |     Forma de trabalho | Qualitativo |Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo h√≠brido com dias fixos de trabalho presencial<br>Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)<br>(vazio) |
  |  'P2_s'     |     Forma de trabalho ideal | Qualitativo | Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo h√≠brido com dias fixos de trabalho presencial<br>Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)<br>(vazio) |


### 3.3. Base Refinada e Transforma√ß√µes
Ap√≥s a filtragem, realizei uma s√©rie de limpezas e transforma√ß√µes para preparar os dados para a modelagem. As principais etapas foram:

  #### 3.3.1. Convers√£o de faixas para valores m√©dios (idade, sal√°rio)
  * 3.3.1.1 M√©dia intervalos das faixas salariais:
  O programa precisava ler atributos float para ter uma no√ß√£o boa do sal√°rio. A ideia foi tirar a m√©dia dos extremos dos intervalos.
  C√≥digo usado no excel:
  > =SE(√âC√âL.VAZIA(H2);10000;
  SE(H2="Acima de R$ 40.001/m√™s";45000;
  SE(H2="de R$ 1.001/m√™s a R$ 2.000/m√™s";1500;
  SE(H2="de R$ 1001/m√™s a R$ 2.000/m√™s";1500;
  SE(H2="de R$ 12.001/m√™s a R$ 16.000/m√™s";14000;
  SE(H2="de R$ 16.001/m√™s a R$ 20.000/m√™s";18000;
  SE(H2="de R$ 2.001/m√™s a R$ 3.000/m√™s";2500;
  SE(H2="de R$ 20.001/m√™s a R$ 25.000/m√™s";22500;
  SE(H2="de R$ 25.001/m√™s a R$ 30.000/m√™s";27500;
  SE(H2="de R$ 3.001/m√™s a R$ 4.000/m√™s";3500;
  SE(H2="de R$ 30.001/m√™s a R$ 40.000/m√™s";35000;
  SE(H2="de R$ 4.001/m√™s a R$ 6.000/m√™s";5000;
  SE(H2="de R$ 6.001/m√™s a R$ 8.000/m√™s";7000;
  SE(H2="de R$ 8.001/m√™s a R$ 12.000/m√™s";10000;
  SE(H2="Menos de R$ 1.000/m√™s";500;"")))))))))))))))

  para a linha 2. Nas linhas subsequentes o c√≥digo √© o mesmo, s√≥ alterando a linha.
  * 3.3.1.2 M√©dia intervalos das idades. O programa precisava ter um atributo int ou float. A ideia foi tirar a m√©dia dos extremos dos intervalos.
  C√≥digo usado no excel:
  > =SE(A2="17-21"; 19;
  SE(A2="22-24"; 23;
  SE(A2="25-29"; 27;
  SE(A2="30-34"; 32;
  SE(A2="35-39"; 37;
  SE(A2="40-44"; 42;
  SE(A2="45-49"; 47;
  SE(A2="50-54"; 52;
  SE(A2="55+"; 57,5)))))))))

  para a linha 2. Nas linhas subsequentes o c√≥digo √© o mesmo, s√≥ alterando a linha.
    
  #### 3.3.2. Agrupamento de cargos em categorias macro
  Havia muitos cargos, alguns "parecidos", podendo ser agrupados em macro-categorias. Altera√ß√µes feitas:
  |Cargo Original|	Cargo Agrupado|
  |---------------|----------------|
  |Cientista de Dados/Data Scientist<br>Analista de Dados/Data Analyst<br>Analista de BI/BI Analyst<br>Analista de Intelig√™ncia de Mercado/Market Intelligence	|An√°lise de Dados|
  |Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect<br>Analytics Engineer	|Engenharia de Dados|
  |Engenheiro de Machine Learning/ML Engineer/AI |Engineer	ML/IA|
  |Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas	|Desenvolvimento|
  Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)	|Produto|
  |Estat√≠stico<br>Economista	|Cient√≠fico/Quantitativo|
  |DBA/Administrador de Banco de Dados<br>Analista de Suporte/Analista T√©cnico|	Infraestrutura|
  |Outras Engenharias (n√£o inclui dev)|	Outras Engenharias|
  |Professor/Pesquisador	|Acad√™mico|
  |Analista de Neg√≥cios/Business Analyst|	Neg√≥cios|
  |Outra Op√ß√£o	|Outro|
  |(vazio)	|N√£o informado|
  
  C√≥digo usado no excel:
  > =SE(√âC√âL.VAZIA(D2);"N√£o informado";
  SE(OU(D2="Cientista de Dados/Data Scientist";D2="Analista de Dados/Data Analyst";D2="Analista de BI/BI Analyst";D2="Analista de Intelig√™ncia de Mercado/Market Intelligence");"An√°lise    de Dados";
  SE(OU(D2="Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect";D2="Analytics Engineer");"Engenharia de Dados";
  SE(D2="Engenheiro de Machine Learning/ML Engineer/AI Engineer";"ML/IA";
  SE(D2="Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas";"Desenvolvimento";
  SE(D2="Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)";"Produto";
  SE(OU(D2="Estat√≠stico";D2="Economista");"Cient√≠fico/Quantitativo";
  SE(OU(D2="DBA/Administrador de Banco de Dados";D2="Analista de Suporte/Analista T√©cnico");"Infraestrutura";
  SE(D2="Outras Engenharias (n√£o inclui dev)";"Outras Engenharias";
  SE(D2="Professor/Pesquisador";"Acad√™mico";
  SE(D2="Analista de Neg√≥cios/Business Analyst";"Neg√≥cios";
  SE(D2="Outra Op√ß√£o";"Outro";"Outro"))))))))))))

  para a linha 2. Nas linhas subsequentes o c√≥digo √© o mesmo, s√≥ alterando a linha.
  
  #### 3.3.3. Convers√£o de vari√°veis categ√≥ricas em num√©ricas (ordinal ou bin√°ria)
  * 3.3.3.1 N√≠vel (j√∫nior, pleno e s√™nior) s√£o um atributo ordinal. Ent√£o decidi transform√°-los em j√∫nior=0, pleno=1 e s√™nior=2, porque s√™nior>pleno>j√∫nior.
  C√≥digo usado:
  > =SE(F2="J√∫nior";0;
  SE(F2="Pleno";1;
  SE(F2="S√™nior";2;
  SE(√âC√âL.VAZIA(F2);ALEAT√ìRIOENTRE(0;2);""""))))

  para a linha 2. Nas linhas subsequentes o c√≥digo √© o mesmo, s√≥ alterando a linha.
  * 3.3.3.2 Pretens√£o de mudar de emprego est√° como atributo qualitativo. Para aquelas pessoas que apresentam qualquer vontade em sair de seu emprego, vou considerar que v√£o sair. 
  Inclusive, esse ser√° o atributo-alvo. Segue abaixo o exemplo:

  |('P2_n ', 'Voc√™ pretende mudar de emprego nos pr√≥ximos 6 meses?') | A pessoa vai sair da empresa?|
  |------------------------------------------------------------------|-------------------------------|
  |Estou em busca de oportunidades dentro ou fora do Brasil | Sim (1) |
  |Estou em busca de oportunidades, mas apenas fora do Brasil | Sim (1) |
  |N√£o estou buscando e n√£o pretendo mudar de emprego nos pr√≥ximos 6 meses | N√£o (0) |
  |N√£o estou buscando, mas me considero aberto a outras oportunidades | Sim (1) |
  |(vazio) | (vazio por enquanto) | 

  C√≥digo usado no excel: 
  > =SE(√âC√âL.VAZIA(L2);
    SE(ALEAT√ìRIO()<=0,75;1;0);
    SE(OU(
        L2="Estou em busca de oportunidades dentro ou fora do Brasil";
        L2="Estou em busca de oportunidades, mas apenas fora do Brasil";
        L2="N√£o estou buscando, mas me considero aberto a outras oportunidades"
    );1;0))
  
  para a linha 2. Nas linhas subsequentes o c√≥digo √© o mesmo, s√≥ alterando a linha.

  
  #### 3.3.4. Preenchimento de valores ausentes de forma proporcional ou por estat√≠stica do grupo remo√ß√£o de linhas. 
  * Voc√™ deve ter percebido que os c√≥digos citados acima apresentam algo a mais que s√≥ transformar dados qualitativos em quantitativos ou outras fun√ß√µes como a de agrupamento.
  Foram implementados nos c√≥digos a tarefa de preencherem os dados faltantes proporcionalmente √† frequ√™ncia com que os dados reais aparecem.
  * Vamos analisar coluna por coluna:
  * `('P1_a_1 ', 'Faixa idade')`:
    - n√£o apresenta dados faltantes.
  * `('P1_b ', 'Genero')`:
    - N√£o apresenta dados faltantes. Entretanto, apresenta dados que podem n√£o contribuir para a an√°lise, como `Outro` e `Prefiro n√£o informar`. Como esses dados s√£o quase       insignificantes na base (veja a tabela abaixo), resolvi tirar.

  
  
   |('P1_b ', 'Genero')|	Porcentagem do total geral) |
   |-------------------|---------------------------------|
   |Feminino|	24,43%|
   |Masculino|	75,10%|
   |Outro	|0,17%|
   |Prefiro n√£o informar|	0,30%|
  
  * `('P2_f ', 'Cargo Atual')`:
    - Nos dados faltantes, adicionei "N√£o foi informado"
  
  * `('P2_g ', 'Nivel')`
    - Haviam muitos dados faltantes. Para isso, distribu√≠ proporcionalmente conforme eles aparecem realmente pelos dados faltantes, j√° que representam 27% de toda base e seria ruim remov√™-los. Na base, eles aparecem de forma equilibrada, confira:

  |N√≠vel   |Quantidade|
  |--------|----------|
  |J√∫nior	| 1046|
  |Pleno	| 1392|
  |S√™nior	| 1419|
  |(vazio) | 1437|	

  * `('P2_r ', 'Atualmente qual a sua forma de trabalho?')`
    - Haviam muitos dados faltantes. Para isso, distribu√≠ proporcionalmente conforme eles aparecem realmente pelos dados faltantes, j√° que representam 10% de toda base e seria ruim remov√™-los. Na base, eles aparecem de forma que o Modelo 100% remoto se destaca. Confira:
   
  |('P2_r ', 'Atualmente qual a sua forma de trabalho?')|	Porcentaegm|
  |-----------------------------------------------------|--------------------------------|
  |Modelo 100% presencial	|14,93%|
  |Modelo 100% remoto	|41,58%|
  |Modelo h√≠brido com dias fixos de trabalho presencial|	14,93%|
  |Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)|	18,36%|
  |(vazio)	|10,20%|
   
  * `('P2_s ', 'Qual a forma de trabalho ideal para voc√™?')`
    - Haviam muitos dados faltantes. Para isso, distribu√≠ proporcionalmente conforme eles aparecem realmente pelos dados faltantes, j√° que representam 10% de toda base e seria ruim remov√™-los. Na base, eles aparecem de forma que o Modelo 100% remoto se destaca mais uma vez. Confira:
  
  |('P2_s ', 'Qual a forma de trabalho ideal para voc√™?')|	Porcentagem|
  |------------------------------------------------------|--------------|
  |Modelo 100% presencial|	1,81%|
  |Modelo 100% remoto|	40,13%|
  |Modelo h√≠brido com dias fixos de trabalho presencial|	7,35%|
  |Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)|	40,51%|
  |(vazio)	|10,20%|
  
  #### 3.3.5. Cria√ß√£o de uma nova feature: `Estou no trabalho ideal para mim?`
  * Aqui a ideia foi pegar a coluna do trabalho que a pessoa est√°, juntamente com a coluna do trabalho que seria ideal para ela. Se a resposta for sim, eu criei uma nova coluna       simbolizando a satisfa√ß√£o pessoal da pessoa com seu trabalho. Se ela est√° no trabalho que √© ideal para ela, as possibilidades de ela querer sair s√£o reduzidas. Exemplo:

  |Forma de trabalho atual | Forma de trabalho ideal | Estou no trabalho ideal para mim? |
  |-------------------------------------------------------------------|---------------------------------------------|-----------|
  |Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)|Modelo 100% remoto| N√£o = 0|
  |Modelo 100% remoto |Modelo 100% remoto| Sim = 1|
  |Modelo 100% remoto|Modelo 100% remoto| Sim = 1|
  |Modelo 100% remoto|Modelo 100% remoto| Sim = 1|
  |Modelo h√≠brido com dias fixos de trabalho presencial|Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)| N√£o = 0|
  |Modelo 100% remoto|Modelo 100% remoto| Sim = 1|
  |Modelo h√≠brido com dias fixos de trabalho presencial|Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)| N√£o = 0|
  |Modelo h√≠brido flex√≠vel|Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)| N√£o = 0|
  |Modelo 100% presencial|Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)| N√£o = 0|

  C√≥digo para excel usado: 
  > =SE(O2=Q2;1;0)

  para a linha 2. Nas linhas subsequentes o c√≥digo √© o mesmo, s√≥ alterando a linha.

  
### 3.6. Base Refinada

* Ap√≥s todas essas altera√ß√µes, a base ficou assim: [base para modelo preditivo refinada.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/blob/main/assets/data/Base_principal_State_of_data_2023/State_of_data_BR_2023_Kaggle%20-%20df_survey_2023.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/blob/main/assets/data/Analise_exploratoria_perguntas_orientadas_a_dados/Pergunta_orientada_a_dados%20(3)/base%20para%20modelo%20preditivo%20refinada.csv))

  - Base original: 5294 linhas, 550 colunas
  - Base filtrada: 5294 linhas, 10 colunas
  - Base refinada: 5294 linhas, 18 colunas (ap√≥s feature engineering)

* Observa√ß√µes:

  - Todas as etapas foram documentadas e os c√≥digos utilizados est√£o nos blocos acima.
  - As transforma√ß√µes garantem que os dados estejam prontos para a modelagem preditiva.
  
---
## 4. Constru√ß√£o do 1¬∫ Modelo Induzido

Usei o Google Colab, programando em Python. C√≥digo usado:


> from google.colab import files
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import csv
uploaded = files.upload()
nome_arquivo = next(iter(uploaded))
data = pd.read_csv(
    nome_arquivo,
    sep=';',
    engine='python',
    encoding='latin1',
    quoting=csv.QUOTE_NONE
)
print("Dados carregados com sucesso!\n")
print(data.head())
print("\nColunas detectadas:")
print(data.columns.tolist())
target = 'Preten√ß√£o de sair - TARGET'
features = [
    'M√©dia_Idades',
    "('P1_b ', 'Genero')",
    'Agrupamento_Cargo_Atual',
    'N√≠vel_Ordinal',
    'M√âDIA_FAIXA_SALARIAL',
    'Satisfa√ß√£o na empresa dados preenchidos',
    'Forma de trabalho com dados faltantes preenchidos',
    'Estou no trabalho que quero?'
]
data = data.dropna(subset=[target])
X = data[features].copy()
y = data[target].copy()
X['M√©dia_Idades'] = (
    X['M√©dia_Idades']
      .astype(str)
      .str.replace(',', '.')
      .astype(float)
)
X['N√≠vel_Ordinal'] = X['N√≠vel_Ordinal'].astype(float)
X['M√©dia_Idades'] = X['M√©dia_Idades'].fillna(X['M√©dia_Idades'].mean())
X['N√≠vel_Ordinal'] = X['N√≠vel_Ordinal'].fillna(X['N√≠vel_Ordinal'].median())
X = pd.get_dummies(
    X,
    columns=[
        "('P1_b ', 'Genero')",
        'Agrupamento_Cargo_Atual',
        'Forma de trabalho com dados faltantes preenchidos'
    ],
    drop_first=True
    )
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(f'\nAcur√°cia:  {accuracy_score(y_test, y_pred):.2f}')
print(f'Precis√£o:  {precision_score(y_test, y_pred):.2f}')
print(f'Recall:    {recall_score(y_test, y_pred):.2f}')
print(f'F1-score:  {f1_score(y_test, y_pred):.2f}')
plt.figure(figsize=(20,10))
plot_tree(
    model,
    feature_names=X.columns,
    class_names=['Ficar','Sair'],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("√Årvore de Decis√£o ‚Äì Inten√ß√£o de Sa√≠da")
plt.show()

### Explica√ß√£o do C√≥digo de Modelagem Preditiva

Este c√≥digo implementa um fluxo completo de modelagem preditiva usando uma √Årvore de Decis√£o para prever a inten√ß√£o de sa√≠da de colaboradores. Veja o passo a passo:

* 1. Importa√ß√£o das Bibliotecas
`python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score`

  - `pandas`: manipula√ß√£o e an√°lise de dados.

  - `sklearn.model_selection.train_test_split`: separa os dados em conjuntos de treino e teste.

  - `sklearn.tree.DecisionTreeClassifier`: algoritmo de √°rvore de decis√£o para classifica√ß√£o.

  - `sklearn.metrics`: m√©tricas para avalia√ß√£o do modelo.

* 2. Carregamento da Base de Dados
`python
data = pd.read_csv('base para modelo preditivo refinada.csv')
print(data.head())`
  - Carrega o arquivo CSV com os dados j√° refinados e prontos para modelagem.

  - Exibe as primeiras linhas para confer√™ncia.

* 3. Defini√ß√£o das Vari√°veis
`target = 'Preten√ß√£o de sair - TARGET'
features = [
    'M√©dia_Idades',
    'Genero',
    'Agrupamento_Cargo_Atual',
    'N√≠vel de forma Ordinal',
    'M√âDIA_FAIXA_SALARIAL',
    'Satisfa√ß√£o na empresa dados preenchidos',
    'Forma de trabalho com dados faltantes preenchidos',
    'Estou no trabalho ideal para mim?'
]`

  - X = data[features]
  - y = data[target]
  - *target*: coluna que indica se o colaborador pretende sair (vari√°vel a ser prevista).

  - features: lista das colunas preditoras utilizadas pelo modelo.

  - X: DataFrame com as vari√°veis preditoras.

  - y: S√©rie com a vari√°vel alvo.

* 4. Divis√£o dos Dados em Treinamento e Teste

`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`
  - Separa os dados em 80% para treino e 20% para teste, garantindo aleatoriedade reprodut√≠vel (random_state=42).

* 5. Treinamento do Modelo
`model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)`
  - Inicializa o modelo de √Årvore de Decis√£o.

  - Treina o modelo usando os dados de treino.

* 6. Realiza√ß√£o de Previs√µes
`y_pred = model.predict(X_test)`
  - Utiliza o modelo treinado para prever a inten√ß√£o de sa√≠da nos dados de teste.

* 7. Avalia√ß√£o do Modelo
`accuracy = accuracy_score(y_test, y_pred)
print(f'Acur√°cia do modelo: {accuracy:.2f}')
precision = precision_score(y_test, y_pred)
print(f'Precis√£o do modelo: {precision:.2f}')
recall = recall_score(y_test, y_pred)
print(f'Recall do modelo: {recall:.2f}')
f1 = f1_score(y_test, y_pred)
print(f'F1-score do modelo: {f1:.2f}')`

  - *Acur√°cia*: propor√ß√£o de previs√µes corretas.

  - *Precis√£o*: entre as previs√µes positivas, quantas estavam corretas.

  - *Recall*: entre os casos positivos reais, quantos foram identificados corretamente.

  - *F1-score*: m√©dia harm√¥nica entre precis√£o e recall.

---

## 5. Resultados

### Avalia√ß√£o do modelo:

  - Acur√°cia = 0.68
  - Precis√£o = 0.80
  - Recall = 0.78
  - F1-score = 0.79
  - cm = [[98,159],[178,619]]

### √Årvore de decis√£o:

![arvore of the decisions](https://github.com/user-attachments/assets/5f882d5c-2e05-4c0d-9495-a391e5899638)


### Matriz de confus√£o:

![matriz confusao](https://github.com/user-attachments/assets/a0b3fdd8-f068-4555-9f72-40cff6184e96)




# üèÅ Sprint 4 ATUALIZADA ‚Äì Relat√≥rio Completo

## 1. Introdu√ß√£o
**Objetivo do projeto:**
Antecipar a inten√ß√£o de sa√≠da (turnover) de colaboradores no setor de tecnologia, fornecendo ao RH indicadores para programas de reten√ß√£o.

**Por que este modelo?**

- Identificar riscos de desligamento antecipadamente
- Minimizar custos de substitui√ß√£o e treinamento
- Melhorar estrat√©gias de engajamento e satisfa√ß√£o
- Em compara√ß√£o com o a vers√£o anterior, este modelo visa aumentar a acur√°cia, a precis√£o, o recall, o f1-score, AUROC, e aumentar os acertos da Matriz de Confus√£o, proporcionalmente ao conjunto analisado e testado.

## 2. Finalidade e explica√ß√µes de o que foi feito
> ‚ÄúQuero otimizar o modelo preditivo anterior‚Äù

- **O que mudou em compara√ß√£o √† vers√£o anterior do modelo?**
- Adicionei mais colunas: `('P1_a ', 'Idade')`(achei as idades num√©ricas sem estarem em faixas), `('P2_d ', 'Gestor?')`(vou remover todos os gestores porque o foco s√£o os funcion√°rios que pretendem sair), `('P0', 'id')`(para me ajudar nas an√°lises no excel (vou remover posteriormente na hora do modelo)).
- Removi colunas: `('P1_a_1 ', 'Faixa idade')`(achei as idades num√©ricas sem estarem em faixas), `M√©dia_Idades`(pelo mesmo motivo).
- Considerei remover todas as linhas as quais suas respectivas colunas continham algum atributo faltante ao inv√©s de prever o dado vazio. (fiz isso na pr√≥pria tabela do excel).
- Anteriormente, estive usando o Google Colab. Agora, adotei o Jupyter Notebook.
- Eu tinha separado 75% do modelo para aprendizado e 25% para teste. Mas agora separei 80% para aprendizado e 20% para teste.

- **O que foi mantido?**
- Optei por manter o algoritmo de √°rvore de decis√£o, uma vez que quero prever um conceito, mesmo que seja booleano (no caso, sair ou ficar, 1/0)
- O TARGET - `Preten√ß√£o de sair - TARGET`
- As outras colunas n√£o citadas, como podemos ver na tabela abaixo: 


|      **Coluna**       | **Tipo de dado** | **Atributos correspondentes** | **Altera√ß√£o** |
|-----------------------|------------------|-------------------------------|---------------|
|     `Faixa idade` | Qualitativo intervalar |17-21 <br>22-24<br>25-29<br>30-34<br>35-39<br>40-44<br>45-49<br>50-54<br>55+ | Removido |
|     `G√™nero` |  Qualitativo | Feminino<br>Masculino<br>Outro<br>Prefiro n√£o informar | Mantido |
|  `Cargo Atual` | Qualitativo | Analista de BI/BI Analyst<br>Analista de Dados/Data Analyst<br>Analista de Intelig√™ncia de Mercado/Market Intelligence<br>Analista de Neg√≥cios/Business Analyst<br>Analista de Suporte/Analista T√©cnico<br>Analytics Engineer<br>Cientista de Dados/Data Scientist<br>Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)<br>DBA/Administrador de Banco de Dados<br>Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas<br>Economista<br>Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect<br>Engenheiro de Machine Learning/ML Engineer/AI Engineer<br>Estat√≠stico<br>Outra Op√ß√£o<br>Outras Engenharias (n√£o inclui dev)<br>Professor/Pesquisador<br>(vazio) | Mantido |
|   `N√≠vel` | Qualitativo |J√∫nior<br>Pleno<br>S√™nior<br>(vazio) | Mantido |
|   `Faixa salarial` | Qualitativo intervalar | Acima de R$ 40.001/m√™s<br>de R$ 1.001/m√™s a R$ 2.000/m√™s<br>de R$ 1001/m√™s a R$ 2.000/m√™s<br>de R$ 12.001/m√™s a R$ 16.000/m√™s<br>de R$ 16.001/m√™s a R$ 20.000/m√™s<br>de R$ 2.001/m√™s a R$ 3.000/m√™s<br>de R$ 20.001/m√™s a R$ 25.000/m√™s<br>de R$ 25.001/m√™s a R$ 30.000/m√™s<br>de R$ 3.001/m√™s a R$ 4.000/m√™s<br>de R$ 30.001/m√™s a R$ 40.000/m√™s<br>de R$ 4.001/m√™s a R$ 6.000/m√™s<br>de R$ 6.001/m√™s a R$ 8.000/m√™s<br>de R$ 8.001/m√™s a R$ 12.000/m√™s<br>Menos de R$ 1.000/m√™s<br>(vazio) | Mantido |
|   `Satisfa√ß√£o empresa` | Bool | 0<br>1<br>(vazio) | Mantido |
|   `Pretens√£o mudar emprego` | Qualitativo | Estou em busca de oportunidades dentro ou fora do Brasil<br>Estou em busca de oportunidades, mas apenas fora do Brasil<br>N√£o estou buscando e n√£o pretendo mudar de emprego nos pr√≥ximos 6 meses<br>N√£o estou buscando, mas me considero aberto a outras oportunidades<br>(vazio) | Mantido |
|     `Forma de trabalho` | Qualitativo | Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo h√≠brido com dias fixos de trabalho presencial<br>Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)<br>(vazio) | Mantido |
|     `Forma de trabalho ideal` | Qualitativo | Modelo 100% presencial<br>Modelo 100% remoto<br>Modelo h√≠brido com dias fixos de trabalho presencial<br>Modelo h√≠brido flex√≠vel (o funcion√°rio tem liberdade para escolher quando estar no escrit√≥rio presencialmente)<br>(vazio) | Mantido |
| `ID` | Qualitativo | c√≥digos espec√≠ficos como 001b2d1qtli8t9z7oqgdhj001b2d4i0g | Acrescido |
|`Gestor?` | Bool | 0 ou 1 | Acrescido |
|`Idade` | Quantitativo discreto | N√∫meros inteiros entre 18 e 73 incluindo os extremos | Acrescido |


---

- Como dessa vez eu vou manter as c√©lulas vazias vazias para ent√£o remov√™-las, os c√≥digos que adicionei √†s colunas mudaram: 

| **Qual coluna da base 2.0?** |**Nome da coluna na base 2.0** | **C√≥digo usado na filtragem dos dados** |
|------------------------------|-------------------------------|-----------------------------------------|
| A | `('P0', 'id')` | - |
| B | `('P1_a ', 'Idade')` | - |
| C | `('P1_b ', 'Genero')`| - |
| D | `('P1_e ', 'experiencia_profissional_prejudicada')` | - |
| E | `EXPERI√äNCIA PREJUDICADA SIM OU NAO` | =SE(√âC√âL.VAZIA(D2);; SE(D2="N√£o acredito que minha experi√™ncia profissional seja afetada devido a esses fatores";0;1)) |
| F | `('P2_d ', 'Gestor?')` | - |
| G | `('P2_f ', 'Cargo Atual')` | - |
| H | `AGRUPAMENTO CARGOS` | =SE(√âC√âL.VAZIA(G2);"N√£o informado"; SE(OU(G2="Cientista de Dados/Data Scientist";G2="Analista de Dados/Data Analyst";G2="Analista de BI/BI Analyst";G2="Analista de Intelig√™ncia de Mercado/Market Intelligence");"An√°lise de Dados"; SE(OU(G2="Engenheiro de Dados/Arquiteto de Dados/Data Engineer/Data Architect";G2="Analytics Engineer");"Engenharia de Dados"; SE(G2="Engenheiro de Machine Learning/ML Engineer/AI Engineer";"ML/IA"; SE(G2="Desenvolvedor/ Engenheiro de Software/ Analista de Sistemas";"Desenvolvimento"; SE(G2="Data Product Manager/ Product Manager (PM/APM/DPM/GPM/PO)";"Produto"; SE(OU(G2="Estat√≠stico";G2="Economista");"Cient√≠fico/Quantitativo"; SE(OU(G2="DBA/Administrador de Banco de Dados";G2="Analista de Suporte/Analista T√©cnico");"Infraestrutura"; SE(G2="Outras Engenharias (n√£o inclui dev)";"Outras Engenharias"; SE(G2="Professor/Pesquisador";"Acad√™mico"; SE(G2="Analista de Neg√≥cios/Business Analyst";"Neg√≥cios"; SE(G2="Outra Op√ß√£o";"Outro";"Outro")))))))))))) |
| I | `('P2_h ', 'Faixa salarial')` | - |
| J | `M√âDIA FAIXA SALARIAL` | =SE(√âC√âL.VAZIA(I2);; SE(I2="Acima de R$ 40.001/m√™s";45000; SE(I2="de R$ 1.001/m√™s a R$ 2.000/m√™s";1500; SE(I2="de R$ 1001/m√™s a R$ 2.000/m√™s";1500; SE(I2="de R$ 12.001/m√™s a R$ 16.000/m√™s";14000; SE(I2="de R$ 16.001/m√™s a R$ 20.000/m√™s";18000; SE(I2="de R$ 2.001/m√™s a R$ 3.000/m√™s";2500; SE(I2="de R$ 20.001/m√™s a R$ 25.000/m√™s";22500; SE(I2="de R$ 25.001/m√™s a R$ 30.000/m√™s";27500; SE(I2="de R$ 3.001/m√™s a R$ 4.000/m√™s";3500; SE(I2="de R$ 30.001/m√™s a R$ 40.000/m√™s";35000; SE(I2="de R$ 4.001/m√™s a R$ 6.000/m√™s";5000; SE(I2="de R$ 6.001/m√™s a R$ 8.000/m√™s";7000; SE(I2="de R$ 8.001/m√™s a R$ 12.000/m√™s";10000; SE(I2="Menos de R$ 1.000/m√™s";500;""))))))))))))))) |
| K | `('P2_g ', 'Nivel')` | - |
| L | `N√çVEL COM N√öMEROS ORDINAIS` | =SE(K2="J√∫nior";0; SE(K2="Pleno";1; SE(K2="S√™nior";2; SE(√âC√âL.VAZIA(K2);ALEAT√ìRIOENTRE(0;2);"""")))) |
| M | `('P2_k ', 'Voc√™ est√° satisfeito na sua empresa atual?')` | - |
| N | `('P2_n ', 'Voc√™ pretende mudar de emprego nos pr√≥ximos 6 meses?')` | - |
| O | `PRETENDE SAIR SIM OU NAO - TARGET` | =SE(√âC√âL.VAZIA(N2); SE(ALEAT√ìRIO()<=0,75;1;0); SE(OU(N2="Estou em busca de oportunidades dentro ou fora do Brasil"; N2="Estou em busca de oportunidades, mas apenas fora do Brasil"; N2="N√£o estou buscando, mas me considero aberto a outras oportunidades");1;0)) |
 | P | `('P2_r ', 'Atualmente qual a sua forma de trabalho?')` | - |
 | Q | `('P2_s ', 'Qual a forma de trabalho ideal para voc√™?')` | - |
 | R | `ESTOU NO TRABALHO IDEAL?` | =SE(P2=Q2;1;0) |

Esta √© a base refinada 2.0
---

- Para a base refinada 2.1, removi as colunas que n√£o ajudariam na an√°lise preditiva, removi todas as linhas com o atributo `1` correspondente √† coluna `Gestor?`, depois removi a coluna `Gestor?` e removi todas as linhas com atributos faltantes, ficando assim:

Base 2.1: atributos: `('P1_a ', 'Idade')`, `('P1_b ', 'Genero')`, `EXPERI√äNCIA PREJUDICADA SIM OU NAO`, `AGRUPAMENTO CARGOS`, `M√âDIA FAIXA SALARIAL`, `N√çVEL COM N√öMEROS ORDINAIS`, `('P2_k ', 'Voc√™ est√° satisfeito na sua empresa atual?')`, `PRETENDE SAIR SIM OU NAO - TARGET`, `ESTOU NA FORMA DE TRABALHO IDEAL?`.

Esta √© a base refinada 2.1
---

## 3. Acesso √†s bases de dados

**Base refinada 2.0**
- [BASE SPRINT 4 VERSAO 2.0.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/commit/ed36a3a91a3095fc8c5fae1bcc7e1fb274cc9beb#diff-10b6f2cedd9707c28d337d832fd8dbc297debcce65626a4b2f86fd78f9b67988)

**Base refinada 2.1**
- [BASE SPRINT 4 VERSAO 2.1.csv)]([https://github.com/seu_usuario/seu_repositorio/blob/main/dados.csv](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/commit/c49d6555503f50f1eb98dc6c77e0e72bea512f7e)

| Base de dados | N√∫mero de linhas | N√∫mero de colunas |
|-----------------|------------------|-------------------|
| State of Data Brazil | 5294 | 399 |
| Refinada 1.0 | 5294 | 10 |
| Refinada 1.1 | 5294 | 18 |
| Refinada 2.0 | 5294 | 18 |
| Refinada 2.1 | 3857 | 9 |


---

## 4. Resultados

## 4.1. Modelo Anterior (√°rvore de decis√£o padr√£o)

- Accuracy: 0.68
- Precision: 0.80
- Recall: 0.78
- F1-score: 0.79

Matriz de Confus√£o:

| | Modelo disse que ficou | Modelo disse que saiu | 
|-|------------------------|-----------------------|
| Ficou | 98 | 159 |
| Saiu | 178 | 619 |

 
## 4.2. Modelo Atual (√°rvore otimizada via GridSearchCV)

- Melhores par√¢metros:
> criterion='gini', max_depth=None, min_samples_leaf=1, class_weight=None

- Accuracy: 0.7552 (+11,7 pp)
- Precision: 0.7599 (‚Äì4,0 pp)
- Recall: 0.9880 (+20,8 pp)
- F1-score: 0.8591 (+6,9 pp)
- AUROC: 0.6878

Matriz de Confus√£o:

| | Modelo disse que ficou | Modelo disse que saiu | 
|-|------------------------|-----------------------|
| Ficou | 7 | 182 |
| Saiu | 7 | 576 |



### 4.2.1. Melhorias

- Recall saltou de 78 % para 98,8 %: o modelo quase n√£o perde nenhum colaborador que vai sair.
- F1 subiu de 0,79 para 0,859: melhor equil√≠brio geral.
- Accuracy cresceu de 0,68 para 0,755: bem acima do baseline de ~0,75.

### 4.2.2. Pioras
- Precision caiu de 0,80 para 0,76, aumentando falsos positivos (de 159 em 1024 (15%) para 182 em 772 (23%)).

- Justificativa: ao priorizar recall, o modelo ficou mais ‚Äúconservador‚Äù em prever sa√≠da, aceitando mais alarmes falsos para n√£o perder verdadeiros turnover ‚Äî estrat√©gia adequada quando perder um turnover real √© mais custoso que lidar com interven√ß√µes desnecess√°rias.

---

## 5. Discuss√£o e Conclus√£o
Trade-off recall √ó precision:
O novo modelo opta por maximizar recall, garantindo que quase ningu√©m que tenha inten√ß√£o de sair seja ignorado.

### Impacto pr√°tico:

- Vantagem: RH consegue agir sobre praticamente 100 % dos potenciais turnover.
- Custo: maior n√∫mero de falsos positivos (interven√ß√µes que n√£o eram necess√°rias).

### Recomenda√ß√£o:
Este modelo √© ideal quando o custo de perder um turnover (e permitir a sa√≠da sem rea√ß√£o) √© maior que o custo de abordagens preventivas em falsos alarmes.

---

## 6. Reprodutibilidade
* C√≥digo em python 3 feito no jupyter notebook utilizado para o modelo 2.0 da SPRINT 4:


```
# 0. Instala√ß√£o (executar apenas se necess√°rio)
!pip install --upgrade pandas scikit-learn matplotlib

# 1. Importa√ß√µes
import os
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.dummy import DummyClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn import metrics

# 2. Carregar CSV (mesmo diret√≥rio do notebook)
filename = 'BASE SPRINT 4 VERSAO 2.1.csv'
df = pd.read_csv(filename, sep=';', encoding='latin1')

# 3. Renomear colunas para simplificar
df.rename(columns={
    "('P1_a ', 'Idade')": "Idade",
    "EXPERI√äNCIA PREJUDICADA SIM OU NAO": "ExperienciaPrejudicada",
    "AGRUPAMENTO CARGOS": "AgrupamentoCargos",
    "M√âDIA FAIXA SALARIAL": "MediaFaixaSalarial",
    "N√çVEL COM N√öMEROS ORDINAIS": "NivelOrdinal",
    "('P2_k ', 'Voc√™ est√° satisfeito na sua empresa atual?')": "Satisfeito",
    "PRETENDE SAIR SIM OU NAO - TARGET": "PretendeSair",
    "ESTOU NA FORMA DE TRABALHO IDEAL?": "TrabalhoIdeal"
}, inplace=True)

# 4. Definir features e target
feature_cols = [
    'Idade', 'ExperienciaPrejudicada', 'AgrupamentoCargos',
    'MediaFaixaSalarial', 'NivelOrdinal', 'Satisfeito', 'TrabalhoIdeal'
]
X = df[feature_cols]
y = df['PretendeSair']

# 5. Pr√©-processamento: One-Hot Encoding em AgrupamentoCargos
preproc = ColumnTransformer([
    ('onehot', OneHotEncoder(handle_unknown='ignore'), ['AgrupamentoCargos'])
], remainder='passthrough')
X_proc = preproc.fit_transform(X)

# 6. Dividir treino/teste 80% / 20% (estratificado)
X_train, X_test, y_train, y_test = train_test_split(
    X_proc, y, test_size=0.20, random_state=42, stratify=y
)

# 7. Baseline DummyClassifier
baseline = DummyClassifier(strategy='most_frequent', random_state=42)
baseline.fit(X_train, y_train)
y_base = baseline.predict(X_test)
print("=== Baseline Metrics ===")
print("Accuracy :", metrics.accuracy_score(y_test, y_base))
print("Precision:", metrics.precision_score(y_test, y_base, zero_division=0))
print("Recall   :", metrics.recall_score(y_test, y_base, zero_division=0))
print("F1 Score :", metrics.f1_score(y_test, y_base, zero_division=0))
print()

# 8. Hyperparameter Tuning com GridSearchCV
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [3, 5, 7, None],
    'min_samples_leaf': [1, 5, 10, 20],
    'class_weight': [None, 'balanced']
}
dt = DecisionTreeClassifier(random_state=42)
grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1)
grid.fit(X_train, y_train)

print("Melhores par√¢metros:", grid.best_params_)
print("Melhor F1 em CV :", grid.best_score_, "\n")

# 9. Avaliar o melhor modelo no conjunto de teste
best_tree = grid.best_estimator_
y_pred = best_tree.predict(X_test)
y_proba = best_tree.predict_proba(X_test)[:, 1]

print("=== Test Metrics (Best Tree) ===")
print("Accuracy :", metrics.accuracy_score(y_test, y_pred))
print("Precision:", metrics.precision_score(y_test, y_pred, zero_division=0))
print("Recall   :", metrics.recall_score(y_test, y_pred, zero_division=0))
print("F1 Score :", metrics.f1_score(y_test, y_pred, zero_division=0))
print("AUROC    :", metrics.roc_auc_score(y_test, y_proba))
print()

# 10. Matriz de Confus√£o
cm = metrics.confusion_matrix(y_test, y_pred, labels=[0,1])
disp = metrics.ConfusionMatrixDisplay(cm, display_labels=['Fica (0)', 'Sai (1)'])
disp.plot(cmap=plt.cm.Blues)
plt.show()

# 11. Plot & exportar a √°rvore de decis√£o
plt.figure(figsize=(30,15), dpi=100)
plot_tree(
    best_tree,
    feature_names=preproc.get_feature_names_out(),
    class_names=['Fica','Sai'],
    filled=True, rounded=True, fontsize=12
)
plt.title("√Årvore de Decis√£o Otimizada")
plt.savefig("decision_tree.png", dpi=300)
plt.show()

print("‚úÖ √Årvore exportada: decision_tree.png")

```
### Matriz de confus√£o:
![matriz de confusao 2](https://github.com/user-attachments/assets/2c3897dd-070b-4d92-90aa-d8bb22893583)

### √Årvore de decis√£o: 
![arvore de decisao 2](https://github.com/user-attachments/assets/5ef9a7f3-7c81-4d12-ab86-ebc9ead490a5)


---
# Sprint 4.1 (pequeno b√¥nus)
* Fiz uma altera√ß√£o no c√≥digo para que ele me mostre as informa√ß√µes separadamente dos √≠ndices na parte de treinamendo do modelo e na parte de teste.
C√≥digo utilizado:
```
# üìì Notebook: v2.3 ‚Äì Poda para Reduzir Overfitting

# 1. Instala√ß√£o (se necess√°rio)
!pip install scikit-learn imbalanced-learn matplotlib seaborn graphviz

# 2. Imports
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, classification_report
)
from imblearn.over_sampling import SMOTE

# 3. Carregar dados
df = pd.read_csv('BASE SPRINT 4 VERSAO 2.1.csv', sep=';', encoding='latin1')
df = df.rename(columns={
    "('P1_a ', 'Idade')"     : "Idade",
    "EXPERI√äNCIA PREJUDICADA SIM OU NAO":"ExperienciaPrejudicada",
    "AGRUPAMENTO CARGOS"     : "AgrupamentoCargos",
    "M√âDIA FAIXA SALARIAL"   : "MediaFaixaSalarial",
    "N√çVEL COM N√öMEROS ORDINAIS":"NivelOrdinal",
    "('P2_k ', 'Voc√™ est√° satisfeito na sua empresa atual?')":"Satisfeito",
    "PRETENDE SAIR SIM OU NAO - TARGET":"PretendeSair",
    "ESTOU NA FORMA DE TRABALHO IDEAL?":"TrabalhoIdeal"
})
df = df[['Idade','ExperienciaPrejudicada','AgrupamentoCargos',
         'MediaFaixaSalarial','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']].dropna()

# 4. Convers√£o de tipos
df['Idade'] = df['Idade'].astype(str).str.replace(',','.').astype(float)
df['MediaFaixaSalarial'] = df['MediaFaixaSalarial'].astype(str).str.replace(',','.').astype(float)
df['NivelOrdinal'] = df['NivelOrdinal'].astype(float)
df['Satisfeito'] = df['Satisfeito'].astype(int)
df['TrabalhoIdeal'] = df['TrabalhoIdeal'].astype(int)
df['PretendeSair'] = df['PretendeSair'].astype(int)

# 5. One-Hot Encoding em AgrupamentoCargos
preproc = ColumnTransformer([
    ('ohe', OneHotEncoder(handle_unknown='ignore'), ['AgrupamentoCargos'])
], remainder='passthrough')
X = preproc.fit_transform(df.drop('PretendeSair', axis=1))
y = df['PretendeSair']

# 6. Divis√£o Treino/Teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 7. Balanceamento com SMOTE
sm = SMOTE(random_state=42)
X_tr, y_tr = sm.fit_resample(X_train, y_train)

print("Distribui√ß√£o TREINO antes SMOTE:", y_train.value_counts().to_dict())
print("Distribui√ß√£o TREINO ap√≥s SMOTE:", pd.Series(y_tr).value_counts().to_dict())

# 8. GridSearchCV com poda mais forte
param_grid = {
    'criterion'       : ['entropy'],
    'max_depth'       : [3, 4, 5],       # profundidades menores
    'min_samples_leaf': [10, 20, 50],    # folhas maiores
    'class_weight'    : ['balanced']
}
dt = DecisionTreeClassifier(random_state=42)
grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)
grid.fit(X_tr, y_tr)

best = grid.best_estimator_
print("\n‚Üí Melhores par√¢metros (poda):", grid.best_params_)
print("‚Üí Melhor F1 CV:", grid.best_score_)

# 9. Avalia√ß√£o ‚Äì TREINO
y_tr_pred  = best.predict(X_tr)
y_tr_prob  = best.predict_proba(X_tr)[:,1]
print("\n=== M√©tricas no TREINO ===")
print(classification_report(y_tr, y_tr_pred, target_names=['Fica','Sai']))
print("AUC train:", roc_auc_score(y_tr, y_tr_prob))
cm_tr = confusion_matrix(y_tr, y_tr_pred)
sns.heatmap(cm_tr, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("Confus√£o (Treino)"); plt.show()

# 10. Avalia√ß√£o ‚Äì TESTE
y_te_pred = best.predict(X_test)
y_te_prob = best.predict_proba(X_test)[:,1]
print("\n=== M√©tricas no TESTE ===")
print(classification_report(y_test, y_te_pred, target_names=['Fica','Sai']))
print("AUC test:", roc_auc_score(y_test, y_te_prob))
cm_te = confusion_matrix(y_test, y_te_pred)
sns.heatmap(cm_te, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("Confus√£o (Teste)"); plt.show()

# 11. Plot √°rvore limitada a 3 n√≠veis
plt.figure(figsize=(16,8))
plot_tree(best,
          feature_names=preproc.get_feature_names_out(),
          class_names=['Fica','Sai'],
          filled=True, rounded=True,
          max_depth=3, fontsize=10)
plt.title("√Årvore de Decis√£o (max_depth=3, min_samples_leaf‚â•10)")
plt.show()
```
## Relat√≥rio de Conclus√£o da atualiza√ß√£o do modelo:

### 1. Contexto
- **Objetivo**: Prever a inten√ß√£o de sa√≠da (`PretendeSair`) de profissionais de dados n√£o-gestores.
- **Dados**: Base refinada com colunas num√©ricas, categ√≥ricas binarizadas e vari√°veis derivadas (ex.: experi√™ncia prejudicada, satisfa√ß√£o, trabalho ideal).
- **Tamanho**: 5.294 linhas originais ‚Üí ap√≥s remo√ß√£o de NaNs e filtragem de gestores: ~4.654 linhas.

---

### 2. Pr√©-processamento
1. **Sele√ß√£o de colunas**:  
   - Num√©ricas: `Idade`, `MediaFaixaSalarial`, `NivelOrdinal`.  
   - Bin√°rias/booleanas: `ExperienciaPrejudicada`, `Satisfeito`, `TrabalhoIdeal`.  
   - Categ√≥rica nominal: `AgrupamentoCargos` (One-Hot Encoding).

2. **Convers√£o de tipos**  
   - Substitui√ß√£o de v√≠rgulas por pontos em colunas num√©ricas.  
   - Cast para `float` ou `int` conforme apropriado.

3. **Divis√£o treino/teste**  
   - 80% treino, 20% teste, estratificado por `PretendeSair`.

4. **Balanceamento (SMOTE)**  
   - Antes:  
     - Classe ‚ÄúSai‚Äù (1): 2.327  
     - Classe ‚ÄúFica‚Äù (0): 757  
   - Depois SMOTE no treino:  
     - Ambas as classes com 2.327 exemplos.

---

## 3. Baseline
- **DummyClassifier (most_frequent)** no teste:
  - Accuracy: 24,5%  
  - Precision/Recall/F1: 0 ‚Üí demonstra que prever sempre a classe majorit√°ria n√£o atende ao problema.

---

## 4. Treinamento & Tuning
- **Modelo**: `DecisionTreeClassifier`  
- **GridSearchCV** (5-fold) sobre:
  - `criterion`: `['gini','entropy']`  
  - `max_depth`: `[4,6,8,None]`  
  - `min_samples_leaf`: `[1,5,10]`  
  - `class_weight`: `[None, 'balanced']`

- **Melhores par√¢metros (SMOTE)**:  
{
`criterion`: `entropy`
`max_depth`: `None`
`min_samples_leaf`: 1
`class_weight`: `balanced`
}

- **F1 CV m√©dio**: 0.800

---

## 5. Avalia√ß√£o

### 5.1. Conjunto de Treino
| Classe | Precision | Recall | F1-score | Support |
|--------|-----------|--------|----------|---------|
| Fica   | 0.93      | 0.96   | 0.94     | 2327    |
| Sai    | 0.96      | 0.92   | 0.94     | 2327    |
| **Accuracy** | **0.94** |       |          |         |
| **AUC**      | 0.99   |       |          |         |

> **Interpreta√ß√£o**: Excelente performance e balanceamento em treino ‚Äì indicativo de poss√≠vel _overfitting_.

### 5.2. Conjunto de Teste
| Classe | Precision | Recall | F1-score | Support |
|--------|-----------|--------|----------|---------|
| Fica   | 0.33      | 0.42   | 0.37     | 189     |
| Sai    | 0.79      | 0.72   | 0.76     | 583     |
| **Accuracy** | **0.65** |       |          |         |
| **AUC**      | 0.57   |       |          |         |

> **Interpreta√ß√£o**:  
> - **Fica**: baixa precis√£o e recall ‚Äì o modelo acerta menos da metade dos que realmente ficaram.  
> - **Sai**: performance moderada, mas pior do que no treino.  
> - **AUC 0.57**: discriminador fraco em dados n√£o vistos.  

---

## 6. Diagn√≥stico
- **Overfitting**: Treino (F1=0.94) √ó Teste (F1 m√©dio=0.56)  
- **Classe minorit√°ria (‚ÄúFica‚Äù) mal detectada** apesar de SMOTE.  
- **√Årvore profunda + folhas pequenas** capturam ru√≠do.

---

## 7. Pontos Fortes
- Pipeline organizado de _preprocessing_ ‚Üí SMOTE ‚Üí Tuning.  
- Baseline e m√©tricas completas (accuracy, precision, recall, f1, AUC) em treino e teste.  
- Visualiza√ß√£o da √°rvore simplificada e matrizes de confus√£o.

---

## 8. Pr√≥ximos Passos
1. **Podar a √°rvore**: reduzir `max_depth` (ex.: 4 ou 5) e aumentar `min_samples_leaf` (ex.: 20+).  
2. **Experimentar ensembles**: Random Forest / Gradient Boosting.  
3. **Refinar features**: eliminar vari√°veis irrelevantes ou criar intera√ß√µes.  
4. **Balanceamento alternativo**: SMOTE+Tomek, Borderline-SMOTE.  
5. **Validar com CV mais extenso** (cv=10) para m√©tricas mais est√°veis.

---

> **Conclus√£o**: O modelo atual generaliza mal para a classe ‚ÄúFica‚Äù. Ajustes de poda e uso de m√©todos ensemble devem melhorar o recall dessa classe e elevar o AUC no teste.
---
* Dito isso, alterei o c√≥digo conforme o ponto 8, presente em 4.1:
```python
# üìì Notebook: v2.3 ‚Äì Poda para Reduzir Overfitting

# 1. Instala√ß√£o (se necess√°rio)
!pip install scikit-learn imbalanced-learn matplotlib seaborn graphviz

# 2. Imports
import pandas as pd, numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, classification_report
)
from imblearn.over_sampling import SMOTE

# 3. Carregar dados
df = pd.read_csv('BASE SPRINT 4 VERSAO 2.1.csv', sep=';', encoding='latin1')
df = df.rename(columns={
    "('P1_a ', 'Idade')"     : "Idade",
    "EXPERI√äNCIA PREJUDICADA SIM OU NAO":"ExperienciaPrejudicada",
    "AGRUPAMENTO CARGOS"     : "AgrupamentoCargos",
    "M√âDIA FAIXA SALARIAL"   : "MediaFaixaSalarial",
    "N√çVEL COM N√öMEROS ORDINAIS":"NivelOrdinal",
    "('P2_k ', 'Voc√™ est√° satisfeito na sua empresa atual?')":"Satisfeito",
    "PRETENDE SAIR SIM OU NAO - TARGET":"PretendeSair",
    "ESTOU NA FORMA DE TRABALHO IDEAL?":"TrabalhoIdeal"
})
df = df[['Idade','ExperienciaPrejudicada','AgrupamentoCargos',
         'MediaFaixaSalarial','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']].dropna()

# 4. Convers√£o de tipos
df['Idade'] = df['Idade'].astype(str).str.replace(',','.').astype(float)
df['MediaFaixaSalarial'] = df['MediaFaixaSalarial'].astype(str).str.replace(',','.').astype(float)
df['NivelOrdinal'] = df['NivelOrdinal'].astype(float)
df['Satisfeito'] = df['Satisfeito'].astype(int)
df['TrabalhoIdeal'] = df['TrabalhoIdeal'].astype(int)
df['PretendeSair'] = df['PretendeSair'].astype(int)

# 5. One-Hot Encoding em AgrupamentoCargos
preproc = ColumnTransformer([
    ('ohe', OneHotEncoder(handle_unknown='ignore'), ['AgrupamentoCargos'])
], remainder='passthrough')
X = preproc.fit_transform(df.drop('PretendeSair', axis=1))
y = df['PretendeSair']

# 6. Divis√£o Treino/Teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 7. Balanceamento com SMOTE
sm = SMOTE(random_state=42)
X_tr, y_tr = sm.fit_resample(X_train, y_train)

print("Distribui√ß√£o TREINO antes SMOTE:", y_train.value_counts().to_dict())
print("Distribui√ß√£o TREINO ap√≥s SMOTE:", pd.Series(y_tr).value_counts().to_dict())

# 8. GridSearchCV com poda mais forte
param_grid = {
    'criterion'       : ['entropy'],
    'max_depth'       : [3, 4, 5],       # profundidades menores
    'min_samples_leaf': [10, 20, 50],    # folhas maiores
    'class_weight'    : ['balanced']
}
dt = DecisionTreeClassifier(random_state=42)
grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)
grid.fit(X_tr, y_tr)

best = grid.best_estimator_
print("\n‚Üí Melhores par√¢metros (poda):", grid.best_params_)
print("‚Üí Melhor F1 CV:", grid.best_score_)

# 9. Avalia√ß√£o ‚Äì TREINO
y_tr_pred  = best.predict(X_tr)
y_tr_prob  = best.predict_proba(X_tr)[:,1]
print("\n=== M√©tricas no TREINO ===")
print(classification_report(y_tr, y_tr_pred, target_names=['Fica','Sai']))
print("AUC train:", roc_auc_score(y_tr, y_tr_prob))
cm_tr = confusion_matrix(y_tr, y_tr_pred)
sns.heatmap(cm_tr, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("Confus√£o (Treino)"); plt.show()

# 10. Avalia√ß√£o ‚Äì TESTE
y_te_pred = best.predict(X_test)
y_te_prob = best.predict_proba(X_test)[:,1]
print("\n=== M√©tricas no TESTE ===")
print(classification_report(y_test, y_te_pred, target_names=['Fica','Sai']))
print("AUC test:", roc_auc_score(y_test, y_te_prob))
cm_te = confusion_matrix(y_test, y_te_pred)
sns.heatmap(cm_te, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("Confus√£o (Teste)"); plt.show()

# 11. Plot √°rvore limitada a 3 n√≠veis
plt.figure(figsize=(16,8))
plot_tree(best,
          feature_names=preproc.get_feature_names_out(),
          class_names=['Fica','Sai'],
          filled=True, rounded=True,
          max_depth=3, fontsize=10)
plt.title("√Årvore de Decis√£o (max_depth=3, min_samples_leaf‚â•10)")
plt.show()

```


## Tivemos ent√£o algumas melhoras:

### Resultados da Vers√£o v2.3 (√Årvore Poda `max_depth=3`, `min_samples_leaf=10`)

#### Distribui√ß√£o de Classes no Treino
- Antes do SMOTE:
  - Sai (1): 2 327  
  - Fica (0):   757  
- Ap√≥s SMOTE:
  - Sai (1): 2 327  
  - Fica (0): 2 327  

---

### Hiperpar√¢metros Otimizados
- criterion: `entropy`
- max_depth': `3`
- min_samples_leaf': `10`
- class_weight': `balanced`
* Melhor F1 CV (5-fold): 0.6939

### M√©tricas no Conjunto de Treino
|Classe  |	Precision|	Recall|	F1-score	|Support|
|--------|-----------|--------|-----------|-------|
|Fica	   |0.69	     |0.76    |	0.72    	|2327   |
|Sai     |0.73	     |0.66	  |0.69       |	2327  |
|Accuracy|0.71       |        |           |		    |	
|AUC     |0.79       |        |           |			  |

### Matriz de Confus√£o (Treino)

|  |Modelo disse que saiu| Modelo disse que ficou|
|--|---------------------|-----------------------|
|Saiu|   1769    |  558 |
|Ficou|  799     | 1528 |
 
### M√©tricas no Conjunto de Teste
|Classe  |	Precision|	Recall|	F1-score	|Support|
|--------|-----------|--------|-----------|-------|
|Fica	   |0.35	     |0.63    |	0.45    	|189   |
|Sai     |0.84       |0.62	  |0.71       |	583  |
|Accuracy|0.62       |        |           |		    |	
|AUC     |0.68       |        |           |			  |


### Matriz de Confus√£o (Teste)

|  |Modelo disse que saiu| Modelo disse que ficou|
|--|---------------------|-----------------------|
|Saiu|   119    |  70 |
|Ficou|  222     | 361 |

### Principais Observa√ß√µes:
- Recall ‚ÄúFica‚Äù subiu de 0.42 ‚Üí 0.63, melhorando em +0.21.
- AUC avan√ßou de 0.57 ‚Üí 0.68, indicando melhor poder de discrimina√ß√£o.
- Trade-off: leve queda em F1 ‚ÄúSai‚Äù (0.76 ‚Üí 0.71) e acur√°cia geral (0.65 ‚Üí 0.62).
---

# Planejamento da Sprint 5.
# Sprint 5 ‚Äì 2¬∫ Modelo Induzido: Rede Neural

## 1. Algoritmo Escolhido e Justificativa

- **Algoritmo:** Rede Neural Feed-Forward (MLP)
- **Justificativa:**  
  - Lida bem com vari√°veis num√©ricas e codificadas (idade, sal√°rio, ordinalidade, bin√°rias).  
  - Capta rela√ß√µes n√£o-lineares entre atributos (e.g. intera√ß√µes entre satisfa√ß√£o e experi√™ncia prejudicada).  
  - Permite ajustarmos arquitetura (camadas, neur√¥nios) e regulariza√ß√£o (dropout, batch-norm).

## 1.1 Altera√ß√µes na base de dados

### 1.1.1 Convers√£o de Atributos Categ√≥ricos

Algumas vari√°veis categ√≥ricas foram transformadas para formato num√©rico com o objetivo de permitir o uso em algoritmos de machine learning, que n√£o operam diretamente com strings. As seguintes convers√µes foram aplicadas:

---

#### a) G√™nero

A coluna original `('P1_b ', 'Genero')` foi transformada na coluna bin√°ria `GENERO bin√°rio`, de acordo com a seguinte l√≥gica:

- `"Masculino"` ‚Üí `1`
- `"Feminino"` ‚Üí `0`

Essa convers√£o possibilita a utiliza√ß√£o da vari√°vel de g√™nero como vari√°vel bin√°ria, simplificando o tratamento nos modelos supervisionados.

---

#### b) Agrupamento de Cargos

A vari√°vel categ√≥rica `AGRUPAMENTO CARGOS` foi convertida em `CARGOS numericamente` atrav√©s de um mapeamento manual, com base em categorias sem√¢nticas predefinidas. O mapeamento ficou da seguinte forma:

| Categoria Original          | Valor Num√©rico |
|----------------------------|----------------|
| Acad√™mico                  | 0              |
| An√°lise de Dados           | 1              |
| Cient√≠fico/Quantitativo    | 2              |
| Desenvolvimento            | 3              |
| Engenharia de Dados        | 4              |
| Infraestrutura             | 5              |
| ML/IA                      | 6              |
| Neg√≥cios                   | 7              |
| Outras Engenharias         | 8              |
| Outro                      | 9              |
| Produto                    | 10             |

Essa transforma√ß√£o foi realizada para garantir que os modelos possam trabalhar com essa vari√°vel como ordinal ou categ√≥rica codificada numericamente.

---

### 1.1.2 Justificativa

Essas transforma√ß√µes foram necess√°rias para atender os pr√©-requisitos do algoritmo de machine learning supervisionado que usarei, redes neural, que exige entradas num√©ricas. Al√©m disso, essa padroniza√ß√£o facilita o tratamento de vari√°veis durante o pipeline de modelagem, valida√ß√£o e explica√ß√£o dos resultados.

Acesso √† nova base:  
[BASE SPRINT 4 VERSAO 2 TODA NUMERICA(in).csv)](https://github.com/ICEI-PUC-Minas-PPL-CDIA/ppl-cd-pcd-sist-int-2025-1-grupo4-Disparidade-de-Genero/commit/a0d61a7739c08b5a2b6cd0e09188858860ae5490#diff-23212db9ecadfda8498670d8fdeb232b9233a1ebbaaf71a1b962074a55bf4c0e))

## 2. Baseline

- **DummyClassifier (maior frequ√™ncia):**  
  - Accuracy ~ 0.76 (prev√™ sempre ‚ÄúSai‚Äù).  
  - Precision/Recall/F1 da classe ‚ÄúFica‚Äù = 0.0.  
- **Meta:** superar baseline em pelo menos uma m√©trica chave (F1 ou AUROC).

## 3. Hiper-par√¢metros Documentados

| Par√¢metro         | Valor usado           | Observa√ß√µes                                    |
|-------------------|-----------------------|------------------------------------------------|
| camadas ocultas   | [64, 32]              | Duas camadas densas de 64 e 32 neur√¥nios       |
| ativa√ß√£o ocultas  | `relu`                | Converg√™ncia mais r√°pida em deep learning      |
| ativa√ß√£o sa√≠da    | `sigmoid`             | Bin√°rio (0/1)                                  |
| otimizador        | `adam`                | Ajuste autom√°tico de learning rate             |
| loss              | `binary_crossentropy` | Adequado para classifica√ß√£o bin√°ria            |
| m√©tricas          | `accuracy`, `AUC`     | Avalia tanto acur√°cia quanto separa√ß√£o de classes |
| batch_size        | 32                    | Tamanho de mini-batch                          |
| epochs            | 50                    | Early-stopping opcional (com validation_split) |
| validation_split  | 0.1                   | 10% dos dados de treino para valida√ß√£o interna |

## 4. C√≥digo Reproduz√≠vel (Usei Google Colab)

```python 
# 1. Instala√ß√£o (se necess√°rio)
!pip install tensorflow scikit-learn pandas matplotlib seaborn

# 2. Importa√ß√µes
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.dummy import DummyClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, classification_report
)

import tensorflow as tf
from tensorflow.keras import Input, Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

# 3. Carregar e preparar dados
df = pd.read_csv('BASE_SPRINT5_REFINADA.csv', sep=';', encoding='latin1')

# Renomear colunas para nomes limpos
df.rename(columns={
    "('P1_a ', 'Idade')": 'Idade',
    'GENERO bin√°rio': 'Genero',
    'EXPERI√äNCIA PREJUDICADA SIM OU NAO': 'ExperienciaPrejudicada',
    'CARGOS num√©ricamente': 'AgrupamentoCargos', 
    'M√âDIA FAIXA SALARIAL': 'MediaFaixaSalarial',
    'N√çVEL COM N√öMEROS ORDINAIS': 'NivelOrdinal',
    "('P2_k ', 'Voc√™ est√° satisfeito na sua empresa atual?')": 'Satisfeito',
    'ESTOU NA FORMA DE TRABALHO IDEAL?': 'TrabalhoIdeal',
    'PRETENDE SAIR SIM OU NAO - TARGET': 'PretendeSair'
}, inplace=True)

# Sele√ß√£o de features e target; drop de missing
features = [
    'Idade','Genero','ExperienciaPrejudicada','AgrupamentoCargos',
    'MediaFaixaSalarial','NivelOrdinal','Satisfeito','TrabalhoIdeal'
]
df = df[features + ['PretendeSair']].dropna()

# Converter tipos
df['Idade']                = df['Idade'].astype(float)
df['MediaFaixaSalarial']   = df['MediaFaixaSalarial'].astype(float)
df[['Genero','ExperienciaPrejudicada','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']] = \
    df[['Genero','ExperienciaPrejudicada','NivelOrdinal','Satisfeito','TrabalhoIdeal','PretendeSair']].astype(int)

# 4.1 Baseline Dummy
X_base = df[features]
y_base = df['PretendeSair']
baseline = DummyClassifier(strategy='most_frequent', random_state=42)
baseline.fit(X_base, y_base)
y_base_pred = baseline.predict(X_base)
print("Baseline Accuracy:", accuracy_score(y_base, y_base_pred))

# 5. Split treino/teste
X = df[features]
y = df['PretendeSair']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, stratify=y, random_state=42
)

# 6. Escalar num√©ricos
num_cols = ['Idade','MediaFaixaSalarial','NivelOrdinal']
scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols]  = scaler.transform(X_test[num_cols])

# 7. Construir Rede Neural
model = Sequential([
    Input(shape=(len(features),)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid'),
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.AUC(name='auroc')]
)

# Early stopping opcional
es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    validation_split=0.1,
    epochs=50,
    batch_size=32,
    callbacks=[es],
    verbose=1
)

# 8. Avalia√ß√£o
y_pred_prob = model.predict(X_test).ravel()
y_pred      = (y_pred_prob > 0.5).astype(int)

acc   = accuracy_score(y_test, y_pred)
auc   = roc_auc_score(y_test, y_pred_prob)
prec  = precision_score(y_test, y_pred)
rec   = recall_score(y_test, y_pred)
f1    = f1_score(y_test, y_pred)

print(f"Accuracy: {acc:.4f}")
print(f"AUC     : {auc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall   : {rec:.4f}")
print(f"F1-score : {f1:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['Fica','Sai']))

# 9. Matriz de Confus√£o
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Fica','Sai'], yticklabels=['Fica','Sai'])
plt.title("Matriz de Confus√£o ‚Äì Rede Neural v1.1")
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.show()
```
## 5. M√©tricas Chave e Interpreta√ß√£o (Teste)
|M√©trica	      |Valor    |
|---------------|---------|
|Accuracy       |	0.7293  |
|AUROC          |	0.6929  |
|Precision(Fica)|	0.36    |
|Recall(Fica)   |	0.14    |
|F1(Fica)      	|0.20     |
|Precision(Sai) |	0.77    |
|Recall(Sai)    |	0.92    |
|F1(Sai)	      |0.84     |

* Acur√°cia global (72.9 %) supera baseline (~76 % na base inteira, mas baseline ‚ÄúSai‚Äù falha em ‚ÄúFica‚Äù).

* AUROC ~ 0.69 indica poder discriminativo moderado.

* Modelo √© forte em prever quem sai (alta recall = 92 %), mas ainda fraco em capturar quem fica (recall = 14 %).

## 6. Pontos Fortes e Limita√ß√µes
* Pontos fortes:

  * Supera baseline trivial em F1 geral.

  * Alto recall na classe ‚ÄúSai‚Äù (detec√ß√£o de turnover).

  * Arquitetura simples e treinamento est√°vel.

* Limita√ß√µes:

  * Desequil√≠brio de classes persiste: fraco recall em ‚ÄúFica‚Äù.

  * Over/under-fitting leve (treino ~ 78 % vs teste ~ 73 %).

  * AUROC < 0.70 sugere melhorias no poder preditivo.
 
## 6.1 Matriz de Confus√£o

Abaixo est√° a matriz de confus√£o gerada pelo modelo de rede neural:

![Matriz de confusao segundo modelo induzido 1 1](https://github.com/user-attachments/assets/06e5286d-25ba-4d26-8216-f3ff0de8e9bb)


### Interpreta√ß√£o:

- **Verdadeiros Positivos (VP - "Sai" predito corretamente)**: 537  
  O modelo acertou **537 pessoas** que realmente **pretendiam sair**.

- **Verdadeiros Negativos (VN - "Fica" predito corretamente)**: 26  
  O modelo acertou **26 pessoas** que realmente **pretendiam ficar**.

- **Falsos Positivos (FP - "Sai" predito, mas na verdade fica)**: 136  
  O modelo previu que **136 pessoas sairiam**, mas **na verdade ficariam**.

- **Falsos Negativos (FN - "Fica" predito, mas na verdade sai)**: 46  
  O modelo previu que **46 pessoas ficariam**, mas **na verdade sairiam**.

### Avalia√ß√£o:

- O modelo teve **bom desempenho em identificar quem vai sair (classe majorit√°ria)**, com alta quantidade de acertos (537 VP).
- Por√©m, apresenta **dificuldade em prever corretamente quem ficar√° (classe minorit√°ria)**: apenas 26 VN contra 136 FP.
- Esse comportamento √© t√≠pico em datasets **desbalanceados**, onde a classe ‚ÄúSai‚Äù √© muito mais frequente do que ‚ÄúFica‚Äù.

### Implica√ß√µes:

- Apesar da acur√°cia global razo√°vel, o modelo tende a **superestimar o risco de sa√≠da**, o que pode ser problem√°tico em cen√°rios de RH.
- Para reduzir os falsos positivos, √© poss√≠vel:
  - Aplicar **t√©cnicas de balanceamento** (ex: SMOTE, undersampling).
  - Ajustar o **threshold de decis√£o** (atualmente √© 0.5).
  - Usar **m√©tricas espec√≠ficas da minoria**, como _Recall_ para a classe ‚ÄúFica‚Äù.

---

> **Resumo:** O modelo √© eficaz para identificar potenciais desligamentos, mas ainda falha bastante em prever corretamente quem ir√° permanecer, o que limita sua utilidade pr√°tica em algumas decis√µes estrat√©gicas.



 
## 7. Sugest√µes para Pr√≥xima Itera√ß√£o

* *Balanceamento*: usar SMOTE ou class weights para refor√ßar ‚ÄúFica‚Äù.

* *Ajuste de threshold*: escolher ponto de corte que maximize F1 m√©dio.

* *Arquitetura*: experimentar mais camadas, dropout ou batch-norm.

* *Novos atributos*: criar intera√ß√µes (e.g. idade √ó satisfa√ß√£o).

* *Algoritmo adicional*: comparar com XGBoost / Random Forest para validar robustez.

## 8. An√°lise das Curvas de Treinamento

### Gr√°fico: Curva de Perda e Acur√°cia ao Longo das √âpocas

![graficos rede neural hipotese vai sair 2](https://github.com/user-attachments/assets/f62ba981-e8f5-4776-9910-eb4298b58ac2)

### Interpreta√ß√£o

#### Curva de Perda (Loss)
- A **linha azul** representa a perda (erro) nos dados de **treinamento**, enquanto a **linha laranja** mostra a perda na **valida√ß√£o**.
- Observamos que:
  - A perda de **treinamento** segue diminuindo de forma suave.
  - A perda de **valida√ß√£o** tamb√©m decresce no in√≠cio, mas apresenta **varia√ß√µes inst√°veis** a partir da 7¬™ √©poca.
  - Isso pode ser um **ind√≠cio inicial de overfitting**, pois o modelo continua melhorando no treino, mas oscila na valida√ß√£o.

#### Curva de Acur√°cia
- A **linha azul** indica a acur√°cia nos dados de **treinamento**, e a **linha laranja**, a acur√°cia na **valida√ß√£o**.
- Acur√°cia de **treinamento aumenta continuamente**, atingindo mais de 77%.
- J√° a **acur√°cia de valida√ß√£o oscila** e estabiliza por volta de 72‚Äì73%, sem grande melhora ap√≥s a 6¬™ √©poca.
- Esse comportamento refor√ßa a hip√≥tese de que o modelo come√ßa a **memorizar** o treino, mas **n√£o generaliza t√£o bem** nos dados de valida√ß√£o.

### Conclus√£o da Curva
- O modelo teve um bom in√≠cio de aprendizado, com melhora tanto em loss quanto em acur√°cia.
- A partir de um certo ponto (√©poca ~6 a 8), os ganhos de valida√ß√£o se estagnam ou oscilam, sugerindo a necessidade de:
  - **Regulariza√ß√£o** (ex: dropout, L2).
  - **Early stopping** com base na valida√ß√£o.
  - **Ajuste da arquitetura** (menos neur√¥nios ou camadas).
  - **Balanceamento de classes**, para melhorar a generaliza√ß√£o, principalmente para a classe minorit√°ria (‚ÄúFica‚Äù).

---

> **Resumo:** As curvas refor√ßam a an√°lise quantitativa: o modelo aprende bem o padr√£o do treino, mas ainda n√£o generaliza de forma robusta. √â um bom ponto de partida, mas h√° margem para ajustes estruturais e de dados.



## Conclus√£o:
> O modelo de rede neural v1.1 validou a viabilidade de prever ‚ÄúPretendeSair‚Äù com performance melhor que baseline trivial. H√° ganho modesto em recall da classe minorit√°ria, mas ainda requer refinamentos de balanceamento e arquitetura para capturar quem fica com mais fidelidade.
